{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89fb063",
   "metadata": {
    "papermill": {
     "duration": 0.004497,
     "end_time": "2025-09-01T15:31:59.144788",
     "exception": false,
     "start_time": "2025-09-01T15:31:59.140291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Overview\n",
    "\n",
    "This is a notebook for training a neural network to submit predictions to the \"Binary Classification with a Bank Dataset\" Kaggle competition ([playground-series-s5e8](https://www.kaggle.com/competitions/playground-series-s5e8)).\n",
    "\n",
    "Synthetic data is used for this playground competition, and the objective is to, for each client (with a corresponding `id`) in the test set, predict the probability that the client will subscribe to a bank term deposit. Note that while the target represented by `y` is binary (i.e. the client either subscribes or does not subscribe), the predictions are about probabilities, and so their values lie between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af99f74f",
   "metadata": {
    "papermill": {
     "duration": 0.003415,
     "end_time": "2025-09-01T15:31:59.152007",
     "exception": false,
     "start_time": "2025-09-01T15:31:59.148592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Setup\n",
    "\n",
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81d1ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:31:59.160364Z",
     "iopub.status.busy": "2025-09-01T15:31:59.160111Z",
     "iopub.status.idle": "2025-09-01T15:32:05.526283Z",
     "shell.execute_reply": "2025-09-01T15:32:05.525729Z"
    },
    "papermill": {
     "duration": 6.372028,
     "end_time": "2025-09-01T15:32:05.527649",
     "exception": false,
     "start_time": "2025-09-01T15:31:59.155621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b297304",
   "metadata": {
    "papermill": {
     "duration": 0.003632,
     "end_time": "2025-09-01T15:32:05.535346",
     "exception": false,
     "start_time": "2025-09-01T15:32:05.531714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Reproducibility\n",
    "\n",
    "For reproducibility of results, an arbitrary number will be used for the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d3dbe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:05.545014Z",
     "iopub.status.busy": "2025-09-01T15:32:05.544484Z",
     "iopub.status.idle": "2025-09-01T15:32:05.605490Z",
     "shell.execute_reply": "2025-09-01T15:32:05.604954Z"
    },
    "papermill": {
     "duration": 0.067345,
     "end_time": "2025-09-01T15:32:05.606660",
     "exception": false,
     "start_time": "2025-09-01T15:32:05.539315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed = 11\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f32713",
   "metadata": {
    "papermill": {
     "duration": 0.003424,
     "end_time": "2025-09-01T15:32:05.613783",
     "exception": false,
     "start_time": "2025-09-01T15:32:05.610359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3 Device\n",
    "\n",
    "`device` will indicate whether CUDA or CPU has to be used. While the CPU can be sufficient for some minor tasks like debugging, training of the neural network that will be done in subsequent sections will require an accelerator (GPU) to allow it to complete in a timely fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32023ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:05.621678Z",
     "iopub.status.busy": "2025-09-01T15:32:05.621482Z",
     "iopub.status.idle": "2025-09-01T15:32:05.626325Z",
     "shell.execute_reply": "2025-09-01T15:32:05.625747Z"
    },
    "papermill": {
     "duration": 0.00991,
     "end_time": "2025-09-01T15:32:05.627357",
     "exception": false,
     "start_time": "2025-09-01T15:32:05.617447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3bd59",
   "metadata": {
    "papermill": {
     "duration": 0.003447,
     "end_time": "2025-09-01T15:32:05.634533",
     "exception": false,
     "start_time": "2025-09-01T15:32:05.631086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4 DataFrames\n",
    "\n",
    "Next, the data provided for the competition will be read into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39bdb0d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:05.642656Z",
     "iopub.status.busy": "2025-09-01T15:32:05.642146Z",
     "iopub.status.idle": "2025-09-01T15:32:08.313809Z",
     "shell.execute_reply": "2025-09-01T15:32:08.313102Z"
    },
    "papermill": {
     "duration": 2.677026,
     "end_time": "2025-09-01T15:32:08.315161",
     "exception": false,
     "start_time": "2025-09-01T15:32:05.638135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data files\n",
    "input_filepath = '/kaggle/input'\n",
    "train_data = pd.read_csv(input_filepath + '/playground-series-s5e8/train.csv')\n",
    "test_data = pd.read_csv(input_filepath + '/playground-series-s5e8/test.csv')\n",
    "\n",
    "# Set index\n",
    "train_data.set_index('id', inplace=True)\n",
    "test_data.set_index('id', inplace=True)\n",
    "\n",
    "# Get numeric and categorical columns from training data (which should be the same for test data)\n",
    "numeric_col_names = train_data.select_dtypes(include='number').columns.to_series()\n",
    "categorical_col_names = train_data.select_dtypes(include='object').columns.to_series()\n",
    "assert numeric_col_names.size + categorical_col_names.size == train_data.shape[1]\n",
    "\n",
    "# Set target column\n",
    "target_col='y'\n",
    "# Drop 'y' column from numeric column names\n",
    "numeric_col_names.drop(target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a35db5",
   "metadata": {
    "papermill": {
     "duration": 0.003718,
     "end_time": "2025-09-01T15:32:08.324283",
     "exception": false,
     "start_time": "2025-09-01T15:32:08.320565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Data Preprocessing\n",
    "\n",
    "## 3.1 Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7b9159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:08.332554Z",
     "iopub.status.busy": "2025-09-01T15:32:08.332343Z",
     "iopub.status.idle": "2025-09-01T15:32:09.941317Z",
     "shell.execute_reply": "2025-09-01T15:32:09.940397Z"
    },
    "papermill": {
     "duration": 1.614616,
     "end_time": "2025-09-01T15:32:09.942603",
     "exception": false,
     "start_time": "2025-09-01T15:32:08.327987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_threshold for third quartile: 1390.0\n",
      "duration_threshold for third quartile: 361.0\n",
      "campaign_threshold for third quartile: 3.0\n"
     ]
    }
   ],
   "source": [
    "# log transformation of numeric features\n",
    "\n",
    "train_data['log_balance'] = np.sign(train_data['balance']) * np.log(train_data['balance'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "test_data['log_balance'] = np.sign(test_data['balance']) * np.log(test_data['balance'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "\n",
    "train_data['log_duration'] = np.sign(train_data['duration']) * np.log(train_data['duration'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "test_data['log_duration'] = np.sign(test_data['duration']) * np.log(test_data['duration'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "\n",
    "train_data['log_pdays'] = train_data['pdays'].apply(lambda x: x if x == -1 else (0 if x < 1 else np.log(x)))\n",
    "test_data['log_pdays'] = test_data['pdays'].apply(lambda x: x if x == -1 else (0 if x < 1 else np.log(x)))\n",
    "\n",
    "# sine transformation of numeric features\n",
    "\n",
    "train_data['sine_balance'] = np.sin(2 * np.pi * train_data['balance'] / 1000)\n",
    "test_data['sine_balance'] = np.sin(2 * np.pi * test_data['balance'] / 1000)\n",
    "\n",
    "train_data['sine_duration'] = np.sin(2 * np.pi * train_data['duration'] / 720)\n",
    "test_data['sine_duration'] = np.sin(2 * np.pi * test_data['duration'] / 720)\n",
    "\n",
    "train_data['sine_pdays'] = np.sin(2 * np.pi * train_data['pdays'] / 7)\n",
    "test_data['sine_pdays'] = np.sin(2 * np.pi * test_data['pdays'] / 7)\n",
    "\n",
    "# square root transformation of numeric features\n",
    "\n",
    "train_data['sqrt_balance'] = np.sign(train_data['balance']) * np.sqrt(train_data['balance'].abs())\n",
    "test_data['sqrt_balance'] = np.sign(test_data['balance']) * np.sqrt(test_data['balance'].abs())\n",
    "\n",
    "train_data['sqrt_duration'] = np.sign(train_data['duration']) * np.sqrt(train_data['duration'].abs())\n",
    "test_data['sqrt_duration'] = np.sign(test_data['duration']) * np.sqrt(test_data['duration'].abs())\n",
    "\n",
    "train_data['sqrt_pdays'] = train_data['pdays'].apply(lambda x: x if x == -1 else np.sqrt(np.abs(x)))\n",
    "test_data['sqrt_pdays'] = test_data['pdays'].apply(lambda x: x if x == -1 else np.sqrt(np.abs(x)))\n",
    "\n",
    "train_data['sqrt_campaign'] = np.sqrt(train_data['campaign'].abs())\n",
    "test_data['sqrt_campaign'] = np.sqrt(test_data['campaign'].abs())\n",
    "\n",
    "# transformation of numeric features to boolean ones based on threshold or specific value\n",
    "\n",
    "balance_threshold = train_data['balance'].quantile(0.75)\n",
    "print(f\"balance_threshold for third quartile: {balance_threshold}\")\n",
    "train_data['balance_above_third_quartile'] = (train_data['balance'] > balance_threshold).astype(object)\n",
    "test_data['balance_above_third_quartile'] = (test_data['balance'] > balance_threshold).astype(object)\n",
    "\n",
    "duration_threshold = train_data['duration'].quantile(0.75)\n",
    "print(f\"duration_threshold for third quartile: {duration_threshold}\")\n",
    "train_data['duration_above_third_quartile'] = (train_data['duration'] > duration_threshold).astype(object)\n",
    "test_data['duration_above_third_quartile'] = (test_data['duration'] > duration_threshold).astype(object)\n",
    "\n",
    "campaign_threshold = train_data['campaign'].quantile(0.75)\n",
    "print(f\"campaign_threshold for third quartile: {campaign_threshold}\")\n",
    "train_data['campaign_above_third_quartile'] = (train_data['campaign'] > campaign_threshold).astype(object)\n",
    "test_data['campaign_above_third_quartile'] = (test_data['campaign'] > campaign_threshold).astype(object)\n",
    "\n",
    "train_data['client_not_previously_contacted'] = (train_data['pdays'] == -1).astype(object)\n",
    "test_data['client_not_previously_contacted'] = (test_data['pdays'] == -1).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32ecf3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:09.951856Z",
     "iopub.status.busy": "2025-09-01T15:32:09.951611Z",
     "iopub.status.idle": "2025-09-01T15:32:10.569514Z",
     "shell.execute_reply": "2025-09-01T15:32:10.568711Z"
    },
    "papermill": {
     "duration": 0.624176,
     "end_time": "2025-09-01T15:32:10.570910",
     "exception": false,
     "start_time": "2025-09-01T15:32:09.946734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop columns that are no longer necessary due to feature generation\n",
    "cols_to_drop = [\n",
    "    'balance',\n",
    "    'duration',\n",
    "    'pdays',\n",
    "]\n",
    "train_data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "test_data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# get numeric and categorical column names for training data again, and check that\n",
    "# the total number of numeric and categorical columns is as expected\n",
    "numeric_col_names = train_data.select_dtypes(include='number').columns.to_series()\n",
    "categorical_col_names = train_data.select_dtypes(include='object').columns.to_series()\n",
    "assert numeric_col_names.size + categorical_col_names.size == train_data.shape[1]\n",
    "\n",
    "# drop 'y' column from numeric column names\n",
    "numeric_col_names.drop(target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce478c0",
   "metadata": {
    "papermill": {
     "duration": 0.004032,
     "end_time": "2025-09-01T15:32:10.579910",
     "exception": false,
     "start_time": "2025-09-01T15:32:10.575878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2 Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d48f7c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:10.589651Z",
     "iopub.status.busy": "2025-09-01T15:32:10.588998Z",
     "iopub.status.idle": "2025-09-01T15:32:13.327265Z",
     "shell.execute_reply": "2025-09-01T15:32:13.326665Z"
    },
    "papermill": {
     "duration": 2.744594,
     "end_time": "2025-09-01T15:32:13.328602",
     "exception": false,
     "start_time": "2025-09-01T15:32:10.584008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode categorical features\n",
    "for col in categorical_col_names:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col].astype(str))\n",
    "    test_data[col] = le.fit_transform(test_data[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187be3cd",
   "metadata": {
    "papermill": {
     "duration": 0.003604,
     "end_time": "2025-09-01T15:32:13.337432",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.333828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3 Review of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aeab59c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.345583Z",
     "iopub.status.busy": "2025-09-01T15:32:13.345364Z",
     "iopub.status.idle": "2025-09-01T15:32:13.349642Z",
     "shell.execute_reply": "2025-09-01T15:32:13.348749Z"
    },
    "papermill": {
     "duration": 0.009806,
     "end_time": "2025-09-01T15:32:13.350887",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.341081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features:\n",
      "['age' 'day' 'campaign' 'previous' 'log_balance' 'log_duration'\n",
      " 'log_pdays' 'sine_balance' 'sine_duration' 'sine_pdays' 'sqrt_balance'\n",
      " 'sqrt_duration' 'sqrt_pdays' 'sqrt_campaign']\n",
      "Categorical features:\n",
      "['job' 'marital' 'education' 'default' 'housing' 'loan' 'contact' 'month'\n",
      " 'poutcome' 'balance_above_third_quartile' 'duration_above_third_quartile'\n",
      " 'campaign_above_third_quartile' 'client_not_previously_contacted']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numeric features:\\n{numeric_col_names.values}\")\n",
    "print(f\"Categorical features:\\n{categorical_col_names.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f229c61",
   "metadata": {
    "papermill": {
     "duration": 0.003617,
     "end_time": "2025-09-01T15:32:13.358298",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.354681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7955596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.367139Z",
     "iopub.status.busy": "2025-09-01T15:32:13.366753Z",
     "iopub.status.idle": "2025-09-01T15:32:13.373630Z",
     "shell.execute_reply": "2025-09-01T15:32:13.372921Z"
    },
    "papermill": {
     "duration": 0.012527,
     "end_time": "2025-09-01T15:32:13.374819",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.362292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BankModel(nn.Module):\n",
    "    def __init__(self, num_numeric_features, num_embeddings_list, embeddings_dim, num_hidden_layers=5, dropout_rate=0.42):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding layers for categorical features\n",
    "        self.categorical_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings, embeddings_dim) for num_embeddings in num_embeddings_list\n",
    "        ])\n",
    "\n",
    "        # layer for projecting numeric features on to the embedding space\n",
    "        self.numeric_projection = nn.Linear(num_numeric_features, embeddings_dim)\n",
    "\n",
    "        num_total_features = 1 + len(num_embeddings_list) # num(numeric features) + num(categorical features)\n",
    "        input_size = num_total_features * embeddings_dim\n",
    "        output_size = input_size\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.layers.append(nn.Linear(input_size, output_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.BatchNorm1d(output_size))\n",
    "            self.layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        self.output_layer = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, numeric_inputs, categorical_inputs):\n",
    "        numeric_embeddings = self.numeric_projection(numeric_inputs)\n",
    "        numeric_embeddings = numeric_embeddings.unsqueeze(1)\n",
    "\n",
    "        num_categorical_features = len(categorical_inputs)\n",
    "        categorical_embeddings = [self.categorical_embeddings[i](categorical_inputs[i].unsqueeze(-1)) for i in range(num_categorical_features)]\n",
    "\n",
    "        all_features = torch.cat([numeric_embeddings] + categorical_embeddings, dim=1)\n",
    "        x = all_features\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249003f5",
   "metadata": {
    "papermill": {
     "duration": 0.003482,
     "end_time": "2025-09-01T15:32:13.381975",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.378493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Helper Classes/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2d37e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.389957Z",
     "iopub.status.busy": "2025-09-01T15:32:13.389754Z",
     "iopub.status.idle": "2025-09-01T15:32:13.394337Z",
     "shell.execute_reply": "2025-09-01T15:32:13.393654Z"
    },
    "papermill": {
     "duration": 0.009796,
     "end_time": "2025-09-01T15:32:13.395339",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.385543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, numeric_data, categorical_data, target_col=None):\n",
    "        self.numeric_data = torch.from_numpy(numeric_data).float()\n",
    "        self.categorical_data = torch.from_numpy(categorical_data).long()\n",
    "        self.target_col = torch.from_numpy(target_col).float() if target_col is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numeric_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        numeric_tensors = self.numeric_data[idx]\n",
    "        categorical_tensors = self.categorical_data[idx]\n",
    "        if self.target_col is not None:\n",
    "            return numeric_tensors, categorical_tensors, self.target_col[idx]\n",
    "        return numeric_tensors, categorical_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4af03d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.403567Z",
     "iopub.status.busy": "2025-09-01T15:32:13.403015Z",
     "iopub.status.idle": "2025-09-01T15:32:13.408550Z",
     "shell.execute_reply": "2025-09-01T15:32:13.407882Z"
    },
    "papermill": {
     "duration": 0.010646,
     "end_time": "2025-09-01T15:32:13.409616",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.398970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(train_indices, validation_indices):\n",
    "    \"\"\"\n",
    "    Retrieves data loaders for training, validation and test data.\n",
    "\n",
    "    Assumes that `train_data` and `test_data` dataframes read from 'train.csv' and 'test.csv' input\n",
    "    files, respectively, have been initialized, and uses the `train_indices` and `validation_indices`\n",
    "    arguments to further split the data from `train_data` into training and validation data to be used\n",
    "    for K-Fold Cross Validation.\n",
    "    \"\"\"\n",
    "    X_train_fold_numerical = train_data[numeric_col_names].iloc[train_indices]\n",
    "    X_train_fold_categorical = train_data[categorical_col_names].iloc[train_indices]\n",
    "    y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "\n",
    "    X_validation_fold_numerical = train_data[numeric_col_names].iloc[validation_indices]\n",
    "    X_validation_fold_categorical = train_data[categorical_col_names].iloc[validation_indices]\n",
    "    y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "    train_dataset = TabularDataset(\n",
    "        X_train_fold_numerical.values,\n",
    "        X_train_fold_categorical.values,\n",
    "        y_train_fold.values\n",
    "    )\n",
    "    validation_dataset = TabularDataset(\n",
    "        X_validation_fold_numerical.values,\n",
    "        X_validation_fold_categorical.values,\n",
    "        y_validation_fold.values\n",
    "    )\n",
    "    test_dataset = TabularDataset(\n",
    "        test_data[numeric_col_names].values,\n",
    "        test_data[categorical_col_names].values\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f85180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.417772Z",
     "iopub.status.busy": "2025-09-01T15:32:13.417561Z",
     "iopub.status.idle": "2025-09-01T15:32:13.421137Z",
     "shell.execute_reply": "2025-09-01T15:32:13.420470Z"
    },
    "papermill": {
     "duration": 0.008794,
     "end_time": "2025-09-01T15:32:13.422135",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.413341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_outputs(model, numeric_data, categorical_data):\n",
    "    \"\"\"\n",
    "    Performs inference, returning outputs from passing numeric and categorical feature inputs\n",
    "    through model.\n",
    "    \"\"\"\n",
    "    numeric_data = numeric_data.to(device)\n",
    "    categorical_data = categorical_data.transpose(1,0).to(device)\n",
    "    return model(numeric_data, categorical_data).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cac70c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.430142Z",
     "iopub.status.busy": "2025-09-01T15:32:13.429922Z",
     "iopub.status.idle": "2025-09-01T15:32:13.434149Z",
     "shell.execute_reply": "2025-09-01T15:32:13.433633Z"
    },
    "papermill": {
     "duration": 0.009349,
     "end_time": "2025-09-01T15:32:13.435172",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.425823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader, is_test_data):\n",
    "    \"\"\"\n",
    "    Performs inference and returns predictions for data loaded by `data_loader`.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if is_test_data:\n",
    "            for numeric_data, categorical_data in data_loader:\n",
    "                outputs = get_outputs(model, numeric_data, categorical_data)\n",
    "                predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "        else:\n",
    "            for numeric_data, categorical_data, _ in data_loader:\n",
    "                outputs = get_outputs(model, numeric_data, categorical_data)\n",
    "                predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28523902",
   "metadata": {
    "papermill": {
     "duration": 0.003666,
     "end_time": "2025-09-01T15:32:13.442786",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.439120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Stratified K-Fold\n",
    "\n",
    "We'll perform Stratified K-Fold using the following hyperparameters (that have been tuned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e4c8fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.450906Z",
     "iopub.status.busy": "2025-09-01T15:32:13.450664Z",
     "iopub.status.idle": "2025-09-01T15:32:13.453757Z",
     "shell.execute_reply": "2025-09-01T15:32:13.453217Z"
    },
    "papermill": {
     "duration": 0.008417,
     "end_time": "2025-09-01T15:32:13.454825",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.446408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfold_num_splits = 10\n",
    "batch_size = 1024\n",
    "max_epochs = 500\n",
    "patience = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b5f100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T15:32:13.463207Z",
     "iopub.status.busy": "2025-09-01T15:32:13.463011Z",
     "iopub.status.idle": "2025-09-01T19:38:32.400626Z",
     "shell.execute_reply": "2025-09-01T19:38:32.400021Z"
    },
    "papermill": {
     "duration": 14778.943652,
     "end_time": "2025-09-01T19:38:32.402117",
     "exception": false,
     "start_time": "2025-09-01T15:32:13.458465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Training Fold 1 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95513\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96334\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96403\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96458\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96492\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96481\n",
      "[Epoch 151] Training Loss: 0.00014, Validation AUC Score: 0.96506\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 1: 0.96516\n",
      "\n",
      "##### Training Fold 2 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95519\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96337\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96404\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96455\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96462\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96485\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96500\n",
      "[Epoch 176] Training Loss: 0.00014, Validation AUC Score: 0.96519\n",
      "[Epoch 201] Training Loss: 0.00014, Validation AUC Score: 0.96516\n",
      "[Epoch 226] Training Loss: 0.00014, Validation AUC Score: 0.96491\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 2: 0.96525\n",
      "\n",
      "##### Training Fold 3 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95255\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96253\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96369\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96396\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96446\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96442\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96431\n",
      "[Epoch 176] Training Loss: 0.00014, Validation AUC Score: 0.96458\n",
      "[Epoch 201] Training Loss: 0.00014, Validation AUC Score: 0.96453\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 3: 0.96467\n",
      "\n",
      "##### Training Fold 4 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95317\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96356\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96480\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96519\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96526\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96519\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96548\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 4: 0.96563\n",
      "\n",
      "##### Training Fold 5 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95477\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96271\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96378\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96414\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96409\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96436\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96454\n",
      "[Epoch 176] Training Loss: 0.00014, Validation AUC Score: 0.96448\n",
      "[Epoch 201] Training Loss: 0.00014, Validation AUC Score: 0.96434\n",
      "[Epoch 226] Training Loss: 0.00014, Validation AUC Score: 0.96433\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 5: 0.96463\n",
      "\n",
      "##### Training Fold 6 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95487\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96213\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96357\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96422\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96443\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96459\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96450\n",
      "[Epoch 176] Training Loss: 0.00014, Validation AUC Score: 0.96464\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 6: 0.96484\n",
      "\n",
      "##### Training Fold 7 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95442\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96207\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96335\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96352\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96371\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96381\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96372\n",
      "[Epoch 176] Training Loss: 0.00014, Validation AUC Score: 0.96368\n",
      "[Epoch 201] Training Loss: 0.00014, Validation AUC Score: 0.96382\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 7: 0.96407\n",
      "\n",
      "##### Training Fold 8 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95539\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96371\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96455\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96495\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96499\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96548\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96533\n",
      "[Epoch 176] Training Loss: 0.00014, Validation AUC Score: 0.96551\n",
      "[Epoch 201] Training Loss: 0.00014, Validation AUC Score: 0.96548\n",
      "[Epoch 226] Training Loss: 0.00014, Validation AUC Score: 0.96520\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 8: 0.96556\n",
      "\n",
      "##### Training Fold 9 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95608\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96355\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96478\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96495\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96530\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96545\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 9: 0.96563\n",
      "\n",
      "##### Training Fold 10 of 10 #####\n",
      "\n",
      "(Max epochs: 500)\n",
      "[Epoch 1] Training Loss: 0.00023, Validation AUC Score: 0.95412\n",
      "[Epoch 26] Training Loss: 0.00015, Validation AUC Score: 0.96317\n",
      "[Epoch 51] Training Loss: 0.00015, Validation AUC Score: 0.96418\n",
      "[Epoch 76] Training Loss: 0.00015, Validation AUC Score: 0.96456\n",
      "[Epoch 101] Training Loss: 0.00015, Validation AUC Score: 0.96474\n",
      "[Epoch 126] Training Loss: 0.00015, Validation AUC Score: 0.96497\n",
      "[Epoch 151] Training Loss: 0.00015, Validation AUC Score: 0.96504\n",
      "[Epoch 176] Training Loss: 0.00014, Validation AUC Score: 0.96509\n",
      "[Epoch 201] Training Loss: 0.00014, Validation AUC Score: 0.96519\n",
      "Stopping early - 50 epochs passed without improvement in best validation ROC AUC score.\n",
      "Final ROC AUC score for Fold 10: 0.96527\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=kfold_num_splits, shuffle=True, random_state=random_seed)\n",
    "kfold_splits = kfold.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "kfold_splits_enumeration = enumerate(kfold_splits)\n",
    "\n",
    "oof_predictions = np.zeros(len(train_data))\n",
    "test_predictions = np.zeros(len(test_data))\n",
    "\n",
    "# will be used later for getting values for 'num_embeddings'\n",
    "train_test_combined = pd.concat([train_data.drop(target_col, axis=1), test_data], axis=0)\n",
    "\n",
    "for fold, (train_indices, validation_indices) in kfold_splits_enumeration:\n",
    "    print(f\"\\n##### Training Fold {fold + 1} of {kfold_num_splits} #####\\n\")\n",
    "\n",
    "    # get data loaders for training, validation and test data\n",
    "    train_loader, validation_loader, test_loader = get_data_loaders(train_indices, validation_indices)\n",
    "\n",
    "    # will be used later for ROC AUC score calculation\n",
    "    y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "    # PyTorch model\n",
    "    model = BankModel(\n",
    "        len(numeric_col_names),\n",
    "        train_test_combined[categorical_col_names].nunique(), # `num_embeddings` Embedding parameter\n",
    "        32 # `embedding_dim` Embedding parameter\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "    best_validation_auc_score = 0\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    print(f\"(Max epochs: {max_epochs})\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        loss_train = 0\n",
    "        for numeric_data, categorical_data, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = get_outputs(model, numeric_data, categorical_data)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        validation_predictions = get_predictions(model, validation_loader, False)\n",
    "        current_validation_auc_score = roc_auc_score(y_validation_fold, validation_predictions)\n",
    "        if epoch % 25 == 0:\n",
    "            print(f\"[Epoch {epoch + 1}] Training Loss: {loss_train / len(train_indices):.5f}, Validation AUC Score: {current_validation_auc_score:.5f}\")\n",
    "\n",
    "        if current_validation_auc_score > best_validation_auc_score:\n",
    "            best_validation_auc_score = current_validation_auc_score\n",
    "            early_stopping_counter = 0\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Stopping early - {patience} epochs passed without improvement in best validation ROC AUC score.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "    model.eval()\n",
    "    validation_predictions = get_predictions(model, validation_loader, False)\n",
    "\n",
    "    oof_predictions[validation_indices] = np.array(validation_predictions)\n",
    "    final_fold_roc_auc_score = roc_auc_score(y_validation_fold, oof_predictions[validation_indices])\n",
    "    print(f\"Final ROC AUC score for Fold {fold + 1}: {final_fold_roc_auc_score:.5f}\")\n",
    "\n",
    "    # Make predictions on test data\n",
    "    test_predictions_fold = get_predictions(model, test_loader, True)\n",
    "    test_predictions += np.array(test_predictions_fold) / kfold_num_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7372d7ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T19:38:32.420249Z",
     "iopub.status.busy": "2025-09-01T19:38:32.419902Z",
     "iopub.status.idle": "2025-09-01T19:38:32.766198Z",
     "shell.execute_reply": "2025-09-01T19:38:32.765441Z"
    },
    "papermill": {
     "duration": 0.35657,
     "end_time": "2025-09-01T19:38:32.767435",
     "exception": false,
     "start_time": "2025-09-01T19:38:32.410865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross Validation ROC AUC: 0.96499\n"
     ]
    }
   ],
   "source": [
    "# calculate the ROC AUC score for all Out-Of-Fold predictions\n",
    "oof_roc_auc_score = roc_auc_score(train_data[target_col], oof_predictions)\n",
    "print(f\"{kfold_num_splits}-Fold Cross Validation ROC AUC: {oof_roc_auc_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27226f29",
   "metadata": {
    "papermill": {
     "duration": 0.008205,
     "end_time": "2025-09-01T19:38:32.784857",
     "exception": false,
     "start_time": "2025-09-01T19:38:32.776652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d95fcae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T19:38:32.802023Z",
     "iopub.status.busy": "2025-09-01T19:38:32.801796Z",
     "iopub.status.idle": "2025-09-01T19:38:33.308657Z",
     "shell.execute_reply": "2025-09-01T19:38:33.307827Z"
    },
    "papermill": {
     "duration": 0.517085,
     "end_time": "2025-09-01T19:38:33.310052",
     "exception": false,
     "start_time": "2025-09-01T19:38:32.792967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file prepared.\n"
     ]
    }
   ],
   "source": [
    "# Prepare submission\n",
    "submission = pd.DataFrame({'id': test_data.index, 'y': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file prepared.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12937777,
     "sourceId": 91719,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14800.441713,
   "end_time": "2025-09-01T19:38:35.888881",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-01T15:31:55.447168",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
