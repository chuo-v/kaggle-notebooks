{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32571ed2",
   "metadata": {
    "papermill": {
     "duration": 0.004504,
     "end_time": "2025-08-28T13:21:51.429994",
     "exception": false,
     "start_time": "2025-08-28T13:21:51.425490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Overview\n",
    "\n",
    "This is a notebook for training a neural network to submit predictions to the \"Binary Classification with a Bank Dataset\" Kaggle competition ([playground-series-s5e8](https://www.kaggle.com/competitions/playground-series-s5e8)).\n",
    "\n",
    "Synthetic data is used for this playground competition, and the objective is to, for each client (with a corresponding `id`) in the test set, predict the probability that the client will subscribe to a bank term deposit. Note that while the target represented by `y` is binary (i.e. the client either subscribes or does not subscribe), the predictions are about probabilities, and so their values lie between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abbbd7",
   "metadata": {
    "papermill": {
     "duration": 0.003708,
     "end_time": "2025-08-28T13:21:51.437397",
     "exception": false,
     "start_time": "2025-08-28T13:21:51.433689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Setup\n",
    "\n",
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad3251b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:21:51.445614Z",
     "iopub.status.busy": "2025-08-28T13:21:51.445284Z",
     "iopub.status.idle": "2025-08-28T13:22:03.409960Z",
     "shell.execute_reply": "2025-08-28T13:22:03.408461Z"
    },
    "papermill": {
     "duration": 11.971393,
     "end_time": "2025-08-28T13:22:03.412394",
     "exception": false,
     "start_time": "2025-08-28T13:21:51.441001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30166f5",
   "metadata": {
    "papermill": {
     "duration": 0.00544,
     "end_time": "2025-08-28T13:22:03.424327",
     "exception": false,
     "start_time": "2025-08-28T13:22:03.418887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Reproducibility\n",
    "\n",
    "For reproducibility of results, an arbitrary number will be used for the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9424f42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:03.435446Z",
     "iopub.status.busy": "2025-08-28T13:22:03.435097Z",
     "iopub.status.idle": "2025-08-28T13:22:03.494504Z",
     "shell.execute_reply": "2025-08-28T13:22:03.493938Z"
    },
    "papermill": {
     "duration": 0.065294,
     "end_time": "2025-08-28T13:22:03.495843",
     "exception": false,
     "start_time": "2025-08-28T13:22:03.430549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed = 11\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a59a9",
   "metadata": {
    "papermill": {
     "duration": 0.003532,
     "end_time": "2025-08-28T13:22:03.503170",
     "exception": false,
     "start_time": "2025-08-28T13:22:03.499638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3 Device\n",
    "\n",
    "`device` will indicate whether CUDA or CPU has to be used. While the CPU can be sufficient for some minor tasks like debugging, training of the neural network that will be done in subsequent sections will require an accelerator (GPU) to allow it to complete in a timely fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d15d19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:03.511121Z",
     "iopub.status.busy": "2025-08-28T13:22:03.510925Z",
     "iopub.status.idle": "2025-08-28T13:22:03.515655Z",
     "shell.execute_reply": "2025-08-28T13:22:03.515087Z"
    },
    "papermill": {
     "duration": 0.009906,
     "end_time": "2025-08-28T13:22:03.516664",
     "exception": false,
     "start_time": "2025-08-28T13:22:03.506758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2363988",
   "metadata": {
    "papermill": {
     "duration": 0.003544,
     "end_time": "2025-08-28T13:22:03.523941",
     "exception": false,
     "start_time": "2025-08-28T13:22:03.520397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4 DataFrames\n",
    "\n",
    "Next, the data provided for the competition will be read into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05554fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:03.532589Z",
     "iopub.status.busy": "2025-08-28T13:22:03.532161Z",
     "iopub.status.idle": "2025-08-28T13:22:06.116254Z",
     "shell.execute_reply": "2025-08-28T13:22:06.115437Z"
    },
    "papermill": {
     "duration": 2.589563,
     "end_time": "2025-08-28T13:22:06.117688",
     "exception": false,
     "start_time": "2025-08-28T13:22:03.528125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data files\n",
    "input_filepath = '/kaggle/input'\n",
    "train_data = pd.read_csv(input_filepath + '/playground-series-s5e8/train.csv')\n",
    "test_data = pd.read_csv(input_filepath + '/playground-series-s5e8/test.csv')\n",
    "\n",
    "# Set index\n",
    "train_data.set_index('id', inplace=True)\n",
    "test_data.set_index('id', inplace=True)\n",
    "\n",
    "# Get numeric and categorical columns from training data (which should be the same for test data)\n",
    "numeric_col_names = train_data.select_dtypes(include='number').columns.to_series()\n",
    "categorical_col_names = train_data.select_dtypes(include='object').columns.to_series()\n",
    "assert numeric_col_names.size + categorical_col_names.size == train_data.shape[1]\n",
    "\n",
    "# Set target column\n",
    "target_col='y'\n",
    "# Drop 'y' column from numeric column names\n",
    "numeric_col_names.drop(target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ae38e5",
   "metadata": {
    "papermill": {
     "duration": 0.003669,
     "end_time": "2025-08-28T13:22:06.125359",
     "exception": false,
     "start_time": "2025-08-28T13:22:06.121690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Data Preprocessing\n",
    "\n",
    "## 3.1 Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fb1545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:06.134287Z",
     "iopub.status.busy": "2025-08-28T13:22:06.133709Z",
     "iopub.status.idle": "2025-08-28T13:22:07.293436Z",
     "shell.execute_reply": "2025-08-28T13:22:07.292658Z"
    },
    "papermill": {
     "duration": 1.165338,
     "end_time": "2025-08-28T13:22:07.294654",
     "exception": false,
     "start_time": "2025-08-28T13:22:06.129316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance_threshold for third quartile: 1390.0\n",
      "duration_threshold for third quartile: 361.0\n",
      "campaign_threshold for third quartile: 3.0\n"
     ]
    }
   ],
   "source": [
    "# log transformation of numeric features\n",
    "\n",
    "train_data['log_balance'] = np.sign(train_data['balance']) * np.log(train_data['balance'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "test_data['log_balance'] = np.sign(test_data['balance']) * np.log(test_data['balance'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "\n",
    "train_data['log_duration'] = np.sign(train_data['duration']) * np.log(train_data['duration'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "test_data['log_duration'] = np.sign(test_data['duration']) * np.log(test_data['duration'].abs().apply(lambda x: x if x > 1 else 1))\n",
    "\n",
    "train_data['log_pdays'] = train_data['pdays'].apply(lambda x: x if x == -1 else (0 if x < 1 else np.log(x)))\n",
    "test_data['log_pdays'] = test_data['pdays'].apply(lambda x: x if x == -1 else (0 if x < 1 else np.log(x)))\n",
    "\n",
    "# sine transformation of numeric features\n",
    "\n",
    "train_data['sine_balance'] = np.sin(2 * np.pi * train_data['balance'] / 1000)\n",
    "test_data['sine_balance'] = np.sin(2 * np.pi * test_data['balance'] / 1000)\n",
    "\n",
    "train_data['sine_duration'] = np.sin(2 * np.pi * train_data['duration'] / 720)\n",
    "test_data['sine_duration'] = np.sin(2 * np.pi * test_data['duration'] / 720)\n",
    "\n",
    "train_data['sine_pdays'] = np.sin(2 * np.pi * train_data['pdays'] / 7)\n",
    "test_data['sine_pdays'] = np.sin(2 * np.pi * test_data['pdays'] / 7)\n",
    "\n",
    "# transformation of numeric features to boolean ones based on threshold or specific value\n",
    "\n",
    "balance_threshold = train_data['balance'].quantile(0.75)\n",
    "print(f\"balance_threshold for third quartile: {balance_threshold}\")\n",
    "train_data['balance_above_third_quartile'] = (train_data['balance'] > balance_threshold).astype(object)\n",
    "test_data['balance_above_third_quartile'] = (test_data['balance'] > balance_threshold).astype(object)\n",
    "\n",
    "duration_threshold = train_data['duration'].quantile(0.75)\n",
    "print(f\"duration_threshold for third quartile: {duration_threshold}\")\n",
    "train_data['duration_above_third_quartile'] = (train_data['duration'] > duration_threshold).astype(object)\n",
    "test_data['duration_above_third_quartile'] = (test_data['duration'] > duration_threshold).astype(object)\n",
    "\n",
    "campaign_threshold = train_data['campaign'].quantile(0.75)\n",
    "print(f\"campaign_threshold for third quartile: {campaign_threshold}\")\n",
    "train_data['campaign_above_third_quartile'] = (train_data['campaign'] > campaign_threshold).astype(object)\n",
    "test_data['campaign_above_third_quartile'] = (test_data['campaign'] > campaign_threshold).astype(object)\n",
    "\n",
    "train_data['client_not_previously_contacted'] = (train_data['pdays'] == -1).astype(object)\n",
    "test_data['client_not_previously_contacted'] = (test_data['pdays'] == -1).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e71fd82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:07.303522Z",
     "iopub.status.busy": "2025-08-28T13:22:07.303108Z",
     "iopub.status.idle": "2025-08-28T13:22:07.899392Z",
     "shell.execute_reply": "2025-08-28T13:22:07.898818Z"
    },
    "papermill": {
     "duration": 0.602064,
     "end_time": "2025-08-28T13:22:07.900707",
     "exception": false,
     "start_time": "2025-08-28T13:22:07.298643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop columns that are no longer necessary due to feature generation\n",
    "cols_to_drop = [\n",
    "    'balance',\n",
    "    'duration',\n",
    "    'pdays',\n",
    "]\n",
    "train_data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "test_data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# get numeric and categorical column names for training data again, and check that\n",
    "# the total number of numeric and categorical columns is as expected\n",
    "numeric_col_names = train_data.select_dtypes(include='number').columns.to_series()\n",
    "categorical_col_names = train_data.select_dtypes(include='object').columns.to_series()\n",
    "assert numeric_col_names.size + categorical_col_names.size == train_data.shape[1]\n",
    "\n",
    "# drop 'y' column from numeric column names\n",
    "numeric_col_names.drop(target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910aa1e",
   "metadata": {
    "papermill": {
     "duration": 0.003538,
     "end_time": "2025-08-28T13:22:07.908252",
     "exception": false,
     "start_time": "2025-08-28T13:22:07.904714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2 Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d983a341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:07.916373Z",
     "iopub.status.busy": "2025-08-28T13:22:07.916175Z",
     "iopub.status.idle": "2025-08-28T13:22:10.620885Z",
     "shell.execute_reply": "2025-08-28T13:22:10.620290Z"
    },
    "papermill": {
     "duration": 2.710376,
     "end_time": "2025-08-28T13:22:10.622212",
     "exception": false,
     "start_time": "2025-08-28T13:22:07.911836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode categorical features\n",
    "for col in categorical_col_names:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col].astype(str))\n",
    "    test_data[col] = le.fit_transform(test_data[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe1a1a",
   "metadata": {
    "papermill": {
     "duration": 0.003516,
     "end_time": "2025-08-28T13:22:10.629746",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.626230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3 Review of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c7be54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.637817Z",
     "iopub.status.busy": "2025-08-28T13:22:10.637593Z",
     "iopub.status.idle": "2025-08-28T13:22:10.641624Z",
     "shell.execute_reply": "2025-08-28T13:22:10.641041Z"
    },
    "papermill": {
     "duration": 0.009251,
     "end_time": "2025-08-28T13:22:10.642598",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.633347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features:\n",
      "['age' 'day' 'campaign' 'previous' 'log_balance' 'log_duration'\n",
      " 'log_pdays' 'sine_balance' 'sine_duration' 'sine_pdays']\n",
      "Categorical features:\n",
      "['job' 'marital' 'education' 'default' 'housing' 'loan' 'contact' 'month'\n",
      " 'poutcome' 'balance_above_third_quartile' 'duration_above_third_quartile'\n",
      " 'campaign_above_third_quartile' 'client_not_previously_contacted']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numeric features:\\n{numeric_col_names.values}\")\n",
    "print(f\"Categorical features:\\n{categorical_col_names.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1b32b",
   "metadata": {
    "papermill": {
     "duration": 0.003482,
     "end_time": "2025-08-28T13:22:10.649785",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.646303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e66c901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.657979Z",
     "iopub.status.busy": "2025-08-28T13:22:10.657759Z",
     "iopub.status.idle": "2025-08-28T13:22:10.664167Z",
     "shell.execute_reply": "2025-08-28T13:22:10.663665Z"
    },
    "papermill": {
     "duration": 0.011754,
     "end_time": "2025-08-28T13:22:10.665218",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.653464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BankModel(nn.Module):\n",
    "    def __init__(self, num_numeric_features, num_embeddings_list, embeddings_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding layers for categorical features\n",
    "        self.categorical_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings, embeddings_dim) for num_embeddings in num_embeddings_list\n",
    "        ])\n",
    "\n",
    "        # layer for projecting numeric features on to the embedding space\n",
    "        self.numeric_projection = nn.Linear(num_numeric_features, embeddings_dim)\n",
    "\n",
    "        num_total_features = 1 + len(num_embeddings_list) # num(numeric features) + num(categorical features)\n",
    "        input_size = num_total_features * embeddings_dim\n",
    "        output_size = input_size\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(5):\n",
    "            self.layers.append(nn.Linear(input_size, output_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.BatchNorm1d(output_size))\n",
    "            self.layers.append(nn.Dropout(0.1))\n",
    "\n",
    "        # final output layer\n",
    "        self.output_layer = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, numeric_inputs, categorical_inputs):\n",
    "        numeric_embeddings = self.numeric_projection(numeric_inputs)\n",
    "        numeric_embeddings = numeric_embeddings.unsqueeze(1)\n",
    "\n",
    "        num_categorical_features = len(categorical_inputs)\n",
    "        categorical_embeddings = [self.categorical_embeddings[i](categorical_inputs[i].unsqueeze(-1)) for i in range(num_categorical_features)]\n",
    "\n",
    "        all_features = torch.cat([numeric_embeddings] + categorical_embeddings, dim=1)\n",
    "        x = all_features\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729d9b2",
   "metadata": {
    "papermill": {
     "duration": 0.003391,
     "end_time": "2025-08-28T13:22:10.672242",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.668851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Helper Classes/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f5fd19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.680096Z",
     "iopub.status.busy": "2025-08-28T13:22:10.679922Z",
     "iopub.status.idle": "2025-08-28T13:22:10.684591Z",
     "shell.execute_reply": "2025-08-28T13:22:10.683939Z"
    },
    "papermill": {
     "duration": 0.00991,
     "end_time": "2025-08-28T13:22:10.685696",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.675786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, numeric_data, categorical_data, target_col=None):\n",
    "        self.numeric_data = torch.from_numpy(numeric_data).float()\n",
    "        self.categorical_data = torch.from_numpy(categorical_data).long()\n",
    "        self.target_col = torch.from_numpy(target_col).float() if target_col is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numeric_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        numeric_tensors = self.numeric_data[idx]\n",
    "        categorical_tensors = self.categorical_data[idx]\n",
    "        if self.target_col is not None:\n",
    "            return numeric_tensors, categorical_tensors, self.target_col[idx]\n",
    "        return numeric_tensors, categorical_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e517314f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.693874Z",
     "iopub.status.busy": "2025-08-28T13:22:10.693641Z",
     "iopub.status.idle": "2025-08-28T13:22:10.698355Z",
     "shell.execute_reply": "2025-08-28T13:22:10.697827Z"
    },
    "papermill": {
     "duration": 0.009948,
     "end_time": "2025-08-28T13:22:10.699374",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.689426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(train_indices, validation_indices):\n",
    "    X_train_fold_numerical = train_data[numeric_col_names].iloc[train_indices]\n",
    "    X_train_fold_categorical = train_data[categorical_col_names].iloc[train_indices]\n",
    "    y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "\n",
    "    X_validation_fold_numerical = train_data[numeric_col_names].iloc[validation_indices]\n",
    "    X_validation_fold_categorical = train_data[categorical_col_names].iloc[validation_indices]\n",
    "    y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "    train_dataset = TabularDataset(\n",
    "        X_train_fold_numerical.values,\n",
    "        X_train_fold_categorical.values,\n",
    "        y_train_fold.values\n",
    "    )\n",
    "    validation_dataset = TabularDataset(\n",
    "        X_validation_fold_numerical.values,\n",
    "        X_validation_fold_categorical.values,\n",
    "        y_validation_fold.values\n",
    "    )\n",
    "    test_dataset = TabularDataset(\n",
    "        test_data[numeric_col_names].values,\n",
    "        test_data[categorical_col_names].values\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ef5167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.707508Z",
     "iopub.status.busy": "2025-08-28T13:22:10.707318Z",
     "iopub.status.idle": "2025-08-28T13:22:10.710507Z",
     "shell.execute_reply": "2025-08-28T13:22:10.710036Z"
    },
    "papermill": {
     "duration": 0.008336,
     "end_time": "2025-08-28T13:22:10.711444",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.703108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_outputs(model, numeric_data, categorical_data):\n",
    "    numeric_data = numeric_data.to(device)\n",
    "    categorical_data = categorical_data.transpose(1,0).to(device)\n",
    "    return model(numeric_data, categorical_data).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1994e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.719332Z",
     "iopub.status.busy": "2025-08-28T13:22:10.719139Z",
     "iopub.status.idle": "2025-08-28T13:22:10.723403Z",
     "shell.execute_reply": "2025-08-28T13:22:10.722726Z"
    },
    "papermill": {
     "duration": 0.009412,
     "end_time": "2025-08-28T13:22:10.724439",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.715027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, numeric_data, categorical_data, data_loader, is_test_data):\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if is_test_data:\n",
    "            for numeric_data, categorical_data in data_loader:\n",
    "                outputs = get_outputs(model, numeric_data, categorical_data)\n",
    "                predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "        else:\n",
    "            for numeric_data, categorical_data, _ in data_loader:\n",
    "                outputs = get_outputs(model, numeric_data, categorical_data)\n",
    "                predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed9828",
   "metadata": {
    "papermill": {
     "duration": 0.003534,
     "end_time": "2025-08-28T13:22:10.731595",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.728061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Stratified K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c477ffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.740174Z",
     "iopub.status.busy": "2025-08-28T13:22:10.739568Z",
     "iopub.status.idle": "2025-08-28T13:22:10.742824Z",
     "shell.execute_reply": "2025-08-28T13:22:10.742156Z"
    },
    "papermill": {
     "duration": 0.008841,
     "end_time": "2025-08-28T13:22:10.744034",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.735193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfold_num_splits = 10\n",
    "batch_size = 1024\n",
    "max_epochs = 5\n",
    "patience = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d10d9120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:22:10.752422Z",
     "iopub.status.busy": "2025-08-28T13:22:10.752229Z",
     "iopub.status.idle": "2025-08-28T13:28:51.235376Z",
     "shell.execute_reply": "2025-08-28T13:28:51.234584Z"
    },
    "papermill": {
     "duration": 400.489016,
     "end_time": "2025-08-28T13:28:51.236718",
     "exception": false,
     "start_time": "2025-08-28T13:22:10.747702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Training Fold 1 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95400\n",
      "Final ROC AUC score for Fold 1: 0.96336\n",
      "\n",
      "##### Training Fold 2 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95595\n",
      "Final ROC AUC score for Fold 2: 0.96344\n",
      "\n",
      "##### Training Fold 3 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00021, Validation AUC Score: 0.95437\n",
      "Final ROC AUC score for Fold 3: 0.96215\n",
      "\n",
      "##### Training Fold 4 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95570\n",
      "Final ROC AUC score for Fold 4: 0.96428\n",
      "\n",
      "##### Training Fold 5 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95692\n",
      "Final ROC AUC score for Fold 5: 0.96310\n",
      "\n",
      "##### Training Fold 6 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95299\n",
      "Final ROC AUC score for Fold 6: 0.96278\n",
      "\n",
      "##### Training Fold 7 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.94923\n",
      "Final ROC AUC score for Fold 7: 0.96199\n",
      "\n",
      "##### Training Fold 8 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95282\n",
      "Final ROC AUC score for Fold 8: 0.96365\n",
      "\n",
      "##### Training Fold 9 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95539\n",
      "Final ROC AUC score for Fold 9: 0.96377\n",
      "\n",
      "##### Training Fold 10 of 10 #####\n",
      "\n",
      "(Max epochs: 5)\n",
      "[Epoch 1] Training Loss: 0.00022, Validation AUC Score: 0.95461\n",
      "Final ROC AUC score for Fold 10: 0.96304\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=kfold_num_splits, shuffle=True, random_state=random_seed)\n",
    "kfold_splits = kfold.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "kfold_splits_enumeration = enumerate(kfold_splits)\n",
    "\n",
    "oof_predictions = np.zeros(len(train_data))\n",
    "test_predictions = np.zeros(len(test_data))\n",
    "\n",
    "# will be used later for getting values for 'num_embeddings'\n",
    "train_test_combined = pd.concat([train_data.drop(target_col, axis=1), test_data], axis=0)\n",
    "\n",
    "for fold, (train_indices, validation_indices) in kfold_splits_enumeration:\n",
    "    print(f\"\\n##### Training Fold {fold + 1} of {kfold_num_splits} #####\\n\")\n",
    "\n",
    "    # get data loaders for training, validation and test data\n",
    "    train_loader, validation_loader, test_loader = get_data_loaders(train_indices, validation_indices)\n",
    "\n",
    "    # will be used later for ROC AUC score calculation\n",
    "    y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "    # PyTorch model\n",
    "    model = BankModel(\n",
    "        len(numeric_col_names),\n",
    "        train_test_combined[categorical_col_names].nunique(), # `num_embeddings` Embedding parameter\n",
    "        32 # `embedding_dim` Embedding parameter\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
    "\n",
    "    best_validation_auc_score = 0\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    print(f\"(Max epochs: {max_epochs})\")\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        loss_train = 0\n",
    "        for numeric_data, categorical_data, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = get_outputs(model, numeric_data, categorical_data)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        validation_predictions = get_predictions(model, numeric_data, categorical_data, validation_loader, False)\n",
    "        current_validation_auc_score = roc_auc_score(y_validation_fold, validation_predictions)\n",
    "        if epoch % 25 == 0:\n",
    "            print(f\"[Epoch {epoch + 1}] Training Loss: {loss_train / len(train_indices):.5f}, Validation AUC Score: {current_validation_auc_score:.5f}\")\n",
    "\n",
    "        if current_validation_auc_score > best_validation_auc_score:\n",
    "            best_validation_auc_score = current_validation_auc_score\n",
    "            early_stopping_counter = 0\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Stopping early - {patience} epochs passed without improvement in best validation ROC AUC score.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "    model.eval()\n",
    "    validation_predictions = get_predictions(model, numeric_data, categorical_data, validation_loader, False)\n",
    "\n",
    "    oof_predictions[validation_indices] = np.array(validation_predictions)\n",
    "    final_fold_roc_auc_score = roc_auc_score(y_validation_fold, oof_predictions[validation_indices])\n",
    "    print(f\"Final ROC AUC score for Fold {fold + 1}: {final_fold_roc_auc_score:.5f}\")\n",
    "\n",
    "    # Make predictions on test data\n",
    "    test_predictions_fold = get_predictions(model, numeric_data, categorical_data, test_loader, True)\n",
    "    test_predictions += np.array(test_predictions_fold) / kfold_num_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35ae9ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:28:51.248768Z",
     "iopub.status.busy": "2025-08-28T13:28:51.248134Z",
     "iopub.status.idle": "2025-08-28T13:28:51.603576Z",
     "shell.execute_reply": "2025-08-28T13:28:51.602803Z"
    },
    "papermill": {
     "duration": 0.362615,
     "end_time": "2025-08-28T13:28:51.604819",
     "exception": false,
     "start_time": "2025-08-28T13:28:51.242204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross Validation ROC AUC: 0.96309\n"
     ]
    }
   ],
   "source": [
    "# calculate the ROC AUC score for all Out-Of-Fold predictions\n",
    "oof_roc_auc_score = roc_auc_score(train_data[target_col], oof_predictions)\n",
    "print(f\"{kfold_num_splits}-Fold Cross Validation ROC AUC: {oof_roc_auc_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e5dba",
   "metadata": {
    "papermill": {
     "duration": 0.005163,
     "end_time": "2025-08-28T13:28:51.615563",
     "exception": false,
     "start_time": "2025-08-28T13:28:51.610400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b523e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T13:28:51.629162Z",
     "iopub.status.busy": "2025-08-28T13:28:51.628527Z",
     "iopub.status.idle": "2025-08-28T13:28:52.128394Z",
     "shell.execute_reply": "2025-08-28T13:28:52.127590Z"
    },
    "papermill": {
     "duration": 0.506873,
     "end_time": "2025-08-28T13:28:52.129665",
     "exception": false,
     "start_time": "2025-08-28T13:28:51.622792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file prepared.\n"
     ]
    }
   ],
   "source": [
    "# Prepare submission\n",
    "submission = pd.DataFrame({'id': test_data.index, 'y': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file prepared.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12937777,
     "sourceId": 91719,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 427.356698,
   "end_time": "2025-08-28T13:28:54.711987",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-28T13:21:47.355289",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
