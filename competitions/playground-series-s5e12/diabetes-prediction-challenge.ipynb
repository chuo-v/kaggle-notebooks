{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d56b284",
   "metadata": {
    "papermill": {
     "duration": 0.008572,
     "end_time": "2025-12-05T00:36:14.658570",
     "exception": false,
     "start_time": "2025-12-05T00:36:14.649998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Overview\n",
    "\n",
    "This is a notebook for training models to submit predictions to the \"Diabetes Prediction Challenge\" Kaggle competition ([playground-series-s5e12](https://www.kaggle.com/competitions/playground-series-s5e12)).\n",
    "\n",
    "Synthetic data is used for this playground competition, and the objective is to, for each patient in the test set, predict the probability that the patient will be diagnosed with diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed563af",
   "metadata": {
    "papermill": {
     "duration": 0.006645,
     "end_time": "2025-12-05T00:36:14.672774",
     "exception": false,
     "start_time": "2025-12-05T00:36:14.666129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Setup\n",
    "\n",
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7b1959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:14.687819Z",
     "iopub.status.busy": "2025-12-05T00:36:14.687545Z",
     "iopub.status.idle": "2025-12-05T00:36:23.390826Z",
     "shell.execute_reply": "2025-12-05T00:36:23.390201Z"
    },
    "papermill": {
     "duration": 8.712614,
     "end_time": "2025-12-05T00:36:23.392230",
     "exception": false,
     "start_time": "2025-12-05T00:36:14.679616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "import hashlib as hl # for StackingEstimator\n",
    "import inspect # for StackingEstimator\n",
    "import random\n",
    "import warnings\n",
    "from catboost import CatBoostClassifier\n",
    "from enum import Enum\n",
    "from pathlib import Path # for StackingPredictionsRetriever\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from types import FunctionType\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) # Display full column content\n",
    "pd.set_option('display.max_rows', None) # Display all rows\n",
    "pd.set_option('display.width', 1000) # Set larger display width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024b400",
   "metadata": {
    "papermill": {
     "duration": 0.007454,
     "end_time": "2025-12-05T00:36:23.406944",
     "exception": false,
     "start_time": "2025-12-05T00:36:23.399490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Reproducibility\n",
    "\n",
    "For reproducibility of results, an arbitrary number will be used for the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476f6d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:23.421847Z",
     "iopub.status.busy": "2025-12-05T00:36:23.421202Z",
     "iopub.status.idle": "2025-12-05T00:36:23.473037Z",
     "shell.execute_reply": "2025-12-05T00:36:23.472209Z"
    },
    "papermill": {
     "duration": 0.060751,
     "end_time": "2025-12-05T00:36:23.474402",
     "exception": false,
     "start_time": "2025-12-05T00:36:23.413651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEEDS = [11, 42]\n",
    "random.seed(RANDOM_SEEDS[0])\n",
    "np.random.seed(RANDOM_SEEDS[0])\n",
    "torch.manual_seed(RANDOM_SEEDS[0])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEEDS[0])\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEEDS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ae947",
   "metadata": {
    "papermill": {
     "duration": 0.00682,
     "end_time": "2025-12-05T00:36:23.488134",
     "exception": false,
     "start_time": "2025-12-05T00:36:23.481314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3 DataFrames\n",
    "\n",
    "Read the data provided for the competition into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206be369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:23.502875Z",
     "iopub.status.busy": "2025-12-05T00:36:23.502156Z",
     "iopub.status.idle": "2025-12-05T00:36:26.087364Z",
     "shell.execute_reply": "2025-12-05T00:36:26.086567Z"
    },
    "papermill": {
     "duration": 2.594215,
     "end_time": "2025-12-05T00:36:26.088937",
     "exception": false,
     "start_time": "2025-12-05T00:36:23.494722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '/kaggle/input'\n",
    "orig_train_data = pd.read_csv(os.path.join(INPUT_DIR, 'playground-series-s5e12/train.csv'))\n",
    "orig_test_data = pd.read_csv(os.path.join(INPUT_DIR, 'playground-series-s5e12/test.csv'))\n",
    "\n",
    "# set index\n",
    "orig_train_data.set_index('id', inplace=True)\n",
    "orig_test_data.set_index('id', inplace=True)\n",
    "\n",
    "# target column\n",
    "target_col = \"diagnosed_diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13638276",
   "metadata": {
    "papermill": {
     "duration": 0.006674,
     "end_time": "2025-12-05T00:36:26.102669",
     "exception": false,
     "start_time": "2025-12-05T00:36:26.095995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daca9075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:26.117105Z",
     "iopub.status.busy": "2025-12-05T00:36:26.116892Z",
     "iopub.status.idle": "2025-12-05T00:36:26.120252Z",
     "shell.execute_reply": "2025-12-05T00:36:26.119582Z"
    },
    "papermill": {
     "duration": 0.012034,
     "end_time": "2025-12-05T00:36:26.121351",
     "exception": false,
     "start_time": "2025-12-05T00:36:26.109317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip the generation of plots (e.g. KDE) in this section that take time; set to False to generate the plots \n",
    "SKIP_PLOTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce4895b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:26.135763Z",
     "iopub.status.busy": "2025-12-05T00:36:26.135192Z",
     "iopub.status.idle": "2025-12-05T00:36:26.629743Z",
     "shell.execute_reply": "2025-12-05T00:36:26.628935Z"
    },
    "papermill": {
     "duration": 0.502948,
     "end_time": "2025-12-05T00:36:26.630892",
     "exception": false,
     "start_time": "2025-12-05T00:36:26.127944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.359734</td>\n",
       "      <td>2.072411</td>\n",
       "      <td>80.230803</td>\n",
       "      <td>5.963695</td>\n",
       "      <td>7.002200</td>\n",
       "      <td>6.012733</td>\n",
       "      <td>25.874684</td>\n",
       "      <td>0.858766</td>\n",
       "      <td>116.294193</td>\n",
       "      <td>75.440924</td>\n",
       "      <td>70.167749</td>\n",
       "      <td>186.818801</td>\n",
       "      <td>53.823214</td>\n",
       "      <td>102.905854</td>\n",
       "      <td>123.081850</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.181990</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>0.623296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.655520</td>\n",
       "      <td>1.048189</td>\n",
       "      <td>51.195071</td>\n",
       "      <td>1.463336</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>2.022707</td>\n",
       "      <td>2.860705</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>11.010390</td>\n",
       "      <td>6.825775</td>\n",
       "      <td>6.938722</td>\n",
       "      <td>16.730832</td>\n",
       "      <td>8.266545</td>\n",
       "      <td>19.022416</td>\n",
       "      <td>24.739397</td>\n",
       "      <td>0.356484</td>\n",
       "      <td>0.385837</td>\n",
       "      <td>0.171478</td>\n",
       "      <td>0.484560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  alcohol_consumption_per_week  physical_activity_minutes_per_week     diet_score  sleep_hours_per_day  screen_time_hours_per_day            bmi  waist_to_hip_ratio    systolic_bp   diastolic_bp     heart_rate  cholesterol_total  hdl_cholesterol  ldl_cholesterol  triglycerides  family_history_diabetes  hypertension_history  cardiovascular_history  diagnosed_diabetes\n",
       "count  700000.000000                 700000.000000                       700000.000000  700000.000000        700000.000000              700000.000000  700000.000000       700000.000000  700000.000000  700000.000000  700000.000000      700000.000000    700000.000000    700000.000000  700000.000000            700000.000000         700000.000000           700000.000000       700000.000000\n",
       "mean       50.359734                      2.072411                           80.230803       5.963695             7.002200                   6.012733      25.874684            0.858766     116.294193      75.440924      70.167749         186.818801        53.823214       102.905854     123.081850                 0.149401              0.181990                0.030324            0.623296\n",
       "std        11.655520                      1.048189                           51.195071       1.463336             0.901907                   2.022707       2.860705            0.037980      11.010390       6.825775       6.938722          16.730832         8.266545        19.022416      24.739397                 0.356484              0.385837                0.171478            0.484560\n",
       "min        19.000000                      1.000000                            1.000000       0.100000             3.100000                   0.600000      15.100000            0.680000      91.000000      51.000000      42.000000         117.000000        21.000000        51.000000      31.000000                 0.000000              0.000000                0.000000            0.000000\n",
       "25%        42.000000                      1.000000                           49.000000       5.000000             6.400000                   4.600000      23.900000            0.830000     108.000000      71.000000      65.000000         175.000000        48.000000        89.000000     106.000000                 0.000000              0.000000                0.000000            0.000000\n",
       "50%        50.000000                      2.000000                           71.000000       6.000000             7.000000                   6.000000      25.900000            0.860000     116.000000      75.000000      70.000000         187.000000        54.000000       103.000000     123.000000                 0.000000              0.000000                0.000000            1.000000\n",
       "75%        58.000000                      3.000000                           96.000000       7.000000             7.600000                   7.400000      27.800000            0.880000     124.000000      80.000000      75.000000         199.000000        59.000000       116.000000     139.000000                 0.000000              0.000000                0.000000            1.000000\n",
       "max        89.000000                      9.000000                          747.000000       9.900000             9.900000                  16.500000      38.400000            1.050000     163.000000     104.000000     101.000000         289.000000        90.000000       205.000000     290.000000                 1.000000              1.000000                1.000000            1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8706e32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:26.646069Z",
     "iopub.status.busy": "2025-12-05T00:36:26.645846Z",
     "iopub.status.idle": "2025-12-05T00:36:26.847048Z",
     "shell.execute_reply": "2025-12-05T00:36:26.846283Z"
    },
    "papermill": {
     "duration": 0.210029,
     "end_time": "2025-12-05T00:36:26.848242",
     "exception": false,
     "start_time": "2025-12-05T00:36:26.638213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.432397</td>\n",
       "      <td>2.089693</td>\n",
       "      <td>92.349087</td>\n",
       "      <td>5.945838</td>\n",
       "      <td>6.997795</td>\n",
       "      <td>6.011278</td>\n",
       "      <td>25.881906</td>\n",
       "      <td>0.859007</td>\n",
       "      <td>116.374117</td>\n",
       "      <td>75.396013</td>\n",
       "      <td>70.048350</td>\n",
       "      <td>187.308620</td>\n",
       "      <td>53.813557</td>\n",
       "      <td>103.416083</td>\n",
       "      <td>123.538480</td>\n",
       "      <td>0.152920</td>\n",
       "      <td>0.184410</td>\n",
       "      <td>0.033110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.938741</td>\n",
       "      <td>1.066214</td>\n",
       "      <td>62.187399</td>\n",
       "      <td>1.481068</td>\n",
       "      <td>0.914693</td>\n",
       "      <td>2.060472</td>\n",
       "      <td>2.894289</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>11.252146</td>\n",
       "      <td>6.950340</td>\n",
       "      <td>7.090543</td>\n",
       "      <td>18.413053</td>\n",
       "      <td>8.398126</td>\n",
       "      <td>20.571855</td>\n",
       "      <td>28.965441</td>\n",
       "      <td>0.359911</td>\n",
       "      <td>0.387819</td>\n",
       "      <td>0.178924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>38.300000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  alcohol_consumption_per_week  physical_activity_minutes_per_week     diet_score  sleep_hours_per_day  screen_time_hours_per_day            bmi  waist_to_hip_ratio    systolic_bp   diastolic_bp     heart_rate  cholesterol_total  hdl_cholesterol  ldl_cholesterol  triglycerides  family_history_diabetes  hypertension_history  cardiovascular_history\n",
       "count  300000.000000                 300000.000000                       300000.000000  300000.000000        300000.000000              300000.000000  300000.000000       300000.000000  300000.000000  300000.000000  300000.000000      300000.000000    300000.000000    300000.000000  300000.000000            300000.000000         300000.000000           300000.000000\n",
       "mean       50.432397                      2.089693                           92.349087       5.945838             6.997795                   6.011278      25.881906            0.859007     116.374117      75.396013      70.048350         187.308620        53.813557       103.416083     123.538480                 0.152920              0.184410                0.033110\n",
       "std        11.938741                      1.066214                           62.187399       1.481068             0.914693                   2.060472       2.894289            0.038523      11.252146       6.950340       7.090543          18.413053         8.398126        20.571855      28.965441                 0.359911              0.387819                0.178924\n",
       "min        19.000000                      1.000000                            1.000000       0.100000             3.100000                   0.600000      15.100000            0.690000      91.000000      51.000000      42.000000         107.000000        22.000000        51.000000      31.000000                 0.000000              0.000000                0.000000\n",
       "25%        42.000000                      1.000000                           51.000000       5.000000             6.400000                   4.600000      23.900000            0.830000     108.000000      71.000000      65.000000         174.000000        48.000000        89.000000     104.000000                 0.000000              0.000000                0.000000\n",
       "50%        50.000000                      2.000000                           77.000000       6.000000             7.000000                   6.000000      25.900000            0.860000     116.000000      75.000000      70.000000         187.000000        54.000000       103.000000     123.000000                 0.000000              0.000000                0.000000\n",
       "75%        59.000000                      3.000000                          115.000000       7.000000             7.600000                   7.400000      27.800000            0.890000     124.000000      80.000000      75.000000         200.000000        60.000000       117.000000     142.000000                 0.000000              0.000000                0.000000\n",
       "max        89.000000                      9.000000                          748.000000       9.900000             9.900000                  15.900000      38.300000            1.050000     170.000000     104.000000     101.000000         285.000000        91.000000       226.000000     290.000000                 1.000000              1.000000                1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9a5451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:26.864164Z",
     "iopub.status.busy": "2025-12-05T00:36:26.863935Z",
     "iopub.status.idle": "2025-12-05T00:36:26.993314Z",
     "shell.execute_reply": "2025-12-05T00:36:26.992479Z"
    },
    "papermill": {
     "duration": 0.138946,
     "end_time": "2025-12-05T00:36:26.994889",
     "exception": false,
     "start_time": "2025-12-05T00:36:26.855943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_col_names = orig_train_data.select_dtypes(include='number').columns.to_series()\n",
    "categorical_col_names = orig_train_data.select_dtypes(include='object').columns.to_series()\n",
    "assert numeric_col_names.size + categorical_col_names.size == orig_train_data.shape[1]\n",
    "\n",
    "# drop target column from numeric column names\n",
    "numeric_col_names.drop(target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe42f7e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:27.010765Z",
     "iopub.status.busy": "2025-12-05T00:36:27.010498Z",
     "iopub.status.idle": "2025-12-05T00:36:27.294170Z",
     "shell.execute_reply": "2025-12-05T00:36:27.293368Z"
    },
    "papermill": {
     "duration": 0.292872,
     "end_time": "2025-12-05T00:36:27.295287",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.002415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train data missing values #####\n",
      "age                                   0\n",
      "alcohol_consumption_per_week          0\n",
      "physical_activity_minutes_per_week    0\n",
      "diet_score                            0\n",
      "sleep_hours_per_day                   0\n",
      "screen_time_hours_per_day             0\n",
      "bmi                                   0\n",
      "waist_to_hip_ratio                    0\n",
      "systolic_bp                           0\n",
      "diastolic_bp                          0\n",
      "heart_rate                            0\n",
      "cholesterol_total                     0\n",
      "hdl_cholesterol                       0\n",
      "ldl_cholesterol                       0\n",
      "triglycerides                         0\n",
      "gender                                0\n",
      "ethnicity                             0\n",
      "education_level                       0\n",
      "income_level                          0\n",
      "smoking_status                        0\n",
      "employment_status                     0\n",
      "family_history_diabetes               0\n",
      "hypertension_history                  0\n",
      "cardiovascular_history                0\n",
      "diagnosed_diabetes                    0\n",
      "dtype: int64\n",
      "\n",
      "##### Test data missing values #####\n",
      "age                                   0\n",
      "alcohol_consumption_per_week          0\n",
      "physical_activity_minutes_per_week    0\n",
      "diet_score                            0\n",
      "sleep_hours_per_day                   0\n",
      "screen_time_hours_per_day             0\n",
      "bmi                                   0\n",
      "waist_to_hip_ratio                    0\n",
      "systolic_bp                           0\n",
      "diastolic_bp                          0\n",
      "heart_rate                            0\n",
      "cholesterol_total                     0\n",
      "hdl_cholesterol                       0\n",
      "ldl_cholesterol                       0\n",
      "triglycerides                         0\n",
      "gender                                0\n",
      "ethnicity                             0\n",
      "education_level                       0\n",
      "income_level                          0\n",
      "smoking_status                        0\n",
      "employment_status                     0\n",
      "family_history_diabetes               0\n",
      "hypertension_history                  0\n",
      "cardiovascular_history                0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (dataset_name, dataset) in [('Train data', orig_train_data), ('Test data', orig_test_data)]:\n",
    "    print(f\"##### {dataset_name} missing values #####\")\n",
    "    print(dataset.isnull().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23128676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:27.311062Z",
     "iopub.status.busy": "2025-12-05T00:36:27.310857Z",
     "iopub.status.idle": "2025-12-05T00:36:27.577268Z",
     "shell.execute_reply": "2025-12-05T00:36:27.576357Z"
    },
    "papermill": {
     "duration": 0.275675,
     "end_time": "2025-12-05T00:36:27.578591",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.302916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train data categorical cols unique values #####\n",
      "gender:\n",
      "['Female' 'Male' 'Other']\n",
      "ethnicity:\n",
      "['Hispanic' 'White' 'Asian' 'Black' 'Other']\n",
      "education_level:\n",
      "['Highschool' 'Graduate' 'Postgraduate' 'No formal']\n",
      "income_level:\n",
      "['Lower-Middle' 'Upper-Middle' 'Low' 'Middle' 'High']\n",
      "smoking_status:\n",
      "['Current' 'Never' 'Former']\n",
      "employment_status:\n",
      "['Employed' 'Retired' 'Student' 'Unemployed']\n",
      "\n",
      "##### Test data categorical cols unique values #####\n",
      "gender:\n",
      "['Female' 'Male' 'Other']\n",
      "ethnicity:\n",
      "['White' 'Hispanic' 'Black' 'Asian' 'Other']\n",
      "education_level:\n",
      "['Highschool' 'Graduate' 'Postgraduate' 'No formal']\n",
      "income_level:\n",
      "['Middle' 'Low' 'Lower-Middle' 'Upper-Middle' 'High']\n",
      "smoking_status:\n",
      "['Former' 'Never' 'Current']\n",
      "employment_status:\n",
      "['Employed' 'Unemployed' 'Retired' 'Student']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (dataset_name, dataset) in [('Train data', orig_train_data), ('Test data', orig_test_data)]:\n",
    "    print(f\"##### {dataset_name} categorical cols unique values #####\")\n",
    "    for categorical_col_name in categorical_col_names:\n",
    "        print(f\"{categorical_col_name}:\")\n",
    "        print(dataset[categorical_col_name].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241ccfa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:27.595077Z",
     "iopub.status.busy": "2025-12-05T00:36:27.594851Z",
     "iopub.status.idle": "2025-12-05T00:36:27.599585Z",
     "shell.execute_reply": "2025-12-05T00:36:27.598774Z"
    },
    "papermill": {
     "duration": 0.014491,
     "end_time": "2025-12-05T00:36:27.600831",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.586340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KDE plots of target variable and numerical features\n",
    "if not SKIP_PLOTS:\n",
    "    plt.figure(figsize=(12, 24))\n",
    "    kdeplot_col_names = [target_col]\n",
    "    kdeplot_col_names.extend(numeric_col_names)\n",
    "    for i, col in enumerate(kdeplot_col_names, start=1):\n",
    "        plt.subplot(10, 2, i)\n",
    "        sns.kdeplot(data=orig_train_data, x=col, fill=True)\n",
    "        plt.tight_layout()\n",
    "        plt.title(f\"KDE plot of {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0707841c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:27.618893Z",
     "iopub.status.busy": "2025-12-05T00:36:27.618660Z",
     "iopub.status.idle": "2025-12-05T00:36:27.623011Z",
     "shell.execute_reply": "2025-12-05T00:36:27.622398Z"
    },
    "papermill": {
     "duration": 0.014858,
     "end_time": "2025-12-05T00:36:27.624105",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.609247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SKIP_PLOTS:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        orig_train_data[numeric_col_names].corr(),\n",
    "        cmap='Reds',\n",
    "        annot=True,\n",
    "        linewidths=2,\n",
    "        fmt='.2f',\n",
    "        vmin=-1,\n",
    "        vmax=1\n",
    "    )\n",
    "    plt.title('Correlation Matrix of Numerical Features', fontsize=18, pad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53731137",
   "metadata": {
    "papermill": {
     "duration": 0.008343,
     "end_time": "2025-12-05T00:36:27.640965",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.632622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa44746d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:27.659318Z",
     "iopub.status.busy": "2025-12-05T00:36:27.658659Z",
     "iopub.status.idle": "2025-12-05T00:36:27.826695Z",
     "shell.execute_reply": "2025-12-05T00:36:27.825962Z"
    },
    "papermill": {
     "duration": 0.178994,
     "end_time": "2025-12-05T00:36:27.828222",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.649228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = orig_train_data.copy()\n",
    "test_data = orig_test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9827632",
   "metadata": {
    "papermill": {
     "duration": 0.008214,
     "end_time": "2025-12-05T00:36:27.845319",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.837105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1 Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd88f840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:27.863172Z",
     "iopub.status.busy": "2025-12-05T00:36:27.862501Z",
     "iopub.status.idle": "2025-12-05T00:36:28.752903Z",
     "shell.execute_reply": "2025-12-05T00:36:28.751808Z"
    },
    "papermill": {
     "duration": 0.900629,
     "end_time": "2025-12-05T00:36:28.754246",
     "exception": false,
     "start_time": "2025-12-05T00:36:27.853617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_level_encoded:\n",
      "{'No formal': 0, 'Highschool': 1, 'Graduate': 2, 'Postgraduate': 3}\n",
      "income_level_encoded:\n",
      "{'Low': 0, 'Lower-Middle': 1, 'Middle': 2, 'Upper-Middle': 3, 'High': 4}\n",
      "smoking_status_encoded:\n",
      "{'Never': 0, 'Former': 1, 'Current': 2}\n"
     ]
    }
   ],
   "source": [
    "# education level\n",
    "education_level_encoder = OrdinalEncoder(categories=[['No formal', 'Highschool', 'Graduate', 'Postgraduate']])\n",
    "train_data['education_level_encoded'] = education_level_encoder.fit_transform(train_data[['education_level']])\n",
    "test_data['education_level_encoded'] = education_level_encoder.fit_transform(test_data[['education_level']])\n",
    "\n",
    "# income level\n",
    "income_level_encoder = OrdinalEncoder(categories=[['Low', 'Lower-Middle','Middle', 'Upper-Middle', 'High']])\n",
    "train_data['income_level_encoded'] = income_level_encoder.fit_transform(train_data[['income_level']])\n",
    "test_data['income_level_encoded'] = income_level_encoder.fit_transform(test_data[['income_level']])\n",
    "\n",
    "# smoking status\n",
    "smoking_status_encoder = OrdinalEncoder(categories=[['Never', 'Former', 'Current']])\n",
    "train_data['smoking_status_encoded'] = smoking_status_encoder.fit_transform(train_data[['smoking_status']])\n",
    "test_data['smoking_status_encoded'] = smoking_status_encoder.fit_transform(test_data[['smoking_status']])\n",
    "\n",
    "# drop original cols\n",
    "for col in ['income_level', 'education_level', 'smoking_status']:\n",
    "    train_data.drop(col, axis=1, inplace=True)\n",
    "    test_data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# print out value maps to check assigned values are as expected\n",
    "for (encoded_col_name, encoder) in [\n",
    "    ('education_level_encoded', education_level_encoder),\n",
    "    ('income_level_encoded', income_level_encoder),\n",
    "    ('smoking_status_encoded', smoking_status_encoder),\n",
    "]:\n",
    "    categories = encoder.categories_[0]\n",
    "    value_map = { category: i for i, category in enumerate(categories) }\n",
    "    print(f\"{encoded_col_name}:\\n{value_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b2266",
   "metadata": {
    "papermill": {
     "duration": 0.009532,
     "end_time": "2025-12-05T00:36:28.772942",
     "exception": false,
     "start_time": "2025-12-05T00:36:28.763410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f26814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:28.791529Z",
     "iopub.status.busy": "2025-12-05T00:36:28.791232Z",
     "iopub.status.idle": "2025-12-05T00:36:28.808291Z",
     "shell.execute_reply": "2025-12-05T00:36:28.807487Z"
    },
    "papermill": {
     "duration": 0.02783,
     "end_time": "2025-12-05T00:36:28.809841",
     "exception": false,
     "start_time": "2025-12-05T00:36:28.782011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_blood_pressure(df):\n",
    "    mask = df['diastolic_bp'] > df['systolic_bp']\n",
    "    df.loc[mask, ['systolic_bp', 'diastolic_bp']] = (\n",
    "        df.loc[mask, ['diastolic_bp', 'systolic_bp']].values\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_data = fix_blood_pressure(train_data)\n",
    "test_data = fix_blood_pressure(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2809c",
   "metadata": {
    "papermill": {
     "duration": 0.009236,
     "end_time": "2025-12-05T00:36:28.828765",
     "exception": false,
     "start_time": "2025-12-05T00:36:28.819529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4 Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "368c4a54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:28.848720Z",
     "iopub.status.busy": "2025-12-05T00:36:28.848132Z",
     "iopub.status.idle": "2025-12-05T00:36:28.936793Z",
     "shell.execute_reply": "2025-12-05T00:36:28.936118Z"
    },
    "papermill": {
     "duration": 0.1003,
     "end_time": "2025-12-05T00:36:28.938276",
     "exception": false,
     "start_time": "2025-12-05T00:36:28.837976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_generated_features(df):\n",
    "    # medical ratios & interactions\n",
    "    df['cholesterol_ratio'] = df['cholesterol_total'] / df['hdl_cholesterol']\n",
    "    df['pulse_pressure'] = df['systolic_bp'] - df['diastolic_bp']\n",
    "    df['age_bmi_interaction'] = df['bmi'] * df['age']\n",
    "\n",
    "    # risk grouping\n",
    "    df['comorbidity_count'] = (\n",
    "        df['hypertension_history'] + \n",
    "        df['cardiovascular_history'] + \n",
    "        df['family_history_diabetes']\n",
    "    )\n",
    "\n",
    "    # log transforms for skewed data\n",
    "    for col in ['triglycerides', 'ldl_cholesterol', 'cholesterol_total']:\n",
    "        df[f'log_{col}'] = np.log1p(df[col])\n",
    "\n",
    "    # binning\n",
    "    df['bmi_cat'] = pd.cut(df['bmi'], bins=[-1, 25, 30, 100], labels=[0, 1, 2]).astype(int)\n",
    "\n",
    "add_generated_features(train_data)\n",
    "add_generated_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a04d6",
   "metadata": {
    "papermill": {
     "duration": 0.007962,
     "end_time": "2025-12-05T00:36:28.955373",
     "exception": false,
     "start_time": "2025-12-05T00:36:28.947411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4 Remaining Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ba70c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:28.972577Z",
     "iopub.status.busy": "2025-12-05T00:36:28.971945Z",
     "iopub.status.idle": "2025-12-05T00:36:29.245061Z",
     "shell.execute_reply": "2025-12-05T00:36:29.244463Z"
    },
    "papermill": {
     "duration": 0.283248,
     "end_time": "2025-12-05T00:36:29.246515",
     "exception": false,
     "start_time": "2025-12-05T00:36:28.963267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_features = train_data.drop(target_col, axis=1).select_dtypes(include='object').columns.to_list()\n",
    "if len(cat_features) > 0:\n",
    "    for col in cat_features:\n",
    "        train_data[col] = train_data[col].astype('category')\n",
    "        test_data[col] = test_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da37d969",
   "metadata": {
    "papermill": {
     "duration": 0.00788,
     "end_time": "2025-12-05T00:36:29.262956",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.255076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Stacking Initial Setup\n",
    "\n",
    "We'll use stacking, an [ensemble learning](https://en.wikipedia.org/wiki/Ensemble_learning) strategy, to generate the predictions. As we'll need to gather predictions from various base models (a.k.a. level-0 models) to feed as input features to a meta model (a.k.a. level-1 model), in order to streamline the process of experimenting with different combinations of base models, some helper classes will be defined in this section. These classes can also be found [here](https://github.com/chuo-v/machine-learning-utils/blob/master/ensemble-learning/stacking/stacking_predictions_retriever.py) at one of my GitHub repositories used to organize some utilities I implemented for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07e9360c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:29.280702Z",
     "iopub.status.busy": "2025-12-05T00:36:29.280231Z",
     "iopub.status.idle": "2025-12-05T00:36:29.307628Z",
     "shell.execute_reply": "2025-12-05T00:36:29.306900Z"
    },
    "papermill": {
     "duration": 0.037979,
     "end_time": "2025-12-05T00:36:29.308824",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.270845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackingEstimator:\n",
    "    \"\"\"\n",
    "    A class representing an estimator that will be used for stacking, an ensemble learning strategy.\n",
    "\n",
    "    Intended to be used in conjunction with the `StackingPredictionsRetriever` class, which helps\n",
    "    retrieve predictions for multiple instances of `StackingEstimator`; as the predictions are saved\n",
    "    in files, on subsequent requests to retrieve predictions, even as the set of estimators has been\n",
    "    modified, the `StackingPredictionsRetriever` class can determine the predictions of estimators\n",
    "    that are non-stale and available (if any) by using the `get_hash` method of the `StackingEstimator`\n",
    "    class to determine the relevance and staleness of any saved predictions.\n",
    "\n",
    "    Proper usage of this class requires one important condition to be satisfied: the predictions made\n",
    "    using the estimator are determinstic, i.e. they are exactly the same everytime the estimator is\n",
    "    run with the same inputs (`name`, `params_dict`, `feature_names`, `get_predictions`).\n",
    "    \"\"\"\n",
    "    name = \"\"\n",
    "    params_dict = {}\n",
    "    feature_names = []\n",
    "    get_predictions = lambda: None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        feature_names: [str],\n",
    "        params_dict: {},\n",
    "        get_preds: FunctionType\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of `StackingEstimator`.\n",
    "\n",
    "        :param name:\n",
    "            A string representing a name for the estimator. It is used for the column names of\n",
    "            the training and test predictions for each estimator, and is also used as an input\n",
    "            to calculate a hash value for the estimator. It is recommended to use a different\n",
    "            name from the names used for other estimators passed to `StackingPredictionsRetriever`.\n",
    "        :param feature_names:\n",
    "            A list of strings representing the names of the features that will be used for the\n",
    "            estimator. It will be passed as an argument to `get_preds`. Internally, it is only\n",
    "            used as an input to calculate a hash value for the estimator.\n",
    "        :param params_dict:\n",
    "            A dictionary of parameters that will be specified for the estimator. It will be\n",
    "            passed as an argument to `get_preds`. Internally, it is only used as an input\n",
    "            to calculate a hash value for the estimator.\n",
    "        :param get_preds:\n",
    "            A function for getting the predictions for the estimator. It should only take two\n",
    "            arguments: 'params_dict' and 'feature_names', and should return predictions for\n",
    "            the training and test data (in that order) as a tuple of two `pandas.Series`.\n",
    "        \"\"\"\n",
    "        # parameter check\n",
    "        if not isinstance(name, str):\n",
    "            raise ValueError(\"`name` argument should be of type `str`\")\n",
    "        if not isinstance(feature_names, list):\n",
    "            raise ValueError(f\"`feature_names` argument for estimator \\\"{name}\\\" should be of type `list`\")\n",
    "        elif not all(isinstance(feature_name, str) for feature_name in feature_names):\n",
    "            raise ValueError(f\"`feature_names` argument for estimator \\\"{name}\\\" should only contain instances of `str`\")\n",
    "        if not isinstance(params_dict, dict):\n",
    "            raise ValueError(f\"`params_dict` argument for estimator \\\"{name}\\\" should be of type `dict`\")\n",
    "        get_preds_params = inspect.signature(get_preds).parameters.values()\n",
    "        get_preds_param_names = [param.name for param in get_preds_params]\n",
    "        if len(get_preds_param_names) != 2:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take two arguments\")\n",
    "        elif \"params_dict\" not in get_preds_param_names:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take a \\\"params_dict\\\" argument\")\n",
    "        elif \"feature_names\" not in get_preds_param_names:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take a \\\"feature_names\\\" argument\")\n",
    "\n",
    "        self.name = name\n",
    "        self.feature_names = feature_names\n",
    "        self.params_dict = params_dict\n",
    "        self.get_preds = get_preds\n",
    "\n",
    "    def get_hash_value(self):\n",
    "        \"\"\"\n",
    "        Calculates and returns a hash value for the estimator using\n",
    "        `name`, `feature_names` and `params_dict` as inputs.\n",
    "        \"\"\"\n",
    "        feature_names_str = \"_\".join(sorted(self.feature_names))\n",
    "        params_dict_str = \"_\".join(f\"{key}-{value}\" for (key, value) in sorted(self.params_dict.items()))\n",
    "        hash_input_str = \"_\".join([self.name, feature_names_str, params_dict_str])\n",
    "        md5_hash = hl.md5(hash_input_str.encode('utf-8')).hexdigest()\n",
    "        return md5_hash\n",
    "\n",
    "class StackingPredictionsRetriever:\n",
    "    \"\"\"\n",
    "    A class for streamlining stacking (an ensemble learning strategy) that saves predictions\n",
    "    from estimators to file so that when trying out different combinations of (base) estimators,\n",
    "    the predictions that are not stale can be reused, saving the time of having the estimators\n",
    "    make predictions again.\n",
    "\n",
    "    Intended to be used in conjunction with the `StackingEstimator` class. The `hash_value` of\n",
    "    `StackingEstimator` is used to determine the staleness and relevance of the predictions for\n",
    "    an estimator. The implementation for making predictions using an estimator needs to be\n",
    "    provided as a function to `get_preds` for `StackingEstimator`; when predictions need to be\n",
    "    made using an estimator, this class will call `get_preds` for the `StackingEstimator` instance.\n",
    "\n",
    "    Proper usage of this class requires one important condition to be satisfied: the predictions made\n",
    "    using the estimators are determinstic, i.e. they are exactly the same everytime a\n",
    "    `StackingEstimator` instance is run with the same inputs.\n",
    "    \"\"\"\n",
    "    estimators = []\n",
    "    working_dir_path = \"\"\n",
    "    train_preds_filename = \"\"\n",
    "    test_preds_filename = \"\"\n",
    "    preds_save_interval = 0\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators: [StackingEstimator],\n",
    "        working_dir_path: str,\n",
    "        train_preds_filename: str = \"train_preds\",\n",
    "        test_preds_filename: str = \"test_preds\",\n",
    "        preds_save_interval: int = 5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of `StackingPredictionsRetriever`.\n",
    "\n",
    "        :param estimators:\n",
    "            A list of `StackingEstimator` instances for which the class will retrieve predictions.\n",
    "        :param working_dir_path:\n",
    "            The path for the working directory where the files with predictions will be saved.\n",
    "        :param train_preds_filename:\n",
    "            The name of the file in which predictions for the training set will be stored.\n",
    "        :param test_preds_filename:\n",
    "            The name of the file in which predictions for the test set will be stored.\n",
    "        :param preds_save_interval:\n",
    "            An integer which specifies the interval at which predictions will be saved when\n",
    "            `get_preds` is called, corresponding to the number of estimators whose predictions\n",
    "            have been retrieved since the predictions were previously saved. Any estimators\n",
    "            whose predictions are not stale and therefore were not required to make predictions\n",
    "            again are not included in this number.\n",
    "        \"\"\"\n",
    "        # parameter check\n",
    "        if not isinstance(estimators, list):\n",
    "            raise ValueError(\"`estimators` must be passed as a list\")\n",
    "        if not all(isinstance(e, StackingEstimator) for e in estimators):\n",
    "            raise ValueError(\"`estimators` should only contain instances of `StackingEstimator`\")\n",
    "        if not isinstance(working_dir_path, str):\n",
    "            raise ValueError(\"`working_dir_path` argument should be of type `str`\")\n",
    "        if not isinstance(preds_save_interval, int):\n",
    "            raise ValueError(\"`preds_save_interval` argument should be of type `int`\")\n",
    "\n",
    "        self.estimators = estimators\n",
    "        self.working_dir_path = working_dir_path\n",
    "        self.train_preds_filename = train_preds_filename\n",
    "        self.test_preds_filename = test_preds_filename\n",
    "        self.preds_save_interval = preds_save_interval\n",
    "\n",
    "    def get_train_preds_file_path(self):\n",
    "        \"\"\"\n",
    "        Returns the file path for storing predictions for training data.\n",
    "        \"\"\"\n",
    "        return Path(f\"{self.working_dir_path}/{self.train_preds_filename}.csv\")\n",
    "\n",
    "    def get_test_preds_file_path(self):\n",
    "        \"\"\"\n",
    "        Returns the file path for storing predictions for test data.\n",
    "        \"\"\"\n",
    "        return Path(f\"{self.working_dir_path}/{self.test_preds_filename}.csv\")\n",
    "\n",
    "    def get_current_train_and_test_preds(self):\n",
    "        \"\"\"\n",
    "        Returns the current predictions for training and test data (in that order)\n",
    "        as a tuple of two `pandas.DataFrame`.\n",
    "\n",
    "        The predictions are attempted to be retrieved from the file paths returned\n",
    "        by `get_train_preds_file_path` and `get_test_preds_file_path`; if there are\n",
    "        any issues with doing so (e.g. file does not exist, dataframe is empty),\n",
    "        empty dataframes will be returned instead.\n",
    "        In the case an `pandas.errors.EmptyDataError` exception is raised when\n",
    "        reading from a file, the corresponding file will be removed.\n",
    "        \"\"\"\n",
    "        curr_train_preds = pd.DataFrame()\n",
    "        curr_test_preds = pd.DataFrame()\n",
    "        train_preds_file_path = self.get_train_preds_file_path()\n",
    "        test_preds_file_path = self.get_test_preds_file_path()\n",
    "\n",
    "        if train_preds_file_path.is_file():\n",
    "            try:\n",
    "                curr_train_preds = pd.read_csv(train_preds_file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                train_preds_file_path.unlink()\n",
    "        if test_preds_file_path.is_file():\n",
    "            try:\n",
    "                curr_test_preds = pd.read_csv(test_preds_file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                test_preds_file_path.unlink()\n",
    "\n",
    "        return curr_train_preds, curr_test_preds\n",
    "\n",
    "    def get_preds(self):\n",
    "        \"\"\"\n",
    "        Retrieves predictions from all estimators in `estimators`, storing them in\n",
    "        two files at the file paths specified by `working_dir_path`,\n",
    "        `train_preds_filename` and `test_preds_filename`.\n",
    "\n",
    "        If non-stale (relevant) predictions are found for an estimator, retrieval\n",
    "        of predictions by calling `get_preds` on the estimator will be skipped,\n",
    "        and the existing predictions for the estimator will be kept.\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Getting predictions..\")\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "\n",
    "        preds_retrieved_count = 0\n",
    "        num_preds_retrieved_but_not_yet_saved = 0\n",
    "        estimators_skipped = []\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            estimator_hash_value = estimator.get_hash_value()\n",
    "            estimator_name = f\"{estimator.name} ({estimator_hash_value})\"\n",
    "\n",
    "            # skip retrieving predictions for estimator if non-stale predictions are already available\n",
    "            train_preds_available = any(estimator_hash_value in col_name for col_name in curr_train_preds.columns)\n",
    "            test_preds_available = any(estimator_hash_value in col_name for col_name in curr_test_preds.columns)\n",
    "            if train_preds_available and test_preds_available:\n",
    "                estimators_skipped += [estimator_name]\n",
    "                continue\n",
    "\n",
    "            print(f\"[INFO] Getting predictions for estimator {estimator_name}\")\n",
    "            train_preds, test_preds = estimator.get_preds(estimator.params_dict, estimator.feature_names)\n",
    "            if not isinstance(train_preds, pd.core.series.Series):\n",
    "                raise ValueError(\"`train_preds` should be of type `pandas.Series`\")\n",
    "            if not isinstance(test_preds, pd.core.series.Series):\n",
    "                raise ValueError(\"`test_preds` should be of type `pandas.Series`\")\n",
    "            curr_train_preds[estimator_name] = train_preds\n",
    "            curr_test_preds[estimator_name] = test_preds\n",
    "            preds_retrieved_count += 1\n",
    "\n",
    "            # save predictions at an interval of `preds_save_interval`\n",
    "            if preds_retrieved_count % self.preds_save_interval == 0:\n",
    "                curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "                curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "                num_preds_retrieved_but_not_yet_saved = 0\n",
    "                print(\"[INFO] Saved predictions\")\n",
    "            else:\n",
    "                num_preds_retrieved_but_not_yet_saved += 1\n",
    "\n",
    "        if estimators_skipped:\n",
    "            estimators_skipped.sort()\n",
    "            formatted_estimators = \", \".join(estimators_skipped)\n",
    "            print(f\"[INFO] Skipped retrieving predictions for following estimators as their current ones are not stale:\\n{formatted_estimators}\")\n",
    "\n",
    "        if num_preds_retrieved_but_not_yet_saved != 0:\n",
    "            curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            print(\"[INFO] Saved predictions\")\n",
    "\n",
    "        print(\"[INFO] Finished getting all predictions\")\n",
    "\n",
    "    def sync_preds(self):\n",
    "        \"\"\"\n",
    "        Syncs the predictions stored at the two file paths specified by\n",
    "        `working_dir_path`, `train_preds_filename` and `test_preds_filename` by\n",
    "        removing predictions for any estimator that is not currently in `estimators`.\n",
    "\n",
    "        Note that new predictions for estimators that do not currently have predictions\n",
    "        in the files will not be added; `get_preds` should be used for this purpose\n",
    "        instead.\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Syncing predictions..\")\n",
    "        estimator_hash_values = [estimator.get_hash_value() for estimator in self.estimators]\n",
    "        should_remove_col = lambda col_name: not any(hash_value in col_name for hash_value in estimator_hash_values)\n",
    "\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "\n",
    "        if not curr_train_preds.empty:\n",
    "            col_names_to_remove = [col_name for col_name in curr_train_preds.columns if should_remove_col(col_name)]\n",
    "            if col_names_to_remove:\n",
    "                print(f\"[INFO] Dropping columns for following estimators from training predictions:\\n{col_names_to_remove}\")\n",
    "                curr_train_preds.drop(columns=col_names_to_remove, inplace=True)\n",
    "                curr_train_preds.to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            else:\n",
    "                print(f\"[INFO] No columns for training predictions were dropped\")\n",
    "        if not curr_test_preds.empty:\n",
    "            col_names_to_remove = [col_name for col_name in curr_test_preds.columns if should_remove_col(col_name)]\n",
    "            if col_names_to_remove:\n",
    "                print(f\"[INFO] Dropping columns for following estimators from test predictions:\\n{col_names_to_remove}\")\n",
    "                curr_test_preds.drop(columns=col_names_to_remove, inplace=True)\n",
    "                curr_test_preds.to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            else:\n",
    "                print(f\"[INFO] No columns for test predictions were dropped\")\n",
    "\n",
    "        print(\"[INFO] Finished syncing predictions\")\n",
    "\n",
    "    def import_preds(self, input_dir_path):\n",
    "        \"\"\"\n",
    "        Imports predictions stored at the two file paths at `input_dir_path` with\n",
    "        `train_preds_filename` and `test_preds_filename` as their filenames. If no\n",
    "        such files are found, no predictions will be imported.\n",
    "\n",
    "        Only predictions for estimators specified in `estimators` will be imported.\n",
    "        Any predictions for estimators that were already available will be overwritten\n",
    "        with predictions for the same estimators found in the files at `input_dir_path`.\n",
    "\n",
    "        :param input_dir_path:\n",
    "            The path to the directory for the training and test predictions files.\n",
    "            The file names are expected to be the same as `train_preds_filename`\n",
    "            and `test_preds_filename`\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Importing predictions..\")\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "        input_train_preds = pd.DataFrame()\n",
    "        input_test_preds = pd.DataFrame()\n",
    "\n",
    "        input_train_preds_path = Path(f\"{input_dir_path}/{self.train_preds_filename}.csv\")\n",
    "        input_test_preds_path = Path(f\"{input_dir_path}/{self.test_preds_filename}.csv\")\n",
    "        if input_train_preds_path.is_file():\n",
    "            try:\n",
    "                input_train_preds = pd.read_csv(input_train_preds_path)\n",
    "            except: pass\n",
    "        if input_test_preds_path.is_file():\n",
    "            try:\n",
    "                input_test_preds = pd.read_csv(input_test_preds_path)\n",
    "            except: pass\n",
    "\n",
    "        estimators_with_imported_train_preds = []\n",
    "        estimators_with_imported_test_preds = []\n",
    "        for estimator in self.estimators:\n",
    "            estimator_hash_value = estimator.get_hash_value()\n",
    "            estimator_name = f\"{estimator.name} ({estimator_hash_value})\"\n",
    "            train_preds_available = any(estimator_hash_value in col_name for col_name in input_train_preds.columns)\n",
    "            test_preds_available = any(estimator_hash_value in col_name for col_name in input_test_preds.columns)\n",
    "\n",
    "            if train_preds_available:\n",
    "                curr_train_preds[estimator_name] = input_train_preds[estimator_name]\n",
    "                estimators_with_imported_train_preds += [estimator_name]\n",
    "            if test_preds_available:\n",
    "                curr_test_preds[estimator_name] = input_test_preds[estimator_name]\n",
    "                estimators_with_imported_test_preds += [estimator_name]\n",
    "\n",
    "        if not estimators_with_imported_train_preds:\n",
    "            print(\"[INFO] No train predictions were imported\")\n",
    "        else:\n",
    "            curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            formatted_estimators = \", \".join(estimators_with_imported_train_preds)\n",
    "            print(f\"[INFO] {len(estimators_with_imported_train_preds)} train predictions were imported:\\n{formatted_estimators}\")\n",
    "        if not estimators_with_imported_test_preds:\n",
    "            print(\"[INFO] No test predictions were imported\")\n",
    "        else:\n",
    "            curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            formatted_estimators = \", \".join(estimators_with_imported_test_preds)\n",
    "            print(f\"[INFO] {len(estimators_with_imported_test_preds)} test predictions were imported:\\n{formatted_estimators}\")\n",
    "        \n",
    "        print(\"[INFO] Finished importing predictions\")\n",
    "\n",
    "    def clear_preds(self):\n",
    "        \"\"\"\n",
    "        Removes all stored predictions by deleting the two files at filepaths specified\n",
    "        by `working_dir_path`, `train_preds_filename` and `test_preds_filename`.\n",
    "        \"\"\"\n",
    "        train_preds_file_path = self.get_train_preds_file_path()\n",
    "        test_preds_file_path = self.get_test_preds_file_path()\n",
    "\n",
    "        if train_preds_file_path.is_file():\n",
    "            train_preds_file_path.unlink()\n",
    "        if test_preds_file_path.is_file():\n",
    "            test_preds_file_path.unlink()\n",
    "\n",
    "        print(\"[INFO] Finished clearing predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb2e30",
   "metadata": {
    "papermill": {
     "duration": 0.007861,
     "end_time": "2025-12-05T00:36:29.324831",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.316970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we'll simply create a variable for storing the estimators (`StackingEstimator` instances) that we'll pass to the `StackingPredictionsRetriever` class for getting all the predictions from our base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f69a76be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:29.341970Z",
     "iopub.status.busy": "2025-12-05T00:36:29.341208Z",
     "iopub.status.idle": "2025-12-05T00:36:29.344681Z",
     "shell.execute_reply": "2025-12-05T00:36:29.344104Z"
    },
    "papermill": {
     "duration": 0.013037,
     "end_time": "2025-12-05T00:36:29.345829",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.332792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951006fc",
   "metadata": {
    "papermill": {
     "duration": 0.008046,
     "end_time": "2025-12-05T00:36:29.361662",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.353616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Base Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e18b6913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:29.378764Z",
     "iopub.status.busy": "2025-12-05T00:36:29.378201Z",
     "iopub.status.idle": "2025-12-05T00:36:29.381488Z",
     "shell.execute_reply": "2025-12-05T00:36:29.380957Z"
    },
    "papermill": {
     "duration": 0.012993,
     "end_time": "2025-12-05T00:36:29.382467",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.369474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip hyperparameter tuning when it's not needed; set to `False` to do the tuning\n",
    "SKIP_BASE_MODEL_HYPERPARAMETER_TUNING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9accff90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:29.399719Z",
     "iopub.status.busy": "2025-12-05T00:36:29.399237Z",
     "iopub.status.idle": "2025-12-05T00:36:29.403123Z",
     "shell.execute_reply": "2025-12-05T00:36:29.402313Z"
    },
    "papermill": {
     "duration": 0.013963,
     "end_time": "2025-12-05T00:36:29.404427",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.390464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseModelOptunaStudyEstimator(Enum):\n",
    "    CATBOOST = \"CatBoost\"\n",
    "    XGBCLASSIFIER = \"XGBClassifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f6a21",
   "metadata": {
    "papermill": {
     "duration": 0.008007,
     "end_time": "2025-12-05T00:36:29.420868",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.412861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Manually configure the values for the following variables for different studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce146065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:29.438413Z",
     "iopub.status.busy": "2025-12-05T00:36:29.437831Z",
     "iopub.status.idle": "2025-12-05T00:36:29.441367Z",
     "shell.execute_reply": "2025-12-05T00:36:29.440801Z"
    },
    "papermill": {
     "duration": 0.013626,
     "end_time": "2025-12-05T00:36:29.442464",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.428838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# estimator to use for Optuna study\n",
    "BASE_MODEL_OPTUNA_STUDY_ESTIMATOR = BaseModelOptunaStudyEstimator.CATBOOST\n",
    "\n",
    "# maximum number of trials Optuna will conduct for the optimization\n",
    "BASE_MODEL_OPTUNA_STUDY_NUM_TRIALS = 200\n",
    "\n",
    "# number of splits to use for Stratified K-Fold Cross-Validation for Optuna study\n",
    "BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "513c7228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:29.459751Z",
     "iopub.status.busy": "2025-12-05T00:36:29.459540Z",
     "iopub.status.idle": "2025-12-05T00:36:29.471995Z",
     "shell.execute_reply": "2025-12-05T00:36:29.471369Z"
    },
    "papermill": {
     "duration": 0.022422,
     "end_time": "2025-12-05T00:36:29.473054",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.450632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_base_model_optuna_params(trial, study_estimator):\n",
    "    if study_estimator == BaseModelOptunaStudyEstimator.CATBOOST:\n",
    "        return {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.1, log=True),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 30),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 30),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0, 20),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),\n",
    "        }\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER:\n",
    "        return {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'alpha': trial.suggest_float('alpha', 0.001, 10.0, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 0.001, 10.0, log=True),\n",
    "            'lambda': trial.suggest_float('lambda', 0.001, 5.0, log=True),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optuna study estimator\")\n",
    "\n",
    "def get_base_model_predictions(study_estimator, trial_params, X_train_fold, y_train_fold, X_validation_fold, y_validation_fold):\n",
    "    if study_estimator == BaseModelOptunaStudyEstimator.CATBOOST:\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=5000,\n",
    "            learning_rate=trial_params['learning_rate'],\n",
    "            depth=trial_params['depth'],\n",
    "            l2_leaf_reg=trial_params['l2_leaf_reg'],\n",
    "            bagging_temperature=trial_params['bagging_temperature'],\n",
    "            random_strength=trial_params['random_strength'],\n",
    "            min_data_in_leaf=trial_params['min_data_in_leaf'],\n",
    "            od_type='Iter',\n",
    "            od_wait=50,\n",
    "            use_best_model=True,\n",
    "            cat_features=cat_features,\n",
    "            eval_metric='AUC',\n",
    "            task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
    "            devices='0',\n",
    "            metric_period=1000,\n",
    "            random_seed=RANDOM_SEEDS[0],\n",
    "            verbose=False,\n",
    "            allow_writing_files=False\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_validation_fold, y_validation_fold),\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER:\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=5000,\n",
    "            learning_rate=trial_params['learning_rate'],\n",
    "            max_depth=trial_params['max_depth'],\n",
    "            subsample=trial_params['subsample'],\n",
    "            colsample_bytree=trial_params['colsample_bytree'],\n",
    "            alpha=trial_params['alpha'],\n",
    "            gamma=trial_params['gamma'],\n",
    "            reg_lambda=trial_params['lambda'],\n",
    "            min_child_weight=trial_params['min_child_weight'],\n",
    "            tree_method='gpu_hist' if torch.cuda.is_available() else 'auto',\n",
    "            predictor='gpu_predictor' if torch.cuda.is_available() else 'cpu_predictor',\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            enable_categorical=True,\n",
    "            eval_metric='auc',\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_SEEDS[0],\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optuna study estimator\")\n",
    "\n",
    "def base_model_optuna_study_objective(trial):\n",
    "    base_model_params = get_base_model_optuna_params(trial, BASE_MODEL_OPTUNA_STUDY_ESTIMATOR)\n",
    "\n",
    "    base_model_optuna_study_skf = StratifiedKFold(n_splits=BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS, shuffle=True, random_state=RANDOM_SEEDS[0])\n",
    "    base_model_optuna_study_skf_splits = base_model_optuna_study_skf.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "    base_model_optuna_study_skf_enumeration = enumerate(base_model_optuna_study_skf_splits)\n",
    "\n",
    "    total_roc_auc = 0\n",
    "\n",
    "    for fold, (train_indices, validation_indices) in base_model_optuna_study_skf_enumeration:\n",
    "        X_train_fold = train_data.drop(target_col, axis=1).iloc[train_indices]\n",
    "        X_validation_fold = train_data.drop(target_col, axis=1).iloc[validation_indices]\n",
    "        y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "        y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "        y_validation_pred_proba = get_base_model_predictions(\n",
    "            BASE_MODEL_OPTUNA_STUDY_ESTIMATOR,\n",
    "            base_model_params,\n",
    "            X_train_fold, y_train_fold,\n",
    "            X_validation_fold, y_validation_fold\n",
    "        )\n",
    "        roc_auc_fold = roc_auc_score(y_validation_fold, y_validation_pred_proba)\n",
    "        total_roc_auc += roc_auc_fold\n",
    "\n",
    "        trial.report(roc_auc_fold, step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    average_roc_auc = total_roc_auc / BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS\n",
    "    return average_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3e7852b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T00:36:29.490685Z",
     "iopub.status.busy": "2025-12-05T00:36:29.490230Z",
     "iopub.status.idle": "2025-12-05T10:50:16.095802Z",
     "shell.execute_reply": "2025-12-05T10:50:16.095032Z"
    },
    "papermill": {
     "duration": 36826.63294,
     "end_time": "2025-12-05T10:50:16.113740",
     "exception": false,
     "start_time": "2025-12-05T00:36:29.480800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-12-05 00:36:29,493] A new study created in memory with name: no-name-a078b543-b599-41b0-9da4-93faa115701d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started base model hyperparameter tuning for CatBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 00:38:47,027] Trial 0 finished with value: 0.6964330525208622 and parameters: {'learning_rate': 0.09169034102359146, 'depth': 10, 'l2_leaf_reg': 14.725998803904917, 'bagging_temperature': 6.306907833051802, 'random_strength': 15.691782203438866, 'min_data_in_leaf': 6}. Best is trial 0 with value: 0.6964330525208622.\n",
      "[I 2025-12-05 00:40:56,281] Trial 1 finished with value: 0.683059447179657 and parameters: {'learning_rate': 0.021275198707758812, 'depth': 9, 'l2_leaf_reg': 6.208510150560575, 'bagging_temperature': 24.26699505020626, 'random_strength': 14.832539033134122, 'min_data_in_leaf': 2}. Best is trial 0 with value: 0.6964330525208622.\n",
      "[I 2025-12-05 00:41:15,014] Trial 2 finished with value: 0.6919141138842012 and parameters: {'learning_rate': 0.006070910381584846, 'depth': 5, 'l2_leaf_reg': 5.3964009957689525, 'bagging_temperature': 7.9294756038160035, 'random_strength': 6.916144953346153, 'min_data_in_leaf': 14}. Best is trial 0 with value: 0.6964330525208622.\n",
      "[I 2025-12-05 00:41:58,555] Trial 3 finished with value: 0.6692928429493373 and parameters: {'learning_rate': 0.012136376862028732, 'depth': 10, 'l2_leaf_reg': 6.314923182779034, 'bagging_temperature': 27.925643955203437, 'random_strength': 15.721352553176304, 'min_data_in_leaf': 17}. Best is trial 0 with value: 0.6964330525208622.\n",
      "[I 2025-12-05 00:42:10,166] Trial 4 finished with value: 0.6699117738471027 and parameters: {'learning_rate': 0.018684074022279028, 'depth': 7, 'l2_leaf_reg': 29.829969459176016, 'bagging_temperature': 13.863925567626188, 'random_strength': 16.278803206753484, 'min_data_in_leaf': 3}. Best is trial 0 with value: 0.6964330525208622.\n",
      "[I 2025-12-05 00:42:23,384] Trial 5 finished with value: 0.6912106973659465 and parameters: {'learning_rate': 0.008880039905380397, 'depth': 4, 'l2_leaf_reg': 2.202017201037332, 'bagging_temperature': 8.448434929657765, 'random_strength': 11.956290429419997, 'min_data_in_leaf': 6}. Best is trial 0 with value: 0.6964330525208622.\n",
      "[I 2025-12-05 00:46:18,975] Trial 6 finished with value: 0.7240305887199288 and parameters: {'learning_rate': 0.04714000383266608, 'depth': 8, 'l2_leaf_reg': 10.919141417360706, 'bagging_temperature': 0.6880399158460693, 'random_strength': 11.644739565871802, 'min_data_in_leaf': 17}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 00:46:23,980] Trial 7 pruned. \n",
      "[I 2025-12-05 00:52:26,737] Trial 8 finished with value: 0.709312865940923 and parameters: {'learning_rate': 0.01740722983904375, 'depth': 5, 'l2_leaf_reg': 24.744054951825824, 'bagging_temperature': 3.767220584647999, 'random_strength': 5.375075604788229, 'min_data_in_leaf': 3}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 00:52:30,475] Trial 9 pruned. \n",
      "[I 2025-12-05 00:55:13,071] Trial 10 finished with value: 0.7224677992151975 and parameters: {'learning_rate': 0.084898976206966, 'depth': 9, 'l2_leaf_reg': 12.009873879045484, 'bagging_temperature': 0.8938501980486563, 'random_strength': 6.769274575807023, 'min_data_in_leaf': 20}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 00:57:08,887] Trial 11 finished with value: 0.7178416167541138 and parameters: {'learning_rate': 0.09510593450387586, 'depth': 8, 'l2_leaf_reg': 13.144760679803012, 'bagging_temperature': 2.186872266932361, 'random_strength': 5.850733232933621, 'min_data_in_leaf': 19}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 01:01:36,194] Trial 12 finished with value: 0.7053410254763058 and parameters: {'learning_rate': 0.04919239725569221, 'depth': 6, 'l2_leaf_reg': 7.723801020444422, 'bagging_temperature': 5.209810425308168, 'random_strength': 13.664248290002611, 'min_data_in_leaf': 20}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 01:09:09,857] Trial 13 finished with value: 0.7041608724159841 and parameters: {'learning_rate': 0.023969967827309972, 'depth': 9, 'l2_leaf_reg': 3.8192305238672812, 'bagging_temperature': 4.227323379985575, 'random_strength': 13.943061073287183, 'min_data_in_leaf': 14}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 01:13:54,165] Trial 14 finished with value: 0.7231122330413898 and parameters: {'learning_rate': 0.04301337162229453, 'depth': 6, 'l2_leaf_reg': 19.337179002739028, 'bagging_temperature': 1.5990642026607897, 'random_strength': 13.383625710858604, 'min_data_in_leaf': 11}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 01:17:12,467] Trial 15 finished with value: 0.7237284651425804 and parameters: {'learning_rate': 0.05769086442942707, 'depth': 7, 'l2_leaf_reg': 22.959184955272146, 'bagging_temperature': 1.1473282867880559, 'random_strength': 14.786550531226018, 'min_data_in_leaf': 8}. Best is trial 6 with value: 0.7240305887199288.\n",
      "[I 2025-12-05 01:17:57,859] Trial 16 pruned. \n",
      "[I 2025-12-05 01:18:50,789] Trial 17 pruned. \n",
      "[I 2025-12-05 01:25:01,596] Trial 18 finished with value: 0.7252192246836217 and parameters: {'learning_rate': 0.02793124164257341, 'depth': 7, 'l2_leaf_reg': 19.903468050176723, 'bagging_temperature': 0.46663222564053897, 'random_strength': 17.077784533819628, 'min_data_in_leaf': 2}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 01:27:46,338] Trial 19 pruned. \n",
      "[I 2025-12-05 01:37:15,036] Trial 20 finished with value: 0.7216177179512732 and parameters: {'learning_rate': 0.014813387938899103, 'depth': 7, 'l2_leaf_reg': 7.274745690430631, 'bagging_temperature': 1.7047858196907715, 'random_strength': 19.537520604857544, 'min_data_in_leaf': 6}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 01:46:45,786] Trial 21 finished with value: 0.7236994736993388 and parameters: {'learning_rate': 0.00975431210227409, 'depth': 7, 'l2_leaf_reg': 21.683286564743117, 'bagging_temperature': 0.4478589753610759, 'random_strength': 18.92766358715531, 'min_data_in_leaf': 4}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 01:52:08,786] Trial 22 finished with value: 0.7234903187966185 and parameters: {'learning_rate': 0.034594406012863455, 'depth': 8, 'l2_leaf_reg': 20.198460969243555, 'bagging_temperature': 1.0760642978231982, 'random_strength': 10.129207537473384, 'min_data_in_leaf': 18}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 02:00:03,951] Trial 23 finished with value: 0.7247948359358265 and parameters: {'learning_rate': 0.025587684540258775, 'depth': 8, 'l2_leaf_reg': 22.947309416472063, 'bagging_temperature': 0.5019904510966428, 'random_strength': 11.036668944668618, 'min_data_in_leaf': 2}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 02:03:08,387] Trial 24 pruned. \n",
      "[I 2025-12-05 02:12:52,280] Trial 25 finished with value: 0.7213745272176393 and parameters: {'learning_rate': 0.02463216881277404, 'depth': 9, 'l2_leaf_reg': 29.802887057998117, 'bagging_temperature': 1.5919935712388207, 'random_strength': 14.666777344548661, 'min_data_in_leaf': 6}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 02:15:11,060] Trial 26 pruned. \n",
      "[I 2025-12-05 02:16:27,271] Trial 27 pruned. \n",
      "[I 2025-12-05 02:17:30,350] Trial 28 pruned. \n",
      "[I 2025-12-05 02:18:17,948] Trial 29 pruned. \n",
      "[I 2025-12-05 02:18:23,067] Trial 30 pruned. \n",
      "[I 2025-12-05 02:19:56,696] Trial 31 pruned. \n",
      "[I 2025-12-05 02:22:02,297] Trial 32 pruned. \n",
      "[I 2025-12-05 02:23:18,113] Trial 33 pruned. \n",
      "[I 2025-12-05 02:24:53,524] Trial 34 pruned. \n",
      "[I 2025-12-05 02:24:56,031] Trial 35 pruned. \n",
      "[I 2025-12-05 02:24:59,098] Trial 36 pruned. \n",
      "[I 2025-12-05 02:28:44,055] Trial 37 finished with value: 0.7207872015196299 and parameters: {'learning_rate': 0.05872319877491645, 'depth': 7, 'l2_leaf_reg': 28.583373672198977, 'bagging_temperature': 2.0906337321044672, 'random_strength': 13.273263061319717, 'min_data_in_leaf': 5}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 02:28:57,716] Trial 38 pruned. \n",
      "[I 2025-12-05 02:33:52,469] Trial 39 finished with value: 0.7247444794544308 and parameters: {'learning_rate': 0.03651335041019906, 'depth': 7, 'l2_leaf_reg': 12.756168183152399, 'bagging_temperature': 0.7044844916753227, 'random_strength': 11.728863421011773, 'min_data_in_leaf': 14}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 02:35:39,169] Trial 40 pruned. \n",
      "[I 2025-12-05 02:37:16,608] Trial 41 pruned. \n",
      "[I 2025-12-05 02:41:43,352] Trial 42 finished with value: 0.7233843785370474 and parameters: {'learning_rate': 0.04482803745433278, 'depth': 7, 'l2_leaf_reg': 10.921652005913165, 'bagging_temperature': 1.2554274829818588, 'random_strength': 9.83708539341283, 'min_data_in_leaf': 12}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 02:49:18,186] Trial 43 finished with value: 0.7245648787644475 and parameters: {'learning_rate': 0.027988454244486042, 'depth': 9, 'l2_leaf_reg': 23.593773367474277, 'bagging_temperature': 0.2242918197945234, 'random_strength': 7.955194137753956, 'min_data_in_leaf': 1}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 02:54:57,483] Trial 44 finished with value: 0.7236711409744215 and parameters: {'learning_rate': 0.05041883433398963, 'depth': 10, 'l2_leaf_reg': 26.759966409367813, 'bagging_temperature': 0.2114095325966283, 'random_strength': 2.937895878576273, 'min_data_in_leaf': 2}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 03:08:23,057] Trial 45 finished with value: 0.7220668085977097 and parameters: {'learning_rate': 0.017169918908668213, 'depth': 9, 'l2_leaf_reg': 19.174505909908778, 'bagging_temperature': 1.3774490119578198, 'random_strength': 7.968322339436695, 'min_data_in_leaf': 1}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 03:08:28,314] Trial 46 pruned. \n",
      "[I 2025-12-05 03:15:56,478] Trial 47 finished with value: 0.724863835720473 and parameters: {'learning_rate': 0.022236120376220303, 'depth': 6, 'l2_leaf_reg': 23.693189568863893, 'bagging_temperature': 0.8828101196743864, 'random_strength': 10.826365678853149, 'min_data_in_leaf': 2}. Best is trial 18 with value: 0.7252192246836217.\n",
      "[I 2025-12-05 03:17:35,643] Trial 48 pruned. \n",
      "[I 2025-12-05 03:26:34,631] Trial 49 finished with value: 0.7253285232615009 and parameters: {'learning_rate': 0.018785199398330822, 'depth': 7, 'l2_leaf_reg': 25.358472538687142, 'bagging_temperature': 0.46014359277544997, 'random_strength': 13.923729127101382, 'min_data_in_leaf': 3}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 03:29:02,696] Trial 50 pruned. \n",
      "[I 2025-12-05 03:36:14,680] Trial 51 finished with value: 0.7241877494457677 and parameters: {'learning_rate': 0.021411577228457074, 'depth': 7, 'l2_leaf_reg': 22.290129495785724, 'bagging_temperature': 0.9447579255532697, 'random_strength': 8.732563431698978, 'min_data_in_leaf': 4}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 03:43:44,702] Trial 52 finished with value: 0.7251856379724803 and parameters: {'learning_rate': 0.023068133813623343, 'depth': 7, 'l2_leaf_reg': 20.074220897822833, 'bagging_temperature': 0.45002159755455984, 'random_strength': 13.965762418577915, 'min_data_in_leaf': 3}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 03:54:37,426] Trial 53 finished with value: 0.7246826496512119 and parameters: {'learning_rate': 0.01872100779679868, 'depth': 8, 'l2_leaf_reg': 18.133078543484785, 'bagging_temperature': 0.6478447027522651, 'random_strength': 13.951818341834667, 'min_data_in_leaf': 4}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 04:02:07,930] Trial 54 finished with value: 0.7240097831160993 and parameters: {'learning_rate': 0.013880415452915443, 'depth': 6, 'l2_leaf_reg': 25.074021457441496, 'bagging_temperature': 0.8187943192882948, 'random_strength': 10.921034366819862, 'min_data_in_leaf': 1}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 04:09:52,680] Trial 55 finished with value: 0.725268391643429 and parameters: {'learning_rate': 0.02256308346913953, 'depth': 7, 'l2_leaf_reg': 23.832902294684683, 'bagging_temperature': 0.5122373774215387, 'random_strength': 16.437580423899583, 'min_data_in_leaf': 3}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 04:12:07,013] Trial 56 pruned. \n",
      "[I 2025-12-05 04:20:32,035] Trial 57 finished with value: 0.7253280173706723 and parameters: {'learning_rate': 0.02068608358098328, 'depth': 7, 'l2_leaf_reg': 22.177352235278732, 'bagging_temperature': 0.39023141787936727, 'random_strength': 18.04903702046738, 'min_data_in_leaf': 1}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 04:22:55,566] Trial 58 pruned. \n",
      "[I 2025-12-05 04:25:24,468] Trial 59 pruned. \n",
      "[I 2025-12-05 04:25:28,548] Trial 60 pruned. \n",
      "[I 2025-12-05 04:33:24,607] Trial 61 finished with value: 0.723928397148303 and parameters: {'learning_rate': 0.021617140156383368, 'depth': 7, 'l2_leaf_reg': 12.96775154521294, 'bagging_temperature': 1.0951899569302461, 'random_strength': 15.297188698493697, 'min_data_in_leaf': 2}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 04:40:08,774] Trial 62 finished with value: 0.7242357389787492 and parameters: {'learning_rate': 0.025116898494809747, 'depth': 7, 'l2_leaf_reg': 20.66583904105268, 'bagging_temperature': 0.9647018167117338, 'random_strength': 17.772172704885147, 'min_data_in_leaf': 3}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 04:49:04,580] Trial 63 finished with value: 0.7243072028128376 and parameters: {'learning_rate': 0.019691817492386344, 'depth': 7, 'l2_leaf_reg': 28.313260048163684, 'bagging_temperature': 0.97810211302984, 'random_strength': 16.20606275493449, 'min_data_in_leaf': 6}. Best is trial 49 with value: 0.7253285232615009.\n",
      "[I 2025-12-05 04:49:29,131] Trial 64 pruned. \n",
      "[I 2025-12-05 04:55:14,633] Trial 65 finished with value: 0.7253340481311786 and parameters: {'learning_rate': 0.029188865146272322, 'depth': 7, 'l2_leaf_reg': 23.01715134198046, 'bagging_temperature': 0.2863246964459907, 'random_strength': 14.663566270702788, 'min_data_in_leaf': 1}. Best is trial 65 with value: 0.7253340481311786.\n",
      "[I 2025-12-05 04:57:00,941] Trial 66 pruned. \n",
      "[I 2025-12-05 04:57:08,174] Trial 67 pruned. \n",
      "[I 2025-12-05 04:59:36,677] Trial 68 pruned. \n",
      "[I 2025-12-05 05:03:43,409] Trial 69 finished with value: 0.7247895488314272 and parameters: {'learning_rate': 0.04993795259126447, 'depth': 7, 'l2_leaf_reg': 24.891231327113832, 'bagging_temperature': 0.7076881264742079, 'random_strength': 18.76341842551762, 'min_data_in_leaf': 1}. Best is trial 65 with value: 0.7253340481311786.\n",
      "[I 2025-12-05 05:07:28,832] Trial 70 finished with value: 0.7253752930576901 and parameters: {'learning_rate': 0.03916904553054856, 'depth': 6, 'l2_leaf_reg': 20.395319868361252, 'bagging_temperature': 0.17554706643950208, 'random_strength': 12.97258131968877, 'min_data_in_leaf': 5}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 05:09:10,325] Trial 71 pruned. \n",
      "[I 2025-12-05 05:10:15,750] Trial 72 pruned. \n",
      "[I 2025-12-05 05:14:40,292] Trial 73 finished with value: 0.7250464133162596 and parameters: {'learning_rate': 0.039141682328441334, 'depth': 7, 'l2_leaf_reg': 23.985669742729815, 'bagging_temperature': 0.5498386264425498, 'random_strength': 13.746221051117766, 'min_data_in_leaf': 1}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 05:14:44,425] Trial 74 pruned. \n",
      "[I 2025-12-05 05:15:50,711] Trial 75 pruned. \n",
      "[I 2025-12-05 05:18:56,257] Trial 76 pruned. \n",
      "[I 2025-12-05 05:19:45,695] Trial 77 pruned. \n",
      "[I 2025-12-05 05:19:58,212] Trial 78 pruned. \n",
      "[I 2025-12-05 05:20:44,704] Trial 79 pruned. \n",
      "[I 2025-12-05 05:21:34,673] Trial 80 pruned. \n",
      "[I 2025-12-05 05:23:36,051] Trial 81 pruned. \n",
      "[I 2025-12-05 05:26:05,863] Trial 82 pruned. \n",
      "[I 2025-12-05 05:26:11,514] Trial 83 pruned. \n",
      "[I 2025-12-05 05:30:27,422] Trial 84 finished with value: 0.7251943804799627 and parameters: {'learning_rate': 0.03626496447710731, 'depth': 6, 'l2_leaf_reg': 21.24999455950467, 'bagging_temperature': 0.4747518891326764, 'random_strength': 11.662087130799485, 'min_data_in_leaf': 2}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 05:30:33,016] Trial 85 pruned. \n",
      "[I 2025-12-05 05:30:36,156] Trial 86 pruned. \n",
      "[I 2025-12-05 05:39:44,054] Trial 87 pruned. \n",
      "[I 2025-12-05 05:39:49,193] Trial 88 pruned. \n",
      "[I 2025-12-05 05:40:57,559] Trial 89 pruned. \n",
      "[I 2025-12-05 05:41:00,055] Trial 90 pruned. \n",
      "[I 2025-12-05 05:43:29,020] Trial 91 pruned. \n",
      "[I 2025-12-05 05:45:23,397] Trial 92 pruned. \n",
      "[I 2025-12-05 05:45:57,278] Trial 93 pruned. \n",
      "[I 2025-12-05 05:46:00,112] Trial 94 pruned. \n",
      "[I 2025-12-05 05:48:02,803] Trial 95 pruned. \n",
      "[I 2025-12-05 05:51:13,224] Trial 96 pruned. \n",
      "[I 2025-12-05 05:51:17,256] Trial 97 pruned. \n",
      "[I 2025-12-05 05:52:55,255] Trial 98 pruned. \n",
      "[I 2025-12-05 05:53:00,674] Trial 99 pruned. \n",
      "[I 2025-12-05 06:00:20,629] Trial 100 finished with value: 0.7247809618684262 and parameters: {'learning_rate': 0.025873404925292366, 'depth': 8, 'l2_leaf_reg': 22.33634897186641, 'bagging_temperature': 0.4486789052204001, 'random_strength': 16.49593396449672, 'min_data_in_leaf': 2}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 06:04:27,513] Trial 101 pruned. \n",
      "[I 2025-12-05 06:05:09,961] Trial 102 pruned. \n",
      "[I 2025-12-05 06:05:18,018] Trial 103 pruned. \n",
      "[I 2025-12-05 06:05:20,550] Trial 104 pruned. \n",
      "[I 2025-12-05 06:16:28,869] Trial 105 finished with value: 0.72486503824077 and parameters: {'learning_rate': 0.014845603691030062, 'depth': 8, 'l2_leaf_reg': 21.667261650304933, 'bagging_temperature': 0.2787916380028682, 'random_strength': 13.717869030297052, 'min_data_in_leaf': 3}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 06:20:50,731] Trial 106 finished with value: 0.7248305089880809 and parameters: {'learning_rate': 0.042191897977391375, 'depth': 7, 'l2_leaf_reg': 17.918988233249557, 'bagging_temperature': 0.6714781473249354, 'random_strength': 15.599338106725027, 'min_data_in_leaf': 4}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 06:25:00,471] Trial 107 pruned. \n",
      "[I 2025-12-05 06:31:53,955] Trial 108 finished with value: 0.7251088349794351 and parameters: {'learning_rate': 0.02396878909430287, 'depth': 7, 'l2_leaf_reg': 21.894919746190908, 'bagging_temperature': 0.01578307337744167, 'random_strength': 12.321170318375941, 'min_data_in_leaf': 5}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 06:38:05,612] Trial 109 pruned. \n",
      "[I 2025-12-05 06:39:46,950] Trial 110 pruned. \n",
      "[I 2025-12-05 06:39:51,172] Trial 111 pruned. \n",
      "[I 2025-12-05 06:45:47,066] Trial 112 pruned. \n",
      "[I 2025-12-05 06:48:59,122] Trial 113 pruned. \n",
      "[I 2025-12-05 06:56:22,186] Trial 114 finished with value: 0.7253105330417263 and parameters: {'learning_rate': 0.01870510827809917, 'depth': 6, 'l2_leaf_reg': 17.67263887260812, 'bagging_temperature': 0.11973371550339129, 'random_strength': 16.929540525541846, 'min_data_in_leaf': 1}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 07:00:33,533] Trial 115 pruned. \n",
      "[I 2025-12-05 07:02:14,073] Trial 116 pruned. \n",
      "[I 2025-12-05 07:05:45,780] Trial 117 finished with value: 0.7252038817153913 and parameters: {'learning_rate': 0.04897095187600319, 'depth': 6, 'l2_leaf_reg': 16.769398380720638, 'bagging_temperature': 0.5480136566315684, 'random_strength': 19.69164614426026, 'min_data_in_leaf': 2}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 07:07:13,814] Trial 118 pruned. \n",
      "[I 2025-12-05 07:10:49,062] Trial 119 finished with value: 0.724462518702067 and parameters: {'learning_rate': 0.05467064558542069, 'depth': 4, 'l2_leaf_reg': 3.1736722387128093, 'bagging_temperature': 1.266782509515369, 'random_strength': 19.738739804886368, 'min_data_in_leaf': 7}. Best is trial 70 with value: 0.7253752930576901.\n",
      "[I 2025-12-05 07:12:12,156] Trial 120 pruned. \n",
      "[I 2025-12-05 07:12:56,325] Trial 121 pruned. \n",
      "[I 2025-12-05 07:13:11,239] Trial 122 pruned. \n",
      "[I 2025-12-05 07:17:22,869] Trial 123 pruned. \n",
      "[I 2025-12-05 07:21:43,728] Trial 124 finished with value: 0.7255130542427936 and parameters: {'learning_rate': 0.04434673335914573, 'depth': 4, 'l2_leaf_reg': 17.235773702036767, 'bagging_temperature': 0.7537498537146833, 'random_strength': 16.45709503502068, 'min_data_in_leaf': 2}. Best is trial 124 with value: 0.7255130542427936.\n",
      "[I 2025-12-05 07:23:45,511] Trial 125 finished with value: 0.7257614687804782 and parameters: {'learning_rate': 0.08955773312600926, 'depth': 4, 'l2_leaf_reg': 8.952470035979275, 'bagging_temperature': 0.21150772067613666, 'random_strength': 14.741499198080962, 'min_data_in_leaf': 1}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 07:24:35,209] Trial 126 pruned. \n",
      "[I 2025-12-05 07:25:58,472] Trial 127 pruned. \n",
      "[I 2025-12-05 07:26:40,957] Trial 128 pruned. \n",
      "[I 2025-12-05 07:28:21,001] Trial 129 pruned. \n",
      "[I 2025-12-05 07:30:00,077] Trial 130 pruned. \n",
      "[I 2025-12-05 07:31:40,013] Trial 131 pruned. \n",
      "[I 2025-12-05 07:33:10,335] Trial 132 pruned. \n",
      "[I 2025-12-05 07:34:22,140] Trial 133 pruned. \n",
      "[I 2025-12-05 07:36:36,505] Trial 134 pruned. \n",
      "[I 2025-12-05 07:39:51,367] Trial 135 finished with value: 0.7256630277510121 and parameters: {'learning_rate': 0.051378805925660236, 'depth': 5, 'l2_leaf_reg': 7.694793117907759, 'bagging_temperature': 0.39627692617022825, 'random_strength': 16.009522196761623, 'min_data_in_leaf': 1}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 07:44:04,379] Trial 136 finished with value: 0.7254743310021583 and parameters: {'learning_rate': 0.03497115038353094, 'depth': 5, 'l2_leaf_reg': 11.78544808014717, 'bagging_temperature': 0.19039252273507623, 'random_strength': 19.8310644884261, 'min_data_in_leaf': 3}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 07:45:31,766] Trial 137 pruned. \n",
      "[I 2025-12-05 07:45:37,119] Trial 138 pruned. \n",
      "[I 2025-12-05 07:46:36,129] Trial 139 pruned. \n",
      "[I 2025-12-05 07:52:39,710] Trial 140 finished with value: 0.7256636572210354 and parameters: {'learning_rate': 0.02581225084784774, 'depth': 5, 'l2_leaf_reg': 10.384356094673606, 'bagging_temperature': 0.34081385656694296, 'random_strength': 18.864029166930838, 'min_data_in_leaf': 4}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 07:59:45,320] Trial 141 finished with value: 0.7256218090034267 and parameters: {'learning_rate': 0.023945921156136196, 'depth': 6, 'l2_leaf_reg': 9.110263425385778, 'bagging_temperature': 0.29686793097519276, 'random_strength': 19.869061006910776, 'min_data_in_leaf': 1}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 07:59:49,004] Trial 142 pruned. \n",
      "[I 2025-12-05 08:06:12,729] Trial 143 pruned. \n",
      "[I 2025-12-05 08:08:31,151] Trial 144 pruned. \n",
      "[I 2025-12-05 08:14:37,431] Trial 145 finished with value: 0.7254819424481734 and parameters: {'learning_rate': 0.02413527079806689, 'depth': 5, 'l2_leaf_reg': 11.211086332251371, 'bagging_temperature': 0.4425202391499775, 'random_strength': 19.403816216378164, 'min_data_in_leaf': 2}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 08:17:07,423] Trial 146 pruned. \n",
      "[I 2025-12-05 08:19:37,735] Trial 147 pruned. \n",
      "[I 2025-12-05 08:21:02,107] Trial 148 pruned. \n",
      "[I 2025-12-05 08:26:01,517] Trial 149 finished with value: 0.7254926215169105 and parameters: {'learning_rate': 0.03217840714512556, 'depth': 5, 'l2_leaf_reg': 6.648030901763684, 'bagging_temperature': 0.4700661782152623, 'random_strength': 18.57720825848807, 'min_data_in_leaf': 5}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 08:27:25,765] Trial 150 pruned. \n",
      "[I 2025-12-05 08:29:27,394] Trial 151 pruned. \n",
      "[I 2025-12-05 08:29:30,324] Trial 152 pruned. \n",
      "[I 2025-12-05 08:31:31,758] Trial 153 pruned. \n",
      "[I 2025-12-05 08:35:48,718] Trial 154 finished with value: 0.7256489951716464 and parameters: {'learning_rate': 0.03636243499447105, 'depth': 5, 'l2_leaf_reg': 2.7231363286544115, 'bagging_temperature': 0.28348551289343105, 'random_strength': 19.656526018757795, 'min_data_in_leaf': 3}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 08:37:17,918] Trial 155 pruned. \n",
      "[I 2025-12-05 08:41:01,744] Trial 156 finished with value: 0.7254053363385919 and parameters: {'learning_rate': 0.04430278320287985, 'depth': 5, 'l2_leaf_reg': 2.7091808899636565, 'bagging_temperature': 0.54539727409223, 'random_strength': 17.788186486231126, 'min_data_in_leaf': 3}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 08:47:05,499] Trial 157 finished with value: 0.7253578511194219 and parameters: {'learning_rate': 0.021159540648837242, 'depth': 5, 'l2_leaf_reg': 6.067664633012664, 'bagging_temperature': 0.2160555592370883, 'random_strength': 15.208056877632718, 'min_data_in_leaf': 2}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 08:49:07,173] Trial 158 pruned. \n",
      "[I 2025-12-05 08:50:45,249] Trial 159 pruned. \n",
      "[I 2025-12-05 08:52:45,372] Trial 160 pruned. \n",
      "[I 2025-12-05 08:56:57,846] Trial 161 finished with value: 0.7256347690309711 and parameters: {'learning_rate': 0.03829889569052935, 'depth': 5, 'l2_leaf_reg': 6.079360123012325, 'bagging_temperature': 0.3847096517778936, 'random_strength': 16.514500123687124, 'min_data_in_leaf': 5}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 08:58:31,885] Trial 162 pruned. \n",
      "[I 2025-12-05 09:04:08,066] Trial 163 finished with value: 0.7253657264125252 and parameters: {'learning_rate': 0.024117103089041515, 'depth': 5, 'l2_leaf_reg': 6.7310456895888695, 'bagging_temperature': 0.10803792832210954, 'random_strength': 17.10097185395204, 'min_data_in_leaf': 11}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:05:46,519] Trial 164 pruned. \n",
      "[I 2025-12-05 09:11:15,727] Trial 165 finished with value: 0.7254908344179652 and parameters: {'learning_rate': 0.02917841059681036, 'depth': 6, 'l2_leaf_reg': 8.938266987657364, 'bagging_temperature': 0.0816135499567826, 'random_strength': 12.344919568222714, 'min_data_in_leaf': 4}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:13:18,016] Trial 166 pruned. \n",
      "[I 2025-12-05 09:14:01,079] Trial 167 pruned. \n",
      "[I 2025-12-05 09:18:52,058] Trial 168 finished with value: 0.7255466965625713 and parameters: {'learning_rate': 0.030508193247543017, 'depth': 5, 'l2_leaf_reg': 10.159707378300752, 'bagging_temperature': 0.33878782260337026, 'random_strength': 17.131388307099122, 'min_data_in_leaf': 7}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:23:24,350] Trial 169 finished with value: 0.7250867315094327 and parameters: {'learning_rate': 0.03381921302239689, 'depth': 6, 'l2_leaf_reg': 7.6427762858227375, 'bagging_temperature': 0.5861788311351567, 'random_strength': 10.705377280781066, 'min_data_in_leaf': 1}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:25:14,702] Trial 170 pruned. \n",
      "[I 2025-12-05 09:27:15,647] Trial 171 pruned. \n",
      "[I 2025-12-05 09:29:03,145] Trial 172 pruned. \n",
      "[I 2025-12-05 09:30:28,926] Trial 173 pruned. \n",
      "[I 2025-12-05 09:34:09,956] Trial 174 finished with value: 0.7255265815680496 and parameters: {'learning_rate': 0.04734476572719421, 'depth': 5, 'l2_leaf_reg': 4.236496681680341, 'bagging_temperature': 0.5012458308329356, 'random_strength': 14.716823749533567, 'min_data_in_leaf': 9}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:39:00,152] Trial 175 finished with value: 0.7257428436238147 and parameters: {'learning_rate': 0.033680482494773754, 'depth': 4, 'l2_leaf_reg': 1.4993187166149922, 'bagging_temperature': 0.10169803804649385, 'random_strength': 9.580006945754901, 'min_data_in_leaf': 6}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:40:37,925] Trial 176 pruned. \n",
      "[I 2025-12-05 09:44:23,519] Trial 177 finished with value: 0.7252434816301823 and parameters: {'learning_rate': 0.04739691249578394, 'depth': 5, 'l2_leaf_reg': 9.416429957625494, 'bagging_temperature': 0.8273235182659147, 'random_strength': 18.307753182925325, 'min_data_in_leaf': 2}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:45:16,269] Trial 178 pruned. \n",
      "[I 2025-12-05 09:48:44,917] Trial 179 pruned. \n",
      "[I 2025-12-05 09:50:17,332] Trial 180 pruned. \n",
      "[I 2025-12-05 09:55:11,040] Trial 181 finished with value: 0.7255797572243993 and parameters: {'learning_rate': 0.030059049653874202, 'depth': 4, 'l2_leaf_reg': 2.719888375988475, 'bagging_temperature': 0.30561992927836523, 'random_strength': 14.29013170774772, 'min_data_in_leaf': 5}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 09:56:24,057] Trial 182 pruned. \n",
      "[I 2025-12-05 10:01:19,116] Trial 183 finished with value: 0.7252802219144009 and parameters: {'learning_rate': 0.025350022534925368, 'depth': 4, 'l2_leaf_reg': 7.532478523790357, 'bagging_temperature': 0.19197733735642664, 'random_strength': 16.25163794403413, 'min_data_in_leaf': 9}. Best is trial 125 with value: 0.7257614687804782.\n",
      "[I 2025-12-05 10:05:22,841] Trial 184 pruned. \n",
      "[I 2025-12-05 10:09:31,255] Trial 185 finished with value: 0.725842155230371 and parameters: {'learning_rate': 0.041779205681346576, 'depth': 4, 'l2_leaf_reg': 3.628892496718331, 'bagging_temperature': 0.1922242909320177, 'random_strength': 8.464699585881778, 'min_data_in_leaf': 5}. Best is trial 185 with value: 0.725842155230371.\n",
      "[I 2025-12-05 10:12:47,887] Trial 186 finished with value: 0.7256364765207944 and parameters: {'learning_rate': 0.04922927303913129, 'depth': 4, 'l2_leaf_reg': 12.35541550903141, 'bagging_temperature': 0.26583298095389224, 'random_strength': 11.289621264124227, 'min_data_in_leaf': 5}. Best is trial 185 with value: 0.725842155230371.\n",
      "[I 2025-12-05 10:14:16,375] Trial 187 pruned. \n",
      "[I 2025-12-05 10:19:15,364] Trial 188 finished with value: 0.7254429205296843 and parameters: {'learning_rate': 0.03075149297312071, 'depth': 5, 'l2_leaf_reg': 2.732519177505906, 'bagging_temperature': 0.42206317432760093, 'random_strength': 19.57910487189882, 'min_data_in_leaf': 4}. Best is trial 185 with value: 0.725842155230371.\n",
      "[I 2025-12-05 10:25:18,262] Trial 189 finished with value: 0.7255873225007948 and parameters: {'learning_rate': 0.02652257958002013, 'depth': 5, 'l2_leaf_reg': 3.7563335804338784, 'bagging_temperature': 0.006035270639225529, 'random_strength': 4.529908131815521, 'min_data_in_leaf': 5}. Best is trial 185 with value: 0.725842155230371.\n",
      "[I 2025-12-05 10:29:26,993] Trial 190 finished with value: 0.7257060989943994 and parameters: {'learning_rate': 0.03891138128707779, 'depth': 4, 'l2_leaf_reg': 9.11861012730605, 'bagging_temperature': 0.44099213031192575, 'random_strength': 2.515221677561385, 'min_data_in_leaf': 7}. Best is trial 185 with value: 0.725842155230371.\n",
      "[I 2025-12-05 10:30:53,163] Trial 191 pruned. \n",
      "[I 2025-12-05 10:32:53,289] Trial 192 pruned. \n",
      "[I 2025-12-05 10:34:32,091] Trial 193 pruned. \n",
      "[I 2025-12-05 10:38:40,292] Trial 194 finished with value: 0.7253978053175191 and parameters: {'learning_rate': 0.03878588467050984, 'depth': 6, 'l2_leaf_reg': 3.3611852257170387, 'bagging_temperature': 0.07506364741798788, 'random_strength': 5.276289075060758, 'min_data_in_leaf': 8}. Best is trial 185 with value: 0.725842155230371.\n",
      "[I 2025-12-05 10:40:40,202] Trial 195 pruned. \n",
      "[I 2025-12-05 10:44:27,432] Trial 196 finished with value: 0.7254366240192639 and parameters: {'learning_rate': 0.04210398050808497, 'depth': 5, 'l2_leaf_reg': 5.730506895280216, 'bagging_temperature': 0.5306255258517933, 'random_strength': 0.5671461410115282, 'min_data_in_leaf': 10}. Best is trial 185 with value: 0.725842155230371.\n",
      "[I 2025-12-05 10:45:51,968] Trial 197 pruned. \n",
      "[I 2025-12-05 10:47:29,784] Trial 198 pruned. \n",
      "[I 2025-12-05 10:50:16,076] Trial 199 finished with value: 0.7253557847534432 and parameters: {'learning_rate': 0.06725717286765645, 'depth': 4, 'l2_leaf_reg': 10.766745140105893, 'bagging_temperature': 0.7860917157908937, 'random_strength': 3.4710049223906525, 'min_data_in_leaf': 8}. Best is trial 185 with value: 0.725842155230371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trials finished: 200\n",
      "Best trial AUC: 0.725842155230371\n",
      "Best trial params:\n",
      "- learning_rate: 0.041779205681346576\n",
      "- depth: 4\n",
      "- l2_leaf_reg: 3.628892496718331\n",
      "- bagging_temperature: 0.1922242909320177\n",
      "- random_strength: 8.464699585881778\n",
      "- min_data_in_leaf: 5\n"
     ]
    }
   ],
   "source": [
    "if SKIP_BASE_MODEL_HYPERPARAMETER_TUNING:\n",
    "    print(\"Skipped base model hyperparameter tuning\")\n",
    "else:\n",
    "    print(f\"Started base model hyperparameter tuning for {BASE_MODEL_OPTUNA_STUDY_ESTIMATOR.value}\")\n",
    "    sampler = optuna.samplers.TPESampler(n_ei_candidates=24, multivariate=True)\n",
    "    study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "    study.optimize(base_model_optuna_study_objective, n_trials=BASE_MODEL_OPTUNA_STUDY_NUM_TRIALS)\n",
    "    \n",
    "    print(f\"# trials finished: {len(study.trials)}\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Best trial AUC: {trial.value}\")\n",
    "    print(f\"Best trial params:\")\n",
    "    for param_key, param_value in trial.params.items():\n",
    "        print(f\"- {param_key}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00001f7",
   "metadata": {
    "papermill": {
     "duration": 0.015041,
     "end_time": "2025-12-05T10:50:16.143925",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.128884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e23051e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:50:16.174840Z",
     "iopub.status.busy": "2025-12-05T10:50:16.174596Z",
     "iopub.status.idle": "2025-12-05T10:50:16.178245Z",
     "shell.execute_reply": "2025-12-05T10:50:16.177673Z"
    },
    "papermill": {
     "duration": 0.020447,
     "end_time": "2025-12-05T10:50:16.179326",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.158879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of splits to use for Stratified K-Fold Cross-Validation for base models\n",
    "BASE_MODEL_KFOLD_NUM_SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f637d",
   "metadata": {
    "papermill": {
     "duration": 0.014558,
     "end_time": "2025-12-05T10:50:16.208750",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.194192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7.1 CatBoost\n",
    "\n",
    "### 7.1.1 Helper Methods (CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6016392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:50:16.239696Z",
     "iopub.status.busy": "2025-12-05T10:50:16.239510Z",
     "iopub.status.idle": "2025-12-05T10:50:16.247077Z",
     "shell.execute_reply": "2025-12-05T10:50:16.246492Z"
    },
    "papermill": {
     "duration": 0.024868,
     "end_time": "2025-12-05T10:50:16.248142",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.223274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_catboost_preds(params_dict, feature_names):\n",
    "    oof_preds = np.zeros(len(train_data))\n",
    "    all_test_preds_total = np.zeros(len(test_data))\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "    \n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = train_data.drop(target_col, axis=1).iloc[train_indices]\n",
    "            X_validation_fold = train_data.drop(target_col, axis=1).iloc[validation_indices]\n",
    "            y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "            y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "        \n",
    "            model = CatBoostClassifier(\n",
    "                iterations=params_dict['iterations'],\n",
    "                learning_rate=params_dict['learning_rate'],\n",
    "                depth=params_dict['depth'],\n",
    "                l2_leaf_reg=params_dict['l2_leaf_reg'],\n",
    "                bagging_temperature=params_dict['bagging_temperature'],\n",
    "                random_strength=params_dict['random_strength'],\n",
    "                min_data_in_leaf=params_dict['min_data_in_leaf'],\n",
    "                od_type='Iter',\n",
    "                od_wait=50,\n",
    "                use_best_model=True,\n",
    "                cat_features=cat_features,\n",
    "                eval_metric='AUC',\n",
    "                task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
    "                devices='0',\n",
    "                metric_period=1000,\n",
    "                random_seed=random_seed,\n",
    "                verbose=False,\n",
    "                allow_writing_files=False\n",
    "            )\n",
    "        \n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=(X_validation_fold, y_validation_fold),\n",
    "                early_stopping_rounds=50\n",
    "            )\n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "        \n",
    "            y_test_pred_proba = model.predict_proba(test_data)[:, 1]\n",
    "            all_test_preds_total += np.array(y_test_pred_proba)\n",
    "\n",
    "    test_preds = all_test_preds_total / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(oof_preds), pd.Series(test_preds)\n",
    "\n",
    "def get_catboost_stacking_estimator(index, params_dict):\n",
    "    return StackingEstimator(\n",
    "        name=f\"CatBoost_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=train_data.columns.tolist(),\n",
    "        get_preds=get_catboost_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5b6509",
   "metadata": {
    "papermill": {
     "duration": 0.014633,
     "end_time": "2025-12-05T10:50:16.277464",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.262831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 7.1.2 Add Estimators (CatBoost)\n",
    "\n",
    "Add CatBoost estimators to list that StackingPredictionsRetriever will process. Hyperparameters were found using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c111550",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:50:16.307884Z",
     "iopub.status.busy": "2025-12-05T10:50:16.307684Z",
     "iopub.status.idle": "2025-12-05T10:50:16.311265Z",
     "shell.execute_reply": "2025-12-05T10:50:16.310710Z"
    },
    "papermill": {
     "duration": 0.020217,
     "end_time": "2025-12-05T10:50:16.312289",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.292072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators += [\n",
    "    get_catboost_stacking_estimator( # Optuna study AUC: 0.708397229333519\n",
    "        index=1,\n",
    "        params_dict={\n",
    "            'iterations': 5000,\n",
    "            'learning_rate': 0.015390603953691526,\n",
    "            'depth': 6,\n",
    "            'l2_leaf_reg': 8.145456703744333,\n",
    "            'bagging_temperature': 3.899779354823547,\n",
    "            'random_strength': 0.7330712093531994,\n",
    "            'min_data_in_leaf': 16,\n",
    "        }\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a06ac",
   "metadata": {
    "papermill": {
     "duration": 0.014718,
     "end_time": "2025-12-05T10:50:16.341870",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.327152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7.2 XGBClassifier\n",
    "\n",
    "### 7.2.1 Helper Methods (XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c4cdc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:50:16.372329Z",
     "iopub.status.busy": "2025-12-05T10:50:16.372132Z",
     "iopub.status.idle": "2025-12-05T10:50:16.379451Z",
     "shell.execute_reply": "2025-12-05T10:50:16.378872Z"
    },
    "papermill": {
     "duration": 0.024007,
     "end_time": "2025-12-05T10:50:16.380466",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.356459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xgbclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds = np.zeros(len(train_data))\n",
    "    all_test_preds_total = np.zeros(len(test_data))\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "\n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = train_data.drop(target_col, axis=1).iloc[train_indices]\n",
    "            X_validation_fold = train_data.drop(target_col, axis=1).iloc[validation_indices]\n",
    "            y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "            y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=params_dict['n_estimators'],\n",
    "                learning_rate=params_dict['learning_rate'],\n",
    "                max_depth=params_dict['max_depth'],\n",
    "                subsample=params_dict['subsample'],\n",
    "                colsample_bytree=params_dict['colsample_bytree'],\n",
    "                alpha=params_dict['alpha'],\n",
    "                gamma=params_dict['gamma'],\n",
    "                reg_lambda=params_dict['lambda'],\n",
    "                min_child_weight=params_dict['min_child_weight'],\n",
    "                tree_method='gpu_hist' if torch.cuda.is_available() else 'auto',\n",
    "                predictor='gpu_predictor' if torch.cuda.is_available() else 'cpu_predictor',\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                enable_categorical=True,\n",
    "                eval_metric='auc',\n",
    "                n_jobs=-1,\n",
    "                random_state=random_seed,\n",
    "                verbosity=0\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "                early_stopping_rounds=50,\n",
    "                verbose=False\n",
    "            )\n",
    "    \n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "        \n",
    "            y_test_pred_proba = model.predict_proba(test_data)[:, 1]\n",
    "            all_test_preds_total += np.array(y_test_pred_proba)\n",
    "\n",
    "    test_preds = all_test_preds_total / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(oof_preds), pd.Series(test_preds)\n",
    "\n",
    "def get_xgbclassifier_stacking_estimator(index, params_dict):\n",
    "    return StackingEstimator(\n",
    "        name=f\"XGBClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=train_data.columns.tolist(),\n",
    "        get_preds=get_xgbclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a039c34",
   "metadata": {
    "papermill": {
     "duration": 0.014502,
     "end_time": "2025-12-05T10:50:16.409675",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.395173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 7.2.2 Add Estimators (XGBClassifier)\n",
    "\n",
    "Add XGBClassifier estimators to list that StackingPredictionsRetriever will process. Hyperparameters were found using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cac63417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:50:16.439664Z",
     "iopub.status.busy": "2025-12-05T10:50:16.439425Z",
     "iopub.status.idle": "2025-12-05T10:50:16.443157Z",
     "shell.execute_reply": "2025-12-05T10:50:16.442595Z"
    },
    "papermill": {
     "duration": 0.019991,
     "end_time": "2025-12-05T10:50:16.444186",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.424195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators += [\n",
    "    get_xgbclassifier_stacking_estimator( # Optuna study AUC: 0.7268086741970188\n",
    "        index=1,\n",
    "        params_dict={\n",
    "            'n_estimators': 5000,\n",
    "            'learning_rate': 0.04713166643911415,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.9548566933205647,\n",
    "            'colsample_bytree': 0.7899405897418637,\n",
    "            'alpha': 0.004535986977762743,\n",
    "            'gamma': 0.001188252496178679,\n",
    "            'lambda': 0.0023834182421268437,\n",
    "            'min_child_weight': 19,\n",
    "        }\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb0ba4",
   "metadata": {
    "papermill": {
     "duration": 0.015091,
     "end_time": "2025-12-05T10:50:16.474070",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.458979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Base Model Predictions\n",
    "\n",
    "## 8.1 Get Base Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e568847e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T10:50:16.504670Z",
     "iopub.status.busy": "2025-12-05T10:50:16.504355Z",
     "iopub.status.idle": "2025-12-05T11:21:00.901640Z",
     "shell.execute_reply": "2025-12-05T11:21:00.901012Z"
    },
    "papermill": {
     "duration": 1844.414141,
     "end_time": "2025-12-05T11:21:00.903089",
     "exception": false,
     "start_time": "2025-12-05T10:50:16.488948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Importing predictions..\n",
      "[INFO] No train predictions were imported\n",
      "[INFO] No test predictions were imported\n",
      "[INFO] Finished importing predictions\n",
      "[INFO] Syncing predictions..\n",
      "[INFO] Finished syncing predictions\n",
      "[INFO] Getting predictions..\n",
      "[INFO] Getting predictions for estimator CatBoost_1 (9bd80f4f2126cad804969b9493228920)\n",
      "[INFO] Saved predictions\n",
      "[INFO] Getting predictions for estimator XGBClassifier_1 (9ba440ab5fba085ef25eed63536e0350)\n",
      "[INFO] Saved predictions\n",
      "[INFO] Finished getting all predictions\n"
     ]
    }
   ],
   "source": [
    "stacking_preds_retriever = StackingPredictionsRetriever(\n",
    "    estimators=estimators,\n",
    "    working_dir_path=\"/kaggle/working/\",\n",
    "    train_preds_filename=\"base_models_train_preds\",\n",
    "    test_preds_filename=\"base_models_test_preds\",\n",
    "    preds_save_interval=1\n",
    ")\n",
    "stacking_preds_retriever.import_preds(\"/kaggle/input/diabetes-prediction-challenge-base-model-preds/\")\n",
    "stacking_preds_retriever.sync_preds()\n",
    "stacking_preds_retriever.get_preds()\n",
    "\n",
    "base_model_train_preds, base_model_test_preds = stacking_preds_retriever.get_current_train_and_test_preds()\n",
    "base_model_train_preds.sort_index(axis=1, inplace=True, key=lambda index: index.map(lambda col_name: (col_name.split(\"_\")[0], int(col_name.split()[0].split(\"_\")[-1]))))\n",
    "base_model_test_preds.sort_index(axis=1, inplace=True, key=lambda index: index.map(lambda col_name: (col_name.split(\"_\")[0], int(col_name.split()[0].split(\"_\")[-1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0e7bc",
   "metadata": {
    "papermill": {
     "duration": 0.01493,
     "end_time": "2025-12-05T11:21:00.933968",
     "exception": false,
     "start_time": "2025-12-05T11:21:00.919038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.2 Base Models AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4b11020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:21:00.965682Z",
     "iopub.status.busy": "2025-12-05T11:21:00.964977Z",
     "iopub.status.idle": "2025-12-05T11:21:01.298132Z",
     "shell.execute_reply": "2025-12-05T11:21:01.297489Z"
    },
    "papermill": {
     "duration": 0.350299,
     "end_time": "2025-12-05T11:21:01.299276",
     "exception": false,
     "start_time": "2025-12-05T11:21:00.948977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CatBoost_1 (9bd80f4f2126cad804969b9493228920)         0.709107\n",
       "XGBClassifier_1 (9ba440ab5fba085ef25eed63536e0350)    0.727065\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_auc = pd.Series()\n",
    "for estimator in base_model_train_preds.columns:\n",
    "    base_model_auc[estimator] = roc_auc_score(train_data[target_col], base_model_train_preds[estimator])\n",
    "base_model_auc.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb54d0",
   "metadata": {
    "papermill": {
     "duration": 0.015337,
     "end_time": "2025-12-05T11:21:01.331230",
     "exception": false,
     "start_time": "2025-12-05T11:21:01.315893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. Meta-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95bde127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:21:01.362804Z",
     "iopub.status.busy": "2025-12-05T11:21:01.362560Z",
     "iopub.status.idle": "2025-12-05T11:21:01.365804Z",
     "shell.execute_reply": "2025-12-05T11:21:01.365222Z"
    },
    "papermill": {
     "duration": 0.020172,
     "end_time": "2025-12-05T11:21:01.366861",
     "exception": false,
     "start_time": "2025-12-05T11:21:01.346689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of splits to use for K-Fold Cross-Validation for meta model\n",
    "META_MODEL_KFOLD_NUM_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77265b6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:21:01.397988Z",
     "iopub.status.busy": "2025-12-05T11:21:01.397811Z",
     "iopub.status.idle": "2025-12-05T11:21:05.401749Z",
     "shell.execute_reply": "2025-12-05T11:21:05.398824Z"
    },
    "papermill": {
     "duration": 4.023175,
     "end_time": "2025-12-05T11:21:05.405107",
     "exception": false,
     "start_time": "2025-12-05T11:21:01.381932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_oof_preds = np.zeros(len(train_data))\n",
    "meta_test_preds_total = np.zeros(len(test_data))\n",
    "meta_train_feature_importances_total = np.zeros(len(base_model_train_preds.columns))\n",
    "\n",
    "kfold = KFold(n_splits=META_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=RANDOM_SEEDS[0])\n",
    "kfold_splits = kfold.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "kfold_enumeration = enumerate(kfold_splits)\n",
    "\n",
    "for fold, (train_indices, validation_indices) in kfold_enumeration:\n",
    "    X_train_fold = base_model_train_preds.iloc[train_indices]\n",
    "    X_validation_fold = base_model_train_preds.iloc[validation_indices]\n",
    "    y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "    y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "    meta_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "\n",
    "    meta_train_feature_importances_total += np.array(model.coef_[0])\n",
    "\n",
    "    y_test_pred_proba = model.predict_proba(base_model_test_preds)[:, 1]\n",
    "    meta_test_preds_total += np.array(y_test_pred_proba)\n",
    "\n",
    "meta_train_feature_importances = meta_train_feature_importances_total / META_MODEL_KFOLD_NUM_SPLITS\n",
    "meta_test_preds = meta_test_preds_total / META_MODEL_KFOLD_NUM_SPLITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0d7832",
   "metadata": {
    "papermill": {
     "duration": 0.026895,
     "end_time": "2025-12-05T11:21:05.464107",
     "exception": false,
     "start_time": "2025-12-05T11:21:05.437212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9.3 Meta-Model Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f80ab269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:21:05.502037Z",
     "iopub.status.busy": "2025-12-05T11:21:05.501220Z",
     "iopub.status.idle": "2025-12-05T11:21:05.507735Z",
     "shell.execute_reply": "2025-12-05T11:21:05.506964Z"
    },
    "papermill": {
     "duration": 0.023442,
     "end_time": "2025-12-05T11:21:05.508787",
     "exception": false,
     "start_time": "2025-12-05T11:21:05.485345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier_1 (9ba440ab5fba085ef25eed63536e0350)    5.356272\n",
       "CatBoost_1 (9bd80f4f2126cad804969b9493228920)        -0.521819\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model_feature_importances = pd.Series(meta_train_feature_importances)\n",
    "meta_model_feature_importances.index = base_model_train_preds.columns\n",
    "meta_model_feature_importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d6a1c",
   "metadata": {
    "papermill": {
     "duration": 0.014832,
     "end_time": "2025-12-05T11:21:05.538643",
     "exception": false,
     "start_time": "2025-12-05T11:21:05.523811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9.4 Meta-Model AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d91198d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:21:05.569457Z",
     "iopub.status.busy": "2025-12-05T11:21:05.569230Z",
     "iopub.status.idle": "2025-12-05T11:21:05.737025Z",
     "shell.execute_reply": "2025-12-05T11:21:05.736407Z"
    },
    "papermill": {
     "duration": 0.18471,
     "end_time": "2025-12-05T11:21:05.738140",
     "exception": false,
     "start_time": "2025-12-05T11:21:05.553430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.727333567253498"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model_auc = roc_auc_score(train_data[target_col], meta_oof_preds)\n",
    "meta_model_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e9000",
   "metadata": {
    "papermill": {
     "duration": 0.015534,
     "end_time": "2025-12-05T11:21:05.769350",
     "exception": false,
     "start_time": "2025-12-05T11:21:05.753816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 10. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a995722c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T11:21:05.800584Z",
     "iopub.status.busy": "2025-12-05T11:21:05.800156Z",
     "iopub.status.idle": "2025-12-05T11:21:06.347190Z",
     "shell.execute_reply": "2025-12-05T11:21:06.346497Z"
    },
    "papermill": {
     "duration": 0.564049,
     "end_time": "2025-12-05T11:21:06.348383",
     "exception": false,
     "start_time": "2025-12-05T11:21:05.784334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file prepared.\n"
     ]
    }
   ],
   "source": [
    "# prepare submission\n",
    "submission = pd.DataFrame({'id': test_data.index, target_col: meta_test_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file prepared.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14272474,
     "sourceId": 91723,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38697.157787,
   "end_time": "2025-12-05T11:21:07.884924",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T00:36:10.727137",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
