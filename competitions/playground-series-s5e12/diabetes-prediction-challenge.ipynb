{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e020d2",
   "metadata": {
    "papermill": {
     "duration": 0.010441,
     "end_time": "2025-12-12T23:49:45.162613",
     "exception": false,
     "start_time": "2025-12-12T23:49:45.152172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Overview\n",
    "\n",
    "This is a notebook for training models to submit predictions to the \"Diabetes Prediction Challenge\" Kaggle competition ([playground-series-s5e12](https://www.kaggle.com/competitions/playground-series-s5e12)).\n",
    "\n",
    "Synthetic data is used for this playground competition, and the objective is to, for each patient in the test set, predict the probability that the patient will be diagnosed with diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eff78f",
   "metadata": {
    "papermill": {
     "duration": 0.008876,
     "end_time": "2025-12-12T23:49:45.180360",
     "exception": false,
     "start_time": "2025-12-12T23:49:45.171484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Setup\n",
    "\n",
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa62a226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:45.199107Z",
     "iopub.status.busy": "2025-12-12T23:49:45.198878Z",
     "iopub.status.idle": "2025-12-12T23:49:52.812280Z",
     "shell.execute_reply": "2025-12-12T23:49:52.811640Z"
    },
    "papermill": {
     "duration": 7.624897,
     "end_time": "2025-12-12T23:49:52.813688",
     "exception": false,
     "start_time": "2025-12-12T23:49:45.188791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import copy\n",
    "import optuna\n",
    "import os\n",
    "import hashlib as hl # for StackingEstimator\n",
    "import inspect # for StackingEstimator\n",
    "import random\n",
    "import warnings\n",
    "from catboost import CatBoostClassifier\n",
    "from enum import Enum\n",
    "from pathlib import Path # for StackingPredictionsRetriever\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression # for meta model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from types import FunctionType\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) # Display full column content\n",
    "pd.set_option('display.max_rows', None) # Display all rows\n",
    "pd.set_option('display.width', 1000) # Set larger display width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d5e94",
   "metadata": {
    "papermill": {
     "duration": 0.008731,
     "end_time": "2025-12-12T23:49:52.831776",
     "exception": false,
     "start_time": "2025-12-12T23:49:52.823045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Reproducibility\n",
    "\n",
    "For reproducibility of results, an arbitrary number will be used for the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720b1551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:52.850381Z",
     "iopub.status.busy": "2025-12-12T23:49:52.849618Z",
     "iopub.status.idle": "2025-12-12T23:49:52.901700Z",
     "shell.execute_reply": "2025-12-12T23:49:52.900983Z"
    },
    "papermill": {
     "duration": 0.062845,
     "end_time": "2025-12-12T23:49:52.903070",
     "exception": false,
     "start_time": "2025-12-12T23:49:52.840225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEEDS = [11, 42]\n",
    "random.seed(RANDOM_SEEDS[0])\n",
    "np.random.seed(RANDOM_SEEDS[0])\n",
    "torch.manual_seed(RANDOM_SEEDS[0])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEEDS[0])\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEEDS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058703d",
   "metadata": {
    "papermill": {
     "duration": 0.008649,
     "end_time": "2025-12-12T23:49:52.920593",
     "exception": false,
     "start_time": "2025-12-12T23:49:52.911944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148dd905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:52.938493Z",
     "iopub.status.busy": "2025-12-12T23:49:52.938253Z",
     "iopub.status.idle": "2025-12-12T23:49:52.941735Z",
     "shell.execute_reply": "2025-12-12T23:49:52.941057Z"
    },
    "papermill": {
     "duration": 0.013756,
     "end_time": "2025-12-12T23:49:52.942837",
     "exception": false,
     "start_time": "2025-12-12T23:49:52.929081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679e5a7",
   "metadata": {
    "papermill": {
     "duration": 0.00841,
     "end_time": "2025-12-12T23:49:52.959896",
     "exception": false,
     "start_time": "2025-12-12T23:49:52.951486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4 DataFrames\n",
    "\n",
    "Read the data provided for the competition into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae223776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:52.978441Z",
     "iopub.status.busy": "2025-12-12T23:49:52.977808Z",
     "iopub.status.idle": "2025-12-12T23:49:55.309693Z",
     "shell.execute_reply": "2025-12-12T23:49:55.308858Z"
    },
    "papermill": {
     "duration": 2.34261,
     "end_time": "2025-12-12T23:49:55.311202",
     "exception": false,
     "start_time": "2025-12-12T23:49:52.968592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '/kaggle/input'\n",
    "orig_train_data = pd.read_csv(os.path.join(INPUT_DIR, 'playground-series-s5e12/train.csv'))\n",
    "orig_test_data = pd.read_csv(os.path.join(INPUT_DIR, 'playground-series-s5e12/test.csv'))\n",
    "\n",
    "# set index\n",
    "orig_train_data.set_index('id', inplace=True)\n",
    "orig_test_data.set_index('id', inplace=True)\n",
    "\n",
    "# target column\n",
    "target_col = \"diagnosed_diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee6ebb",
   "metadata": {
    "papermill": {
     "duration": 0.0086,
     "end_time": "2025-12-12T23:49:55.328803",
     "exception": false,
     "start_time": "2025-12-12T23:49:55.320203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48080041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:55.346990Z",
     "iopub.status.busy": "2025-12-12T23:49:55.346601Z",
     "iopub.status.idle": "2025-12-12T23:49:55.349911Z",
     "shell.execute_reply": "2025-12-12T23:49:55.349200Z"
    },
    "papermill": {
     "duration": 0.013747,
     "end_time": "2025-12-12T23:49:55.351052",
     "exception": false,
     "start_time": "2025-12-12T23:49:55.337305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip the generation of plots (e.g. KDE) in this section that take time; set to False to generate the plots \n",
    "SKIP_PLOTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f046298e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:55.369502Z",
     "iopub.status.busy": "2025-12-12T23:49:55.369301Z",
     "iopub.status.idle": "2025-12-12T23:49:55.846623Z",
     "shell.execute_reply": "2025-12-12T23:49:55.845875Z"
    },
    "papermill": {
     "duration": 0.487709,
     "end_time": "2025-12-12T23:49:55.847797",
     "exception": false,
     "start_time": "2025-12-12T23:49:55.360088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.359734</td>\n",
       "      <td>2.072411</td>\n",
       "      <td>80.230803</td>\n",
       "      <td>5.963695</td>\n",
       "      <td>7.002200</td>\n",
       "      <td>6.012733</td>\n",
       "      <td>25.874684</td>\n",
       "      <td>0.858766</td>\n",
       "      <td>116.294193</td>\n",
       "      <td>75.440924</td>\n",
       "      <td>70.167749</td>\n",
       "      <td>186.818801</td>\n",
       "      <td>53.823214</td>\n",
       "      <td>102.905854</td>\n",
       "      <td>123.081850</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.181990</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>0.623296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.655520</td>\n",
       "      <td>1.048189</td>\n",
       "      <td>51.195071</td>\n",
       "      <td>1.463336</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>2.022707</td>\n",
       "      <td>2.860705</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>11.010390</td>\n",
       "      <td>6.825775</td>\n",
       "      <td>6.938722</td>\n",
       "      <td>16.730832</td>\n",
       "      <td>8.266545</td>\n",
       "      <td>19.022416</td>\n",
       "      <td>24.739397</td>\n",
       "      <td>0.356484</td>\n",
       "      <td>0.385837</td>\n",
       "      <td>0.171478</td>\n",
       "      <td>0.484560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  alcohol_consumption_per_week  physical_activity_minutes_per_week     diet_score  sleep_hours_per_day  screen_time_hours_per_day            bmi  waist_to_hip_ratio    systolic_bp   diastolic_bp     heart_rate  cholesterol_total  hdl_cholesterol  ldl_cholesterol  triglycerides  family_history_diabetes  hypertension_history  cardiovascular_history  diagnosed_diabetes\n",
       "count  700000.000000                 700000.000000                       700000.000000  700000.000000        700000.000000              700000.000000  700000.000000       700000.000000  700000.000000  700000.000000  700000.000000      700000.000000    700000.000000    700000.000000  700000.000000            700000.000000         700000.000000           700000.000000       700000.000000\n",
       "mean       50.359734                      2.072411                           80.230803       5.963695             7.002200                   6.012733      25.874684            0.858766     116.294193      75.440924      70.167749         186.818801        53.823214       102.905854     123.081850                 0.149401              0.181990                0.030324            0.623296\n",
       "std        11.655520                      1.048189                           51.195071       1.463336             0.901907                   2.022707       2.860705            0.037980      11.010390       6.825775       6.938722          16.730832         8.266545        19.022416      24.739397                 0.356484              0.385837                0.171478            0.484560\n",
       "min        19.000000                      1.000000                            1.000000       0.100000             3.100000                   0.600000      15.100000            0.680000      91.000000      51.000000      42.000000         117.000000        21.000000        51.000000      31.000000                 0.000000              0.000000                0.000000            0.000000\n",
       "25%        42.000000                      1.000000                           49.000000       5.000000             6.400000                   4.600000      23.900000            0.830000     108.000000      71.000000      65.000000         175.000000        48.000000        89.000000     106.000000                 0.000000              0.000000                0.000000            0.000000\n",
       "50%        50.000000                      2.000000                           71.000000       6.000000             7.000000                   6.000000      25.900000            0.860000     116.000000      75.000000      70.000000         187.000000        54.000000       103.000000     123.000000                 0.000000              0.000000                0.000000            1.000000\n",
       "75%        58.000000                      3.000000                           96.000000       7.000000             7.600000                   7.400000      27.800000            0.880000     124.000000      80.000000      75.000000         199.000000        59.000000       116.000000     139.000000                 0.000000              0.000000                0.000000            1.000000\n",
       "max        89.000000                      9.000000                          747.000000       9.900000             9.900000                  16.500000      38.400000            1.050000     163.000000     104.000000     101.000000         289.000000        90.000000       205.000000     290.000000                 1.000000              1.000000                1.000000            1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18756588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:55.867151Z",
     "iopub.status.busy": "2025-12-12T23:49:55.866914Z",
     "iopub.status.idle": "2025-12-12T23:49:56.061794Z",
     "shell.execute_reply": "2025-12-12T23:49:56.061135Z"
    },
    "papermill": {
     "duration": 0.205764,
     "end_time": "2025-12-12T23:49:56.063052",
     "exception": false,
     "start_time": "2025-12-12T23:49:55.857288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.432397</td>\n",
       "      <td>2.089693</td>\n",
       "      <td>92.349087</td>\n",
       "      <td>5.945838</td>\n",
       "      <td>6.997795</td>\n",
       "      <td>6.011278</td>\n",
       "      <td>25.881906</td>\n",
       "      <td>0.859007</td>\n",
       "      <td>116.374117</td>\n",
       "      <td>75.396013</td>\n",
       "      <td>70.048350</td>\n",
       "      <td>187.308620</td>\n",
       "      <td>53.813557</td>\n",
       "      <td>103.416083</td>\n",
       "      <td>123.538480</td>\n",
       "      <td>0.152920</td>\n",
       "      <td>0.184410</td>\n",
       "      <td>0.033110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.938741</td>\n",
       "      <td>1.066214</td>\n",
       "      <td>62.187399</td>\n",
       "      <td>1.481068</td>\n",
       "      <td>0.914693</td>\n",
       "      <td>2.060472</td>\n",
       "      <td>2.894289</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>11.252146</td>\n",
       "      <td>6.950340</td>\n",
       "      <td>7.090543</td>\n",
       "      <td>18.413053</td>\n",
       "      <td>8.398126</td>\n",
       "      <td>20.571855</td>\n",
       "      <td>28.965441</td>\n",
       "      <td>0.359911</td>\n",
       "      <td>0.387819</td>\n",
       "      <td>0.178924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>38.300000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  alcohol_consumption_per_week  physical_activity_minutes_per_week     diet_score  sleep_hours_per_day  screen_time_hours_per_day            bmi  waist_to_hip_ratio    systolic_bp   diastolic_bp     heart_rate  cholesterol_total  hdl_cholesterol  ldl_cholesterol  triglycerides  family_history_diabetes  hypertension_history  cardiovascular_history\n",
       "count  300000.000000                 300000.000000                       300000.000000  300000.000000        300000.000000              300000.000000  300000.000000       300000.000000  300000.000000  300000.000000  300000.000000      300000.000000    300000.000000    300000.000000  300000.000000            300000.000000         300000.000000           300000.000000\n",
       "mean       50.432397                      2.089693                           92.349087       5.945838             6.997795                   6.011278      25.881906            0.859007     116.374117      75.396013      70.048350         187.308620        53.813557       103.416083     123.538480                 0.152920              0.184410                0.033110\n",
       "std        11.938741                      1.066214                           62.187399       1.481068             0.914693                   2.060472       2.894289            0.038523      11.252146       6.950340       7.090543          18.413053         8.398126        20.571855      28.965441                 0.359911              0.387819                0.178924\n",
       "min        19.000000                      1.000000                            1.000000       0.100000             3.100000                   0.600000      15.100000            0.690000      91.000000      51.000000      42.000000         107.000000        22.000000        51.000000      31.000000                 0.000000              0.000000                0.000000\n",
       "25%        42.000000                      1.000000                           51.000000       5.000000             6.400000                   4.600000      23.900000            0.830000     108.000000      71.000000      65.000000         174.000000        48.000000        89.000000     104.000000                 0.000000              0.000000                0.000000\n",
       "50%        50.000000                      2.000000                           77.000000       6.000000             7.000000                   6.000000      25.900000            0.860000     116.000000      75.000000      70.000000         187.000000        54.000000       103.000000     123.000000                 0.000000              0.000000                0.000000\n",
       "75%        59.000000                      3.000000                          115.000000       7.000000             7.600000                   7.400000      27.800000            0.890000     124.000000      80.000000      75.000000         200.000000        60.000000       117.000000     142.000000                 0.000000              0.000000                0.000000\n",
       "max        89.000000                      9.000000                          748.000000       9.900000             9.900000                  15.900000      38.300000            1.050000     170.000000     104.000000     101.000000         285.000000        91.000000       226.000000     290.000000                 1.000000              1.000000                1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105d767f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:56.083544Z",
     "iopub.status.busy": "2025-12-12T23:49:56.083200Z",
     "iopub.status.idle": "2025-12-12T23:49:56.204387Z",
     "shell.execute_reply": "2025-12-12T23:49:56.203575Z"
    },
    "papermill": {
     "duration": 0.13244,
     "end_time": "2025-12-12T23:49:56.205806",
     "exception": false,
     "start_time": "2025-12-12T23:49:56.073366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_col_names = orig_train_data.select_dtypes(include='number').columns.to_series()\n",
    "categorical_col_names = orig_train_data.select_dtypes(include='object').columns.to_series()\n",
    "assert numeric_col_names.size + categorical_col_names.size == orig_train_data.shape[1]\n",
    "\n",
    "# drop target column from numeric column names\n",
    "numeric_col_names.drop(target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c84ef793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:56.225655Z",
     "iopub.status.busy": "2025-12-12T23:49:56.225420Z",
     "iopub.status.idle": "2025-12-12T23:49:56.503872Z",
     "shell.execute_reply": "2025-12-12T23:49:56.502954Z"
    },
    "papermill": {
     "duration": 0.289643,
     "end_time": "2025-12-12T23:49:56.505125",
     "exception": false,
     "start_time": "2025-12-12T23:49:56.215482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train data missing values #####\n",
      "age                                   0\n",
      "alcohol_consumption_per_week          0\n",
      "physical_activity_minutes_per_week    0\n",
      "diet_score                            0\n",
      "sleep_hours_per_day                   0\n",
      "screen_time_hours_per_day             0\n",
      "bmi                                   0\n",
      "waist_to_hip_ratio                    0\n",
      "systolic_bp                           0\n",
      "diastolic_bp                          0\n",
      "heart_rate                            0\n",
      "cholesterol_total                     0\n",
      "hdl_cholesterol                       0\n",
      "ldl_cholesterol                       0\n",
      "triglycerides                         0\n",
      "gender                                0\n",
      "ethnicity                             0\n",
      "education_level                       0\n",
      "income_level                          0\n",
      "smoking_status                        0\n",
      "employment_status                     0\n",
      "family_history_diabetes               0\n",
      "hypertension_history                  0\n",
      "cardiovascular_history                0\n",
      "diagnosed_diabetes                    0\n",
      "dtype: int64\n",
      "\n",
      "##### Test data missing values #####\n",
      "age                                   0\n",
      "alcohol_consumption_per_week          0\n",
      "physical_activity_minutes_per_week    0\n",
      "diet_score                            0\n",
      "sleep_hours_per_day                   0\n",
      "screen_time_hours_per_day             0\n",
      "bmi                                   0\n",
      "waist_to_hip_ratio                    0\n",
      "systolic_bp                           0\n",
      "diastolic_bp                          0\n",
      "heart_rate                            0\n",
      "cholesterol_total                     0\n",
      "hdl_cholesterol                       0\n",
      "ldl_cholesterol                       0\n",
      "triglycerides                         0\n",
      "gender                                0\n",
      "ethnicity                             0\n",
      "education_level                       0\n",
      "income_level                          0\n",
      "smoking_status                        0\n",
      "employment_status                     0\n",
      "family_history_diabetes               0\n",
      "hypertension_history                  0\n",
      "cardiovascular_history                0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (dataset_name, dataset) in [('Train data', orig_train_data), ('Test data', orig_test_data)]:\n",
    "    print(f\"##### {dataset_name} missing values #####\")\n",
    "    print(dataset.isnull().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da1c2e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:56.526532Z",
     "iopub.status.busy": "2025-12-12T23:49:56.526287Z",
     "iopub.status.idle": "2025-12-12T23:49:56.789639Z",
     "shell.execute_reply": "2025-12-12T23:49:56.788864Z"
    },
    "papermill": {
     "duration": 0.274467,
     "end_time": "2025-12-12T23:49:56.790740",
     "exception": false,
     "start_time": "2025-12-12T23:49:56.516273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train data categorical cols unique values #####\n",
      "gender:\n",
      "['Female' 'Male' 'Other']\n",
      "ethnicity:\n",
      "['Hispanic' 'White' 'Asian' 'Black' 'Other']\n",
      "education_level:\n",
      "['Highschool' 'Graduate' 'Postgraduate' 'No formal']\n",
      "income_level:\n",
      "['Lower-Middle' 'Upper-Middle' 'Low' 'Middle' 'High']\n",
      "smoking_status:\n",
      "['Current' 'Never' 'Former']\n",
      "employment_status:\n",
      "['Employed' 'Retired' 'Student' 'Unemployed']\n",
      "\n",
      "##### Test data categorical cols unique values #####\n",
      "gender:\n",
      "['Female' 'Male' 'Other']\n",
      "ethnicity:\n",
      "['White' 'Hispanic' 'Black' 'Asian' 'Other']\n",
      "education_level:\n",
      "['Highschool' 'Graduate' 'Postgraduate' 'No formal']\n",
      "income_level:\n",
      "['Middle' 'Low' 'Lower-Middle' 'Upper-Middle' 'High']\n",
      "smoking_status:\n",
      "['Former' 'Never' 'Current']\n",
      "employment_status:\n",
      "['Employed' 'Unemployed' 'Retired' 'Student']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (dataset_name, dataset) in [('Train data', orig_train_data), ('Test data', orig_test_data)]:\n",
    "    print(f\"##### {dataset_name} categorical cols unique values #####\")\n",
    "    for categorical_col_name in categorical_col_names:\n",
    "        print(f\"{categorical_col_name}:\")\n",
    "        print(dataset[categorical_col_name].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cad8d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:56.811737Z",
     "iopub.status.busy": "2025-12-12T23:49:56.811157Z",
     "iopub.status.idle": "2025-12-12T23:49:56.815501Z",
     "shell.execute_reply": "2025-12-12T23:49:56.814834Z"
    },
    "papermill": {
     "duration": 0.015673,
     "end_time": "2025-12-12T23:49:56.816611",
     "exception": false,
     "start_time": "2025-12-12T23:49:56.800938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KDE plots of target variable and numerical features\n",
    "if not SKIP_PLOTS:\n",
    "    plt.figure(figsize=(12, 24))\n",
    "    kdeplot_col_names = [target_col]\n",
    "    kdeplot_col_names.extend(numeric_col_names)\n",
    "    for i, col in enumerate(kdeplot_col_names, start=1):\n",
    "        plt.subplot(10, 2, i)\n",
    "        sns.kdeplot(data=orig_train_data, x=col, fill=True)\n",
    "        plt.tight_layout()\n",
    "        plt.title(f\"KDE plot of {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff029ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:56.836347Z",
     "iopub.status.busy": "2025-12-12T23:49:56.836140Z",
     "iopub.status.idle": "2025-12-12T23:49:56.840000Z",
     "shell.execute_reply": "2025-12-12T23:49:56.839452Z"
    },
    "papermill": {
     "duration": 0.014945,
     "end_time": "2025-12-12T23:49:56.840975",
     "exception": false,
     "start_time": "2025-12-12T23:49:56.826030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SKIP_PLOTS:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        orig_train_data[numeric_col_names].corr(),\n",
    "        cmap='Reds',\n",
    "        annot=True,\n",
    "        linewidths=2,\n",
    "        fmt='.2f',\n",
    "        vmin=-1,\n",
    "        vmax=1\n",
    "    )\n",
    "    plt.title('Correlation Matrix of Numerical Features', fontsize=18, pad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080946b4",
   "metadata": {
    "papermill": {
     "duration": 0.009345,
     "end_time": "2025-12-12T23:49:56.859687",
     "exception": false,
     "start_time": "2025-12-12T23:49:56.850342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61fbbb08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:56.879184Z",
     "iopub.status.busy": "2025-12-12T23:49:56.878740Z",
     "iopub.status.idle": "2025-12-12T23:49:57.033718Z",
     "shell.execute_reply": "2025-12-12T23:49:57.033119Z"
    },
    "papermill": {
     "duration": 0.166247,
     "end_time": "2025-12-12T23:49:57.035123",
     "exception": false,
     "start_time": "2025-12-12T23:49:56.868876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = orig_train_data.copy()\n",
    "test_data = orig_test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3a037",
   "metadata": {
    "papermill": {
     "duration": 0.009355,
     "end_time": "2025-12-12T23:49:57.054335",
     "exception": false,
     "start_time": "2025-12-12T23:49:57.044980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1 Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea13c93e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:57.074075Z",
     "iopub.status.busy": "2025-12-12T23:49:57.073874Z",
     "iopub.status.idle": "2025-12-12T23:49:57.934183Z",
     "shell.execute_reply": "2025-12-12T23:49:57.933208Z"
    },
    "papermill": {
     "duration": 0.871797,
     "end_time": "2025-12-12T23:49:57.935357",
     "exception": false,
     "start_time": "2025-12-12T23:49:57.063560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_level_encoded:\n",
      "{'No formal': 0, 'Highschool': 1, 'Graduate': 2, 'Postgraduate': 3}\n",
      "income_level_encoded:\n",
      "{'Low': 0, 'Lower-Middle': 1, 'Middle': 2, 'Upper-Middle': 3, 'High': 4}\n",
      "smoking_status_encoded:\n",
      "{'Never': 0, 'Former': 1, 'Current': 2}\n"
     ]
    }
   ],
   "source": [
    "# education level\n",
    "education_level_encoder = OrdinalEncoder(categories=[['No formal', 'Highschool', 'Graduate', 'Postgraduate']])\n",
    "train_data['education_level_encoded'] = education_level_encoder.fit_transform(train_data[['education_level']])\n",
    "test_data['education_level_encoded'] = education_level_encoder.fit_transform(test_data[['education_level']])\n",
    "\n",
    "# income level\n",
    "income_level_encoder = OrdinalEncoder(categories=[['Low', 'Lower-Middle','Middle', 'Upper-Middle', 'High']])\n",
    "train_data['income_level_encoded'] = income_level_encoder.fit_transform(train_data[['income_level']])\n",
    "test_data['income_level_encoded'] = income_level_encoder.fit_transform(test_data[['income_level']])\n",
    "\n",
    "# smoking status\n",
    "smoking_status_encoder = OrdinalEncoder(categories=[['Never', 'Former', 'Current']])\n",
    "train_data['smoking_status_encoded'] = smoking_status_encoder.fit_transform(train_data[['smoking_status']])\n",
    "test_data['smoking_status_encoded'] = smoking_status_encoder.fit_transform(test_data[['smoking_status']])\n",
    "\n",
    "# drop original cols\n",
    "for col in ['income_level', 'education_level', 'smoking_status']:\n",
    "    train_data.drop(col, axis=1, inplace=True)\n",
    "    test_data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# print out value maps to check assigned values are as expected\n",
    "for (encoded_col_name, encoder) in [\n",
    "    ('education_level_encoded', education_level_encoder),\n",
    "    ('income_level_encoded', income_level_encoder),\n",
    "    ('smoking_status_encoded', smoking_status_encoder),\n",
    "]:\n",
    "    categories = encoder.categories_[0]\n",
    "    value_map = { category: i for i, category in enumerate(categories) }\n",
    "    print(f\"{encoded_col_name}:\\n{value_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f906e",
   "metadata": {
    "papermill": {
     "duration": 0.010152,
     "end_time": "2025-12-12T23:49:57.955404",
     "exception": false,
     "start_time": "2025-12-12T23:49:57.945252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2996d2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:57.975150Z",
     "iopub.status.busy": "2025-12-12T23:49:57.974912Z",
     "iopub.status.idle": "2025-12-12T23:49:57.990577Z",
     "shell.execute_reply": "2025-12-12T23:49:57.990053Z"
    },
    "papermill": {
     "duration": 0.026999,
     "end_time": "2025-12-12T23:49:57.991695",
     "exception": false,
     "start_time": "2025-12-12T23:49:57.964696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_blood_pressure(df):\n",
    "    mask = df['diastolic_bp'] > df['systolic_bp']\n",
    "    df.loc[mask, ['systolic_bp', 'diastolic_bp']] = (\n",
    "        df.loc[mask, ['diastolic_bp', 'systolic_bp']].values\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_data = fix_blood_pressure(train_data)\n",
    "test_data = fix_blood_pressure(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6cc2bc",
   "metadata": {
    "papermill": {
     "duration": 0.009399,
     "end_time": "2025-12-12T23:49:58.010636",
     "exception": false,
     "start_time": "2025-12-12T23:49:58.001237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4 Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "322aba1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:58.030229Z",
     "iopub.status.busy": "2025-12-12T23:49:58.030009Z",
     "iopub.status.idle": "2025-12-12T23:49:58.036248Z",
     "shell.execute_reply": "2025-12-12T23:49:58.035736Z"
    },
    "papermill": {
     "duration": 0.017329,
     "end_time": "2025-12-12T23:49:58.037191",
     "exception": false,
     "start_time": "2025-12-12T23:49:58.019862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_generated_features(df):\n",
    "    # log transforms for skewed data\n",
    "    for col in ['triglycerides', 'ldl_cholesterol', 'cholesterol_total']:\n",
    "        df[f'log_{col}'] = np.log1p(df[col])\n",
    "\n",
    "    # medical ratios & interactions\n",
    "    df['cholesterol_ratio'] = df['cholesterol_total'] / (df['hdl_cholesterol'] + 1e-5)\n",
    "    df['ldl_hdl_ratio'] = df['ldl_cholesterol'] / (df['hdl_cholesterol'] + 1e-5)\n",
    "    df['pulse_pressure'] = df['systolic_bp'] - df['diastolic_bp']\n",
    "    df['mean_arterial_pressure'] = (df['systolic_bp'] + 2 * df['diastolic_bp']) / 3\n",
    "    df['age_x_bmi'] = df['age'] * df['bmi']\n",
    "    df['waist_x_bmi'] = df['waist_to_hip_ratio'] * df['bmi']\n",
    "    df['family_history_diabetes_x_log_triglycerides'] = df['family_history_diabetes'] * df['log_triglycerides']\n",
    "    df['hypertension_history_x_systolic_bp'] = df['hypertension_history'] * df['systolic_bp']\n",
    "    df['activity_x_diet'] = df['physical_activity_minutes_per_week'] * df['diet_score']\n",
    "\n",
    "    # squared\n",
    "    df['age_sq'] = df['age'] ** 2\n",
    "    df['bmi_sq'] = df['bmi'] ** 2\n",
    "    df['waist_to_hip_ratio_sq'] = df['waist_to_hip_ratio'] ** 2\n",
    "    df['systolic_bp_sq'] = df['systolic_bp'] ** 2\n",
    "\n",
    "    # risk grouping\n",
    "    df['comorbidity_count'] = (\n",
    "        df['hypertension_history'] + \n",
    "        df['cardiovascular_history'] + \n",
    "        df['family_history_diabetes']\n",
    "    )\n",
    "\n",
    "    # binning\n",
    "    df['bmi_cat'] = pd.cut(df['bmi'], bins=[-1, 25, 30, 100], labels=[0, 1, 2]).astype(int)\n",
    "    bmi_cat_encoder = OrdinalEncoder(categories=[[0, 1, 2]])\n",
    "    df['bmi_cat_encoded'] = bmi_cat_encoder.fit_transform(df[['bmi_cat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d2cc7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:58.057040Z",
     "iopub.status.busy": "2025-12-12T23:49:58.056602Z",
     "iopub.status.idle": "2025-12-12T23:49:58.061126Z",
     "shell.execute_reply": "2025-12-12T23:49:58.060550Z"
    },
    "papermill": {
     "duration": 0.015696,
     "end_time": "2025-12-12T23:49:58.062203",
     "exception": false,
     "start_time": "2025-12-12T23:49:58.046507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_kmeans_features(train_df, test_df, n_clusters):\n",
    "    features_to_cluster = [\n",
    "        'age', 'bmi', 'mean_arterial_pressure', 'cholesterol_ratio', 'log_triglycerides'\n",
    "    ]\n",
    "    \n",
    "    combined = pd.concat([train_df[features_to_cluster], test_df[features_to_cluster]], axis=0)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(combined)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_SEEDS[0], n_init=10)\n",
    "    clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "    train_df['cluster_label'] = clusters[:len(train_df)].astype(object)\n",
    "    test_df['cluster_label'] = clusters[len(train_df):].astype(object)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2adfae67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:49:58.081986Z",
     "iopub.status.busy": "2025-12-12T23:49:58.081443Z",
     "iopub.status.idle": "2025-12-12T23:50:11.778194Z",
     "shell.execute_reply": "2025-12-12T23:50:11.777590Z"
    },
    "papermill": {
     "duration": 13.707971,
     "end_time": "2025-12-12T23:50:11.779545",
     "exception": false,
     "start_time": "2025-12-12T23:49:58.071574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add generated features\n",
    "add_generated_features(train_data)\n",
    "add_generated_features(test_data)\n",
    "\n",
    "# apply clustering\n",
    "train_data, test_data = add_kmeans_features(train_data, test_data, n_clusters=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a068323e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:11.799710Z",
     "iopub.status.busy": "2025-12-12T23:50:11.799486Z",
     "iopub.status.idle": "2025-12-12T23:50:11.804427Z",
     "shell.execute_reply": "2025-12-12T23:50:11.803743Z"
    },
    "papermill": {
     "duration": 0.016081,
     "end_time": "2025-12-12T23:50:11.805474",
     "exception": false,
     "start_time": "2025-12-12T23:50:11.789393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'gender', 'ethnicity', 'employment_status', 'family_history_diabetes', 'hypertension_history', 'cardiovascular_history', 'diagnosed_diabetes', 'education_level_encoded', 'income_level_encoded', 'smoking_status_encoded', 'log_triglycerides', 'log_ldl_cholesterol', 'log_cholesterol_total', 'cholesterol_ratio', 'ldl_hdl_ratio', 'pulse_pressure', 'mean_arterial_pressure', 'age_x_bmi', 'waist_x_bmi', 'family_history_diabetes_x_log_triglycerides', 'hypertension_history_x_systolic_bp', 'activity_x_diet', 'age_sq', 'bmi_sq', 'waist_to_hip_ratio_sq', 'systolic_bp_sq', 'comorbidity_count', 'bmi_cat', 'bmi_cat_encoded', 'cluster_label'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612989c7",
   "metadata": {
    "papermill": {
     "duration": 0.009631,
     "end_time": "2025-12-12T23:50:11.824917",
     "exception": false,
     "start_time": "2025-12-12T23:50:11.815286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4 Remaining Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d50537d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:11.844581Z",
     "iopub.status.busy": "2025-12-12T23:50:11.844371Z",
     "iopub.status.idle": "2025-12-12T23:50:12.258856Z",
     "shell.execute_reply": "2025-12-12T23:50:12.258033Z"
    },
    "papermill": {
     "duration": 0.426082,
     "end_time": "2025-12-12T23:50:12.260325",
     "exception": false,
     "start_time": "2025-12-12T23:50:11.834243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_features = train_data.drop(target_col, axis=1).select_dtypes(include='object').columns.to_list()\n",
    "if len(cat_features) > 0:\n",
    "    for col in cat_features:\n",
    "        train_data[col] = train_data[col].astype('category')\n",
    "        test_data[col] = test_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2eafe",
   "metadata": {
    "papermill": {
     "duration": 0.009519,
     "end_time": "2025-12-12T23:50:12.279637",
     "exception": false,
     "start_time": "2025-12-12T23:50:12.270118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.5 MLP Data Preparation\n",
    "\n",
    "Since MLP cannot handle categorical features and requires the data to be scaled, the training and test data that will be used for it are prepared as separate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03ee3301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:12.299483Z",
     "iopub.status.busy": "2025-12-12T23:50:12.299233Z",
     "iopub.status.idle": "2025-12-12T23:50:14.371511Z",
     "shell.execute_reply": "2025-12-12T23:50:14.370713Z"
    },
    "papermill": {
     "duration": 2.083882,
     "end_time": "2025-12-12T23:50:14.372932",
     "exception": false,
     "start_time": "2025-12-12T23:50:12.289050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_mlp_data(df, cat_features):\n",
    "    df = df.copy()\n",
    "    df = pd.get_dummies(df, columns=cat_features, drop_first=True, dtype=int)\n",
    "    cols_to_scale = [c for c in df.columns if c != 'diagnosed_diabetes']\n",
    "    scaler = StandardScaler()\n",
    "    df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "    return df\n",
    "\n",
    "train_data_mlp = prepare_mlp_data(train_data, cat_features)\n",
    "test_data_mlp = prepare_mlp_data(test_data, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "054ab09f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.393304Z",
     "iopub.status.busy": "2025-12-12T23:50:14.393071Z",
     "iopub.status.idle": "2025-12-12T23:50:14.397605Z",
     "shell.execute_reply": "2025-12-12T23:50:14.397118Z"
    },
    "papermill": {
     "duration": 0.015653,
     "end_time": "2025-12-12T23:50:14.398496",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.382843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'family_history_diabetes', 'hypertension_history', 'cardiovascular_history', 'diagnosed_diabetes', 'education_level_encoded', 'income_level_encoded', 'smoking_status_encoded', 'log_triglycerides', 'log_ldl_cholesterol', 'log_cholesterol_total', 'cholesterol_ratio', 'ldl_hdl_ratio', 'pulse_pressure', 'mean_arterial_pressure', 'age_x_bmi', 'waist_x_bmi', 'family_history_diabetes_x_log_triglycerides', 'hypertension_history_x_systolic_bp', 'activity_x_diet', 'age_sq', 'bmi_sq', 'waist_to_hip_ratio_sq', 'systolic_bp_sq', 'comorbidity_count', 'bmi_cat', 'bmi_cat_encoded', 'gender_Male', 'gender_Other', 'ethnicity_Black', 'ethnicity_Hispanic', 'ethnicity_Other', 'ethnicity_White',\n",
       "       'employment_status_Retired', 'employment_status_Student', 'employment_status_Unemployed', 'cluster_label_1', 'cluster_label_2', 'cluster_label_3', 'cluster_label_4', 'cluster_label_5', 'cluster_label_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_mlp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6063d88",
   "metadata": {
    "papermill": {
     "duration": 0.009344,
     "end_time": "2025-12-12T23:50:14.417266",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.407922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Stacking Initial Setup\n",
    "\n",
    "We'll use stacking, an [ensemble learning](https://en.wikipedia.org/wiki/Ensemble_learning) strategy, to generate the predictions. As we'll need to gather predictions from various base models (a.k.a. level-0 models) to feed as input features to a meta model (a.k.a. level-1 model), in order to streamline the process of experimenting with different combinations of base models, some helper classes will be defined in this section. These classes can also be found [here](https://github.com/chuo-v/machine-learning-utils/blob/master/ensemble-learning/stacking/stacking_predictions_retriever.py) at one of my GitHub repositories used to organize some utilities I implemented for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01c4e0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.437398Z",
     "iopub.status.busy": "2025-12-12T23:50:14.437194Z",
     "iopub.status.idle": "2025-12-12T23:50:14.463736Z",
     "shell.execute_reply": "2025-12-12T23:50:14.463063Z"
    },
    "papermill": {
     "duration": 0.038375,
     "end_time": "2025-12-12T23:50:14.464945",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.426570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackingEstimator:\n",
    "    \"\"\"\n",
    "    A class representing an estimator that will be used for stacking, an ensemble learning strategy.\n",
    "\n",
    "    Intended to be used in conjunction with the `StackingPredictionsRetriever` class, which helps\n",
    "    retrieve predictions for multiple instances of `StackingEstimator`; as the predictions are saved\n",
    "    in files, on subsequent requests to retrieve predictions, even as the set of estimators has been\n",
    "    modified, the `StackingPredictionsRetriever` class can determine the predictions of estimators\n",
    "    that are non-stale and available (if any) by using the `get_hash` method of the `StackingEstimator`\n",
    "    class to determine the relevance and staleness of any saved predictions.\n",
    "\n",
    "    Proper usage of this class requires one important condition to be satisfied: the predictions made\n",
    "    using the estimator are determinstic, i.e. they are exactly the same everytime the estimator is\n",
    "    run with the same inputs (`name`, `params_dict`, `feature_names`, `get_predictions`).\n",
    "    \"\"\"\n",
    "    name = \"\"\n",
    "    params_dict = {}\n",
    "    feature_names = []\n",
    "    get_predictions = lambda: None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        feature_names: [str],\n",
    "        params_dict: {},\n",
    "        get_preds: FunctionType\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of `StackingEstimator`.\n",
    "\n",
    "        :param name:\n",
    "            A string representing a name for the estimator. It is used for the column names of\n",
    "            the training and test predictions for each estimator, and is also used as an input\n",
    "            to calculate a hash value for the estimator. It is recommended to use a different\n",
    "            name from the names used for other estimators passed to `StackingPredictionsRetriever`.\n",
    "        :param feature_names:\n",
    "            A list of strings representing the names of the features that will be used for the\n",
    "            estimator. It will be passed as an argument to `get_preds`. Internally, it is only\n",
    "            used as an input to calculate a hash value for the estimator.\n",
    "        :param params_dict:\n",
    "            A dictionary of parameters that will be specified for the estimator. It will be\n",
    "            passed as an argument to `get_preds`. Internally, it is only used as an input\n",
    "            to calculate a hash value for the estimator.\n",
    "        :param get_preds:\n",
    "            A function for getting the predictions for the estimator. It should only take two\n",
    "            arguments: 'params_dict' and 'feature_names', and should return predictions for\n",
    "            the training and test data (in that order) as a tuple of two `pandas.Series`.\n",
    "        \"\"\"\n",
    "        # parameter check\n",
    "        if not isinstance(name, str):\n",
    "            raise ValueError(\"`name` argument should be of type `str`\")\n",
    "        if not isinstance(feature_names, list):\n",
    "            raise ValueError(f\"`feature_names` argument for estimator \\\"{name}\\\" should be of type `list`\")\n",
    "        elif not all(isinstance(feature_name, str) for feature_name in feature_names):\n",
    "            raise ValueError(f\"`feature_names` argument for estimator \\\"{name}\\\" should only contain instances of `str`\")\n",
    "        if not isinstance(params_dict, dict):\n",
    "            raise ValueError(f\"`params_dict` argument for estimator \\\"{name}\\\" should be of type `dict`\")\n",
    "        get_preds_params = inspect.signature(get_preds).parameters.values()\n",
    "        get_preds_param_names = [param.name for param in get_preds_params]\n",
    "        if len(get_preds_param_names) != 2:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take two arguments\")\n",
    "        elif \"params_dict\" not in get_preds_param_names:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take a \\\"params_dict\\\" argument\")\n",
    "        elif \"feature_names\" not in get_preds_param_names:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take a \\\"feature_names\\\" argument\")\n",
    "\n",
    "        self.name = name\n",
    "        self.feature_names = feature_names\n",
    "        self.params_dict = params_dict\n",
    "        self.get_preds = get_preds\n",
    "\n",
    "    def get_hash_value(self):\n",
    "        \"\"\"\n",
    "        Calculates and returns a hash value for the estimator using\n",
    "        `name`, `feature_names` and `params_dict` as inputs.\n",
    "        \"\"\"\n",
    "        feature_names_str = \"_\".join(sorted(self.feature_names))\n",
    "        params_dict_str = \"_\".join(f\"{key}-{value}\" for (key, value) in sorted(self.params_dict.items()))\n",
    "        hash_input_str = \"_\".join([self.name, feature_names_str, params_dict_str])\n",
    "        md5_hash = hl.md5(hash_input_str.encode('utf-8')).hexdigest()\n",
    "        return md5_hash\n",
    "\n",
    "class StackingPredictionsRetriever:\n",
    "    \"\"\"\n",
    "    A class for streamlining stacking (an ensemble learning strategy) that saves predictions\n",
    "    from estimators to file so that when trying out different combinations of (base) estimators,\n",
    "    the predictions that are not stale can be reused, saving the time of having the estimators\n",
    "    make predictions again.\n",
    "\n",
    "    Intended to be used in conjunction with the `StackingEstimator` class. The `hash_value` of\n",
    "    `StackingEstimator` is used to determine the staleness and relevance of the predictions for\n",
    "    an estimator. The implementation for making predictions using an estimator needs to be\n",
    "    provided as a function to `get_preds` for `StackingEstimator`; when predictions need to be\n",
    "    made using an estimator, this class will call `get_preds` for the `StackingEstimator` instance.\n",
    "\n",
    "    Proper usage of this class requires one important condition to be satisfied: the predictions made\n",
    "    using the estimators are determinstic, i.e. they are exactly the same everytime a\n",
    "    `StackingEstimator` instance is run with the same inputs.\n",
    "    \"\"\"\n",
    "    estimators = []\n",
    "    working_dir_path = \"\"\n",
    "    train_preds_filename = \"\"\n",
    "    test_preds_filename = \"\"\n",
    "    preds_save_interval = 0\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators: [StackingEstimator],\n",
    "        working_dir_path: str,\n",
    "        train_preds_filename: str = \"train_preds\",\n",
    "        test_preds_filename: str = \"test_preds\",\n",
    "        preds_save_interval: int = 5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of `StackingPredictionsRetriever`.\n",
    "\n",
    "        :param estimators:\n",
    "            A list of `StackingEstimator` instances for which the class will retrieve predictions.\n",
    "        :param working_dir_path:\n",
    "            The path for the working directory where the files with predictions will be saved.\n",
    "        :param train_preds_filename:\n",
    "            The name of the file in which predictions for the training set will be stored.\n",
    "        :param test_preds_filename:\n",
    "            The name of the file in which predictions for the test set will be stored.\n",
    "        :param preds_save_interval:\n",
    "            An integer which specifies the interval at which predictions will be saved when\n",
    "            `get_preds` is called, corresponding to the number of estimators whose predictions\n",
    "            have been retrieved since the predictions were previously saved. Any estimators\n",
    "            whose predictions are not stale and therefore were not required to make predictions\n",
    "            again are not included in this number.\n",
    "        \"\"\"\n",
    "        # parameter check\n",
    "        if not isinstance(estimators, list):\n",
    "            raise ValueError(\"`estimators` must be passed as a list\")\n",
    "        if not all(isinstance(e, StackingEstimator) for e in estimators):\n",
    "            raise ValueError(\"`estimators` should only contain instances of `StackingEstimator`\")\n",
    "        if not isinstance(working_dir_path, str):\n",
    "            raise ValueError(\"`working_dir_path` argument should be of type `str`\")\n",
    "        if not isinstance(preds_save_interval, int):\n",
    "            raise ValueError(\"`preds_save_interval` argument should be of type `int`\")\n",
    "\n",
    "        self.estimators = estimators\n",
    "        self.working_dir_path = working_dir_path\n",
    "        self.train_preds_filename = train_preds_filename\n",
    "        self.test_preds_filename = test_preds_filename\n",
    "        self.preds_save_interval = preds_save_interval\n",
    "\n",
    "    def get_train_preds_file_path(self):\n",
    "        \"\"\"\n",
    "        Returns the file path for storing predictions for training data.\n",
    "        \"\"\"\n",
    "        return Path(f\"{self.working_dir_path}/{self.train_preds_filename}.csv\")\n",
    "\n",
    "    def get_test_preds_file_path(self):\n",
    "        \"\"\"\n",
    "        Returns the file path for storing predictions for test data.\n",
    "        \"\"\"\n",
    "        return Path(f\"{self.working_dir_path}/{self.test_preds_filename}.csv\")\n",
    "\n",
    "    def get_current_train_and_test_preds(self):\n",
    "        \"\"\"\n",
    "        Returns the current predictions for training and test data (in that order)\n",
    "        as a tuple of two `pandas.DataFrame`.\n",
    "\n",
    "        The predictions are attempted to be retrieved from the file paths returned\n",
    "        by `get_train_preds_file_path` and `get_test_preds_file_path`; if there are\n",
    "        any issues with doing so (e.g. file does not exist, dataframe is empty),\n",
    "        empty dataframes will be returned instead.\n",
    "        In the case an `pandas.errors.EmptyDataError` exception is raised when\n",
    "        reading from a file, the corresponding file will be removed.\n",
    "        \"\"\"\n",
    "        curr_train_preds = pd.DataFrame()\n",
    "        curr_test_preds = pd.DataFrame()\n",
    "        train_preds_file_path = self.get_train_preds_file_path()\n",
    "        test_preds_file_path = self.get_test_preds_file_path()\n",
    "\n",
    "        if train_preds_file_path.is_file():\n",
    "            try:\n",
    "                curr_train_preds = pd.read_csv(train_preds_file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                train_preds_file_path.unlink()\n",
    "        if test_preds_file_path.is_file():\n",
    "            try:\n",
    "                curr_test_preds = pd.read_csv(test_preds_file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                test_preds_file_path.unlink()\n",
    "\n",
    "        return curr_train_preds, curr_test_preds\n",
    "\n",
    "    def get_preds(self):\n",
    "        \"\"\"\n",
    "        Retrieves predictions from all estimators in `estimators`, storing them in\n",
    "        two files at the file paths specified by `working_dir_path`,\n",
    "        `train_preds_filename` and `test_preds_filename`.\n",
    "\n",
    "        If non-stale (relevant) predictions are found for an estimator, retrieval\n",
    "        of predictions by calling `get_preds` on the estimator will be skipped,\n",
    "        and the existing predictions for the estimator will be kept.\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Getting predictions..\")\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "\n",
    "        preds_retrieved_count = 0\n",
    "        num_preds_retrieved_but_not_yet_saved = 0\n",
    "        estimators_skipped = []\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            estimator_hash_value = estimator.get_hash_value()\n",
    "            estimator_name = f\"{estimator.name} ({estimator_hash_value})\"\n",
    "\n",
    "            # skip retrieving predictions for estimator if non-stale predictions are already available\n",
    "            train_preds_available = any(estimator_hash_value in col_name for col_name in curr_train_preds.columns)\n",
    "            test_preds_available = any(estimator_hash_value in col_name for col_name in curr_test_preds.columns)\n",
    "            if train_preds_available and test_preds_available:\n",
    "                estimators_skipped += [estimator_name]\n",
    "                continue\n",
    "\n",
    "            print(f\"[INFO] Getting predictions for estimator {estimator_name}\")\n",
    "            train_preds, test_preds = estimator.get_preds(estimator.params_dict, estimator.feature_names)\n",
    "            if not isinstance(train_preds, pd.core.series.Series):\n",
    "                raise ValueError(\"`train_preds` should be of type `pandas.Series`\")\n",
    "            if not isinstance(test_preds, pd.core.series.Series):\n",
    "                raise ValueError(\"`test_preds` should be of type `pandas.Series`\")\n",
    "            curr_train_preds[estimator_name] = train_preds\n",
    "            curr_test_preds[estimator_name] = test_preds\n",
    "            preds_retrieved_count += 1\n",
    "\n",
    "            # save predictions at an interval of `preds_save_interval`\n",
    "            if preds_retrieved_count % self.preds_save_interval == 0:\n",
    "                curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "                curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "                num_preds_retrieved_but_not_yet_saved = 0\n",
    "                print(\"[INFO] Saved predictions\")\n",
    "            else:\n",
    "                num_preds_retrieved_but_not_yet_saved += 1\n",
    "\n",
    "        if estimators_skipped:\n",
    "            estimators_skipped.sort()\n",
    "            formatted_estimators = \", \".join(estimators_skipped)\n",
    "            print(f\"[INFO] Skipped retrieving predictions for following estimators as their current ones are not stale:\\n{formatted_estimators}\")\n",
    "\n",
    "        if num_preds_retrieved_but_not_yet_saved != 0:\n",
    "            curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            print(\"[INFO] Saved predictions\")\n",
    "\n",
    "        print(\"[INFO] Finished getting all predictions\")\n",
    "\n",
    "    def sync_preds(self):\n",
    "        \"\"\"\n",
    "        Syncs the predictions stored at the two file paths specified by\n",
    "        `working_dir_path`, `train_preds_filename` and `test_preds_filename` by\n",
    "        removing predictions for any estimator that is not currently in `estimators`.\n",
    "\n",
    "        Note that new predictions for estimators that do not currently have predictions\n",
    "        in the files will not be added; `get_preds` should be used for this purpose\n",
    "        instead.\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Syncing predictions..\")\n",
    "        estimator_hash_values = [estimator.get_hash_value() for estimator in self.estimators]\n",
    "        should_remove_col = lambda col_name: not any(hash_value in col_name for hash_value in estimator_hash_values)\n",
    "\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "\n",
    "        if not curr_train_preds.empty:\n",
    "            col_names_to_remove = [col_name for col_name in curr_train_preds.columns if should_remove_col(col_name)]\n",
    "            if col_names_to_remove:\n",
    "                print(f\"[INFO] Dropping columns for following estimators from training predictions:\\n{col_names_to_remove}\")\n",
    "                curr_train_preds.drop(columns=col_names_to_remove, inplace=True)\n",
    "                curr_train_preds.to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            else:\n",
    "                print(f\"[INFO] No columns for training predictions were dropped\")\n",
    "        if not curr_test_preds.empty:\n",
    "            col_names_to_remove = [col_name for col_name in curr_test_preds.columns if should_remove_col(col_name)]\n",
    "            if col_names_to_remove:\n",
    "                print(f\"[INFO] Dropping columns for following estimators from test predictions:\\n{col_names_to_remove}\")\n",
    "                curr_test_preds.drop(columns=col_names_to_remove, inplace=True)\n",
    "                curr_test_preds.to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            else:\n",
    "                print(f\"[INFO] No columns for test predictions were dropped\")\n",
    "\n",
    "        print(\"[INFO] Finished syncing predictions\")\n",
    "\n",
    "    def import_preds(self, input_dir_path):\n",
    "        \"\"\"\n",
    "        Imports predictions stored at the two file paths at `input_dir_path` with\n",
    "        `train_preds_filename` and `test_preds_filename` as their filenames. If no\n",
    "        such files are found, no predictions will be imported.\n",
    "\n",
    "        Only predictions for estimators specified in `estimators` will be imported.\n",
    "        Any predictions for estimators that were already available will be overwritten\n",
    "        with predictions for the same estimators found in the files at `input_dir_path`.\n",
    "\n",
    "        :param input_dir_path:\n",
    "            The path to the directory for the training and test predictions files.\n",
    "            The file names are expected to be the same as `train_preds_filename`\n",
    "            and `test_preds_filename`\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Importing predictions..\")\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "        input_train_preds = pd.DataFrame()\n",
    "        input_test_preds = pd.DataFrame()\n",
    "\n",
    "        input_train_preds_path = Path(f\"{input_dir_path}/{self.train_preds_filename}.csv\")\n",
    "        input_test_preds_path = Path(f\"{input_dir_path}/{self.test_preds_filename}.csv\")\n",
    "        if input_train_preds_path.is_file():\n",
    "            try:\n",
    "                input_train_preds = pd.read_csv(input_train_preds_path)\n",
    "            except: pass\n",
    "        if input_test_preds_path.is_file():\n",
    "            try:\n",
    "                input_test_preds = pd.read_csv(input_test_preds_path)\n",
    "            except: pass\n",
    "\n",
    "        estimators_with_imported_train_preds = []\n",
    "        estimators_with_imported_test_preds = []\n",
    "        for estimator in self.estimators:\n",
    "            estimator_hash_value = estimator.get_hash_value()\n",
    "            estimator_name = f\"{estimator.name} ({estimator_hash_value})\"\n",
    "            train_preds_available = any(estimator_hash_value in col_name for col_name in input_train_preds.columns)\n",
    "            test_preds_available = any(estimator_hash_value in col_name for col_name in input_test_preds.columns)\n",
    "\n",
    "            if train_preds_available:\n",
    "                curr_train_preds[estimator_name] = input_train_preds[estimator_name]\n",
    "                estimators_with_imported_train_preds += [estimator_name]\n",
    "            if test_preds_available:\n",
    "                curr_test_preds[estimator_name] = input_test_preds[estimator_name]\n",
    "                estimators_with_imported_test_preds += [estimator_name]\n",
    "\n",
    "        if not estimators_with_imported_train_preds:\n",
    "            print(\"[INFO] No train predictions were imported\")\n",
    "        else:\n",
    "            curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            formatted_estimators = \", \".join(estimators_with_imported_train_preds)\n",
    "            print(f\"[INFO] {len(estimators_with_imported_train_preds)} train predictions were imported:\\n{formatted_estimators}\")\n",
    "        if not estimators_with_imported_test_preds:\n",
    "            print(\"[INFO] No test predictions were imported\")\n",
    "        else:\n",
    "            curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            formatted_estimators = \", \".join(estimators_with_imported_test_preds)\n",
    "            print(f\"[INFO] {len(estimators_with_imported_test_preds)} test predictions were imported:\\n{formatted_estimators}\")\n",
    "        \n",
    "        print(\"[INFO] Finished importing predictions\")\n",
    "\n",
    "    def clear_preds(self):\n",
    "        \"\"\"\n",
    "        Removes all stored predictions by deleting the two files at filepaths specified\n",
    "        by `working_dir_path`, `train_preds_filename` and `test_preds_filename`.\n",
    "        \"\"\"\n",
    "        train_preds_file_path = self.get_train_preds_file_path()\n",
    "        test_preds_file_path = self.get_test_preds_file_path()\n",
    "\n",
    "        if train_preds_file_path.is_file():\n",
    "            train_preds_file_path.unlink()\n",
    "        if test_preds_file_path.is_file():\n",
    "            test_preds_file_path.unlink()\n",
    "\n",
    "        print(\"[INFO] Finished clearing predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124db4d9",
   "metadata": {
    "papermill": {
     "duration": 0.009437,
     "end_time": "2025-12-12T23:50:14.483843",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.474406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we'll simply create a variable for storing the estimators (`StackingEstimator` instances) that we'll pass to the `StackingPredictionsRetriever` class for getting all the predictions from our base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87d573b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.503502Z",
     "iopub.status.busy": "2025-12-12T23:50:14.503131Z",
     "iopub.status.idle": "2025-12-12T23:50:14.506140Z",
     "shell.execute_reply": "2025-12-12T23:50:14.505508Z"
    },
    "papermill": {
     "duration": 0.014038,
     "end_time": "2025-12-12T23:50:14.507185",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.493147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5ccb9",
   "metadata": {
    "papermill": {
     "duration": 0.009502,
     "end_time": "2025-12-12T23:50:14.526408",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.516906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Base Model Definitions\n",
    "\n",
    "Custom implementations of some of the base models that require them can be found in this section.\n",
    "\n",
    "## 6.1 MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8da8b19f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.546470Z",
     "iopub.status.busy": "2025-12-12T23:50:14.546262Z",
     "iopub.status.idle": "2025-12-12T23:50:14.556792Z",
     "shell.execute_reply": "2025-12-12T23:50:14.556023Z"
    },
    "papermill": {
     "duration": 0.022423,
     "end_time": "2025-12-12T23:50:14.558281",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.535858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_dim, hidden_layers, dropout, learning_rate, batch_size, weight_decay, epochs, device, patience=10):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.patience = patience\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        layers = []\n",
    "        in_dim = self.input_dim\n",
    "        for h_dim in self.hidden_layers:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.BatchNorm1d(h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout))\n",
    "            in_dim = h_dim\n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        return nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        X_train_t = torch.FloatTensor(X_train.values).to(self.device)\n",
    "        y_train_t = torch.FloatTensor(y_train.values).to(self.device).unsqueeze(1)\n",
    "        train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        val_loader = None\n",
    "        if X_val is not None and y_val is not None:\n",
    "            X_val_t = torch.FloatTensor(X_val.values).to(self.device)\n",
    "            y_val_t = torch.FloatTensor(y_val.values).to(self.device).unsqueeze(1)\n",
    "            val_dataset = TensorDataset(X_val_t, y_val_t)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.batch_size*2, shuffle=False)\n",
    "\n",
    "        self.model = self.build_model()\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self.model(X_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            if val_loader:\n",
    "                self.model.eval() # switch to eval mode (disable dropout)\n",
    "                val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for X_v, y_v in val_loader:\n",
    "                        val_pred = self.model(X_v)\n",
    "                        val_loss += criterion(val_pred, y_v).item()\n",
    "                \n",
    "                # check for improvement\n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "                \n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    patience_counter = 0\n",
    "                    # save the best model weights\n",
    "                    best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                self.model.train() # switch back to train mode\n",
    "\n",
    "                if patience_counter >= self.patience:\n",
    "                    break\n",
    "\n",
    "        if best_model_state:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        X_t = torch.FloatTensor(X.values).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(X_t).cpu().numpy()\n",
    "        return np.column_stack((1 - preds, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9592a8",
   "metadata": {
    "papermill": {
     "duration": 0.009533,
     "end_time": "2025-12-12T23:50:14.577252",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.567719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Base Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67a5602c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.596909Z",
     "iopub.status.busy": "2025-12-12T23:50:14.596688Z",
     "iopub.status.idle": "2025-12-12T23:50:14.599854Z",
     "shell.execute_reply": "2025-12-12T23:50:14.599179Z"
    },
    "papermill": {
     "duration": 0.01422,
     "end_time": "2025-12-12T23:50:14.600882",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.586662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip hyperparameter tuning when it's not needed; set to `False` to do the tuning\n",
    "SKIP_BASE_MODEL_HYPERPARAMETER_TUNING = False\n",
    "\n",
    "# value set for early stopping for base models that support it; this value will be used for actual model training as well\n",
    "BASE_MODEL_EARLY_STOPPING_ROUNDS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ef93cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.620390Z",
     "iopub.status.busy": "2025-12-12T23:50:14.620187Z",
     "iopub.status.idle": "2025-12-12T23:50:14.623423Z",
     "shell.execute_reply": "2025-12-12T23:50:14.622946Z"
    },
    "papermill": {
     "duration": 0.014266,
     "end_time": "2025-12-12T23:50:14.624523",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.610257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseModelOptunaStudyEstimator(Enum):\n",
    "    CATBOOSTCLASSIFIER = \"CatBoostClassifier\"\n",
    "    XGBCLASSIFIER = \"XGBClassifier\"\n",
    "    XGBRFCLASSIFIER = \"XGBRFClassifier\"\n",
    "    MLPCLASSIFIER = \"MLPClassifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d317c6",
   "metadata": {
    "papermill": {
     "duration": 0.009787,
     "end_time": "2025-12-12T23:50:14.643899",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.634112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Manually configure the values for the following variables for different studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0b8a72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.664210Z",
     "iopub.status.busy": "2025-12-12T23:50:14.664015Z",
     "iopub.status.idle": "2025-12-12T23:50:14.667201Z",
     "shell.execute_reply": "2025-12-12T23:50:14.666681Z"
    },
    "papermill": {
     "duration": 0.014875,
     "end_time": "2025-12-12T23:50:14.668236",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.653361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# estimator to use for Optuna study\n",
    "BASE_MODEL_OPTUNA_STUDY_ESTIMATOR = BaseModelOptunaStudyEstimator.XGBCLASSIFIER\n",
    "\n",
    "# maximum number of trials Optuna will conduct for the optimization\n",
    "BASE_MODEL_OPTUNA_STUDY_NUM_TRIALS = 150\n",
    "\n",
    "# number of splits to use for Stratified K-Fold Cross-Validation for Optuna study\n",
    "BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9014738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.688048Z",
     "iopub.status.busy": "2025-12-12T23:50:14.687807Z",
     "iopub.status.idle": "2025-12-12T23:50:14.702189Z",
     "shell.execute_reply": "2025-12-12T23:50:14.701611Z"
    },
    "papermill": {
     "duration": 0.025681,
     "end_time": "2025-12-12T23:50:14.703257",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.677576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_base_model_optuna_params(trial, study_estimator):\n",
    "    if study_estimator == BaseModelOptunaStudyEstimator.CATBOOSTCLASSIFIER:\n",
    "        return {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.1, log=True),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 30),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 30),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0, 20),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 20),\n",
    "        }\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER:\n",
    "        return {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.03, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 8, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 0.7),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "            'alpha': trial.suggest_float('alpha', 0.1, 5.0, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 0.1, 1.0),\n",
    "            'lambda': trial.suggest_float('lambda', 1.0, 10.0, log=True),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 40, 100),\n",
    "        }\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBRFCLASSIFIER:\n",
    "        return {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 10, 25),\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 0.9),\n",
    "            'colsample_bynode': trial.suggest_float('colsample_bynode', 0.4, 0.9),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        }\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.MLPCLASSIFIER:\n",
    "        return {\n",
    "            'hidden_layers': trial.suggest_categorical('hidden_layers', [\n",
    "                (128, 64), \n",
    "                (256, 128),\n",
    "                (512, 256, 128),\n",
    "                (128, 64, 32)\n",
    "            ]),\n",
    "            'dropout': trial.suggest_float('dropout', 0.1, 0.4),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "            'batch_size': trial.suggest_categorical('batch_size', [512, 1024, 2048]),\n",
    "            'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-4, log=True),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optuna study estimator\")\n",
    "\n",
    "def get_base_model_predictions(study_estimator, trial_params, X_train_fold, y_train_fold, X_validation_fold, y_validation_fold):\n",
    "    if study_estimator == BaseModelOptunaStudyEstimator.CATBOOSTCLASSIFIER:\n",
    "        model = CatBoostClassifier(\n",
    "            **trial_params,\n",
    "            iterations=30000,\n",
    "            use_best_model=True,\n",
    "            cat_features=cat_features,\n",
    "            loss_function='Logloss',\n",
    "            eval_metric='AUC',\n",
    "            task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
    "            devices='0',\n",
    "            metric_period=1000,\n",
    "            random_seed=RANDOM_SEEDS[0],\n",
    "            verbose=False,\n",
    "            allow_writing_files=False\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_validation_fold, y_validation_fold),\n",
    "            early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER:\n",
    "        model = XGBClassifier(\n",
    "            **trial_params,\n",
    "            n_estimators=30000,\n",
    "            tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            enable_categorical=True,\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='auc',\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_SEEDS[0],\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "            early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS,\n",
    "            verbose=False\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBRFCLASSIFIER:\n",
    "        model = XGBRFClassifier(\n",
    "            **trial_params,\n",
    "            tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            enable_categorical=True,\n",
    "            learning_rate=1.0,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_SEEDS[0],\n",
    "            verbose=0\n",
    "        )\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.MLPCLASSIFIER:\n",
    "        model = MLPClassifier(\n",
    "            **trial_params,\n",
    "            input_dim=X_train_fold.shape[1],\n",
    "            epochs=100,\n",
    "            patience=10,\n",
    "            device=DEVICE\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            X_val=X_validation_fold, y_val=y_validation_fold\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optuna study estimator\")\n",
    "\n",
    "def base_model_optuna_study_objective(trial):\n",
    "    base_model_params = get_base_model_optuna_params(trial, BASE_MODEL_OPTUNA_STUDY_ESTIMATOR)\n",
    "\n",
    "    if BASE_MODEL_OPTUNA_STUDY_ESTIMATOR == BaseModelOptunaStudyEstimator.MLPCLASSIFIER:\n",
    "        optuna_train_data = train_data_mlp\n",
    "    else:\n",
    "        optuna_train_data = train_data\n",
    "\n",
    "    base_model_optuna_study_skf = StratifiedKFold(n_splits=BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS, shuffle=True, random_state=RANDOM_SEEDS[0])\n",
    "    base_model_optuna_study_skf_splits = base_model_optuna_study_skf.split(optuna_train_data.drop(target_col, axis=1), optuna_train_data[target_col])\n",
    "    base_model_optuna_study_skf_enumeration = enumerate(base_model_optuna_study_skf_splits)\n",
    "\n",
    "    total_roc_auc = 0\n",
    "\n",
    "    for fold, (train_indices, validation_indices) in base_model_optuna_study_skf_enumeration:\n",
    "        X_train_fold = optuna_train_data.drop(target_col, axis=1).iloc[train_indices]\n",
    "        X_validation_fold = optuna_train_data.drop(target_col, axis=1).iloc[validation_indices]\n",
    "        y_train_fold = optuna_train_data[target_col].iloc[train_indices]\n",
    "        y_validation_fold = optuna_train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "        y_validation_pred_proba = get_base_model_predictions(\n",
    "            BASE_MODEL_OPTUNA_STUDY_ESTIMATOR,\n",
    "            base_model_params,\n",
    "            X_train_fold, y_train_fold,\n",
    "            X_validation_fold, y_validation_fold\n",
    "        )\n",
    "        roc_auc_fold = roc_auc_score(y_validation_fold, y_validation_pred_proba)\n",
    "        total_roc_auc += roc_auc_fold\n",
    "\n",
    "        trial.report(roc_auc_fold, step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    average_roc_auc = total_roc_auc / BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS\n",
    "    return average_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea627d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T23:50:14.722980Z",
     "iopub.status.busy": "2025-12-12T23:50:14.722750Z",
     "iopub.status.idle": "2025-12-13T06:10:03.039500Z",
     "shell.execute_reply": "2025-12-13T06:10:03.038701Z"
    },
    "papermill": {
     "duration": 22788.344585,
     "end_time": "2025-12-13T06:10:03.057230",
     "exception": false,
     "start_time": "2025-12-12T23:50:14.712645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-12-12 23:50:14,726] A new study created in memory with name: no-name-2580ac7c-7ca7-4eee-a475-c900c91b6df7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started base model hyperparameter tuning for XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-12 23:51:45,449] Trial 0 finished with value: 0.724307446457349 and parameters: {'learning_rate': 0.01853822952582478, 'max_depth': 10, 'subsample': 0.541036846787766, 'colsample_bytree': 0.7389400029713178, 'alpha': 0.6413430838492891, 'gamma': 0.973501399275845, 'lambda': 6.890243453717046, 'min_child_weight': 54}. Best is trial 0 with value: 0.724307446457349.\n",
      "[I 2025-12-12 23:53:13,185] Trial 1 finished with value: 0.7252673377239155 and parameters: {'learning_rate': 0.020282210566753434, 'max_depth': 8, 'subsample': 0.6493842649593238, 'colsample_bytree': 0.8596303219982993, 'alpha': 3.4060106157778764, 'gamma': 0.35272588463082466, 'lambda': 1.198459927931261, 'min_child_weight': 93}. Best is trial 1 with value: 0.7252673377239155.\n",
      "[I 2025-12-12 23:55:08,669] Trial 2 finished with value: 0.7248215905066019 and parameters: {'learning_rate': 0.013306466621792589, 'max_depth': 10, 'subsample': 0.6304195985619386, 'colsample_bytree': 0.8984733694483262, 'alpha': 0.430713865334983, 'gamma': 0.8638106756693161, 'lambda': 4.869838951115883, 'min_child_weight': 81}. Best is trial 1 with value: 0.7252673377239155.\n",
      "[I 2025-12-12 23:56:20,801] Trial 3 finished with value: 0.7256379905326708 and parameters: {'learning_rate': 0.024871647927874368, 'max_depth': 8, 'subsample': 0.6306456455029223, 'colsample_bytree': 0.5137977312126626, 'alpha': 0.49963587944126425, 'gamma': 0.448011888903286, 'lambda': 1.5636848645528767, 'min_child_weight': 98}. Best is trial 3 with value: 0.7256379905326708.\n",
      "[I 2025-12-12 23:59:02,816] Trial 4 finished with value: 0.7255674019714117 and parameters: {'learning_rate': 0.010041742995362112, 'max_depth': 8, 'subsample': 0.6880165562253513, 'colsample_bytree': 0.7598452319753041, 'alpha': 0.31820412623919697, 'gamma': 0.9272886444900282, 'lambda': 7.653463389921847, 'min_child_weight': 45}. Best is trial 3 with value: 0.7256379905326708.\n",
      "[I 2025-12-12 23:59:28,450] Trial 5 pruned. \n",
      "[I 2025-12-13 00:00:02,781] Trial 6 pruned. \n",
      "[I 2025-12-13 00:01:58,520] Trial 7 finished with value: 0.7255079300204099 and parameters: {'learning_rate': 0.013874295065492754, 'max_depth': 8, 'subsample': 0.6898131672818617, 'colsample_bytree': 0.8653834899372492, 'alpha': 0.6507382440141288, 'gamma': 0.7003035422303495, 'lambda': 7.566894866674863, 'min_child_weight': 92}. Best is trial 3 with value: 0.7256379905326708.\n",
      "[I 2025-12-13 00:06:00,891] Trial 8 finished with value: 0.7260092344982082 and parameters: {'learning_rate': 0.006572523417005223, 'max_depth': 8, 'subsample': 0.6929169014807113, 'colsample_bytree': 0.5803590021506524, 'alpha': 0.1281813372222567, 'gamma': 0.8052568892528539, 'lambda': 8.304127198618376, 'min_child_weight': 79}. Best is trial 8 with value: 0.7260092344982082.\n",
      "[I 2025-12-13 00:06:22,320] Trial 9 pruned. \n",
      "[I 2025-12-13 00:10:07,403] Trial 10 finished with value: 0.7257647207270108 and parameters: {'learning_rate': 0.006945551040154136, 'max_depth': 8, 'subsample': 0.6776205937593869, 'colsample_bytree': 0.738067394250938, 'alpha': 0.12148796810851215, 'gamma': 0.8673781098670665, 'lambda': 9.79801940899215, 'min_child_weight': 91}. Best is trial 8 with value: 0.7260092344982082.\n",
      "[I 2025-12-13 00:14:51,532] Trial 11 finished with value: 0.7257590191028189 and parameters: {'learning_rate': 0.005110498177521869, 'max_depth': 8, 'subsample': 0.6290122894220526, 'colsample_bytree': 0.6482492026217399, 'alpha': 0.1423596692417751, 'gamma': 0.8787385301640471, 'lambda': 9.72302839806015, 'min_child_weight': 87}. Best is trial 8 with value: 0.7260092344982082.\n",
      "[I 2025-12-13 00:18:16,089] Trial 12 finished with value: 0.7259052622504766 and parameters: {'learning_rate': 0.007711066672100142, 'max_depth': 9, 'subsample': 0.6969132907225075, 'colsample_bytree': 0.5635033086680686, 'alpha': 0.3368402699247187, 'gamma': 0.8629675971569439, 'lambda': 5.176939325606462, 'min_child_weight': 97}. Best is trial 8 with value: 0.7260092344982082.\n",
      "[I 2025-12-13 00:21:01,604] Trial 13 finished with value: 0.7258071864869485 and parameters: {'learning_rate': 0.010449755449662325, 'max_depth': 9, 'subsample': 0.6938183132052087, 'colsample_bytree': 0.5601599798625502, 'alpha': 0.739842964676345, 'gamma': 0.736512834194301, 'lambda': 5.553406648726938, 'min_child_weight': 83}. Best is trial 8 with value: 0.7260092344982082.\n",
      "[I 2025-12-13 00:24:54,271] Trial 14 finished with value: 0.726091785239313 and parameters: {'learning_rate': 0.006827608315154258, 'max_depth': 8, 'subsample': 0.6954493432136487, 'colsample_bytree': 0.5864549727530528, 'alpha': 0.2842104146444031, 'gamma': 0.8223524108501956, 'lambda': 1.9113576926398688, 'min_child_weight': 94}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:29:16,975] Trial 15 finished with value: 0.7259182215515029 and parameters: {'learning_rate': 0.005831483977486663, 'max_depth': 8, 'subsample': 0.6376221220643186, 'colsample_bytree': 0.6154259775829711, 'alpha': 0.18077010640131386, 'gamma': 0.8396429903525959, 'lambda': 1.3625980977612444, 'min_child_weight': 86}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:32:53,740] Trial 16 finished with value: 0.72595887796226 and parameters: {'learning_rate': 0.007606621238409101, 'max_depth': 8, 'subsample': 0.6583605123977453, 'colsample_bytree': 0.501905679721199, 'alpha': 0.20507151702302176, 'gamma': 0.44679583428249475, 'lambda': 6.234538205016482, 'min_child_weight': 58}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:33:33,682] Trial 17 pruned. \n",
      "[I 2025-12-13 00:35:04,735] Trial 18 pruned. \n",
      "[I 2025-12-13 00:37:08,160] Trial 19 finished with value: 0.7258181526114799 and parameters: {'learning_rate': 0.012650339494451959, 'max_depth': 8, 'subsample': 0.6646658644788397, 'colsample_bytree': 0.5019066368684592, 'alpha': 0.193918075976858, 'gamma': 0.9330321052879064, 'lambda': 6.342167670678555, 'min_child_weight': 72}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:41:52,687] Trial 20 finished with value: 0.7258098720157863 and parameters: {'learning_rate': 0.005659686794896338, 'max_depth': 8, 'subsample': 0.6949271687469474, 'colsample_bytree': 0.7510060453534437, 'alpha': 1.6010763600045914, 'gamma': 0.741871319907577, 'lambda': 2.2559922839146824, 'min_child_weight': 85}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:44:19,368] Trial 21 finished with value: 0.7259307902868978 and parameters: {'learning_rate': 0.012015471779208111, 'max_depth': 8, 'subsample': 0.6774981517104589, 'colsample_bytree': 0.5129149900390877, 'alpha': 0.16033042425335817, 'gamma': 0.3404726335620671, 'lambda': 5.982771005420194, 'min_child_weight': 65}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:46:59,791] Trial 22 finished with value: 0.7260587807493769 and parameters: {'learning_rate': 0.010551249531519513, 'max_depth': 8, 'subsample': 0.6988279047297241, 'colsample_bytree': 0.5440592749732243, 'alpha': 0.5833469469786836, 'gamma': 0.9015801743265692, 'lambda': 1.710025373663531, 'min_child_weight': 86}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:49:30,297] Trial 23 finished with value: 0.7259424070060936 and parameters: {'learning_rate': 0.011009086298827913, 'max_depth': 8, 'subsample': 0.6853985909556295, 'colsample_bytree': 0.5601550985492815, 'alpha': 0.5118099341377415, 'gamma': 0.9866328946606298, 'lambda': 1.2239448343916526, 'min_child_weight': 74}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:52:03,181] Trial 24 finished with value: 0.7259354712881456 and parameters: {'learning_rate': 0.010620800380397824, 'max_depth': 8, 'subsample': 0.6822031969826652, 'colsample_bytree': 0.5963506351016381, 'alpha': 1.0957598538224986, 'gamma': 0.8079598241788097, 'lambda': 1.9202056263475131, 'min_child_weight': 100}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 00:57:04,089] Trial 25 finished with value: 0.7260633482100366 and parameters: {'learning_rate': 0.005021838756389544, 'max_depth': 8, 'subsample': 0.6996531041237706, 'colsample_bytree': 0.5532235252520529, 'alpha': 0.30342476359484377, 'gamma': 0.4511404202290987, 'lambda': 2.5136207515104725, 'min_child_weight': 78}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 01:00:43,516] Trial 26 finished with value: 0.7260186293003553 and parameters: {'learning_rate': 0.006945457123067781, 'max_depth': 8, 'subsample': 0.6827101559968956, 'colsample_bytree': 0.5582564171216395, 'alpha': 0.6519994189261319, 'gamma': 0.45822843033747673, 'lambda': 2.031556057171611, 'min_child_weight': 81}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 01:03:27,125] Trial 27 finished with value: 0.7260497612613591 and parameters: {'learning_rate': 0.010055073811222281, 'max_depth': 8, 'subsample': 0.6886199728913645, 'colsample_bytree': 0.5655963366842792, 'alpha': 0.10271072294630063, 'gamma': 0.9839095614582551, 'lambda': 1.8873125472563024, 'min_child_weight': 95}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 01:08:05,179] Trial 28 finished with value: 0.7259152971613849 and parameters: {'learning_rate': 0.005539622087892223, 'max_depth': 8, 'subsample': 0.6714735226859774, 'colsample_bytree': 0.6137813685723326, 'alpha': 0.14664669177967216, 'gamma': 0.28188810402754755, 'lambda': 4.091481191938992, 'min_child_weight': 90}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 01:09:16,242] Trial 29 pruned. \n",
      "[I 2025-12-13 01:10:38,471] Trial 30 pruned. \n",
      "[I 2025-12-13 01:13:25,706] Trial 31 finished with value: 0.726033025912414 and parameters: {'learning_rate': 0.009515368679562534, 'max_depth': 8, 'subsample': 0.6839914277822917, 'colsample_bytree': 0.5084834035831246, 'alpha': 0.13438508551853834, 'gamma': 0.9535701689580618, 'lambda': 2.276675254443925, 'min_child_weight': 96}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 01:14:11,087] Trial 32 pruned. \n",
      "[I 2025-12-13 01:15:48,043] Trial 33 pruned. \n",
      "[I 2025-12-13 01:16:16,294] Trial 34 pruned. \n",
      "[I 2025-12-13 01:18:10,728] Trial 35 finished with value: 0.7259131221499908 and parameters: {'learning_rate': 0.014919259457861407, 'max_depth': 8, 'subsample': 0.6708350178752711, 'colsample_bytree': 0.5091825506738388, 'alpha': 0.1399540145791304, 'gamma': 0.5435015569107606, 'lambda': 1.5014770541751123, 'min_child_weight': 77}. Best is trial 14 with value: 0.726091785239313.\n",
      "[I 2025-12-13 01:21:53,373] Trial 36 finished with value: 0.7261205687315853 and parameters: {'learning_rate': 0.007197289488394008, 'max_depth': 8, 'subsample': 0.698127370531509, 'colsample_bytree': 0.548530356901066, 'alpha': 0.4669142635628854, 'gamma': 0.9320745844814049, 'lambda': 1.2890830045073542, 'min_child_weight': 100}. Best is trial 36 with value: 0.7261205687315853.\n",
      "[I 2025-12-13 01:26:35,514] Trial 37 finished with value: 0.7259781085040364 and parameters: {'learning_rate': 0.005758165858673696, 'max_depth': 8, 'subsample': 0.654433317549044, 'colsample_bytree': 0.5490864976693367, 'alpha': 1.1836576332360322, 'gamma': 0.9267445532403887, 'lambda': 1.4354081259936426, 'min_child_weight': 87}. Best is trial 36 with value: 0.7261205687315853.\n",
      "[I 2025-12-13 01:27:43,943] Trial 38 pruned. \n",
      "[I 2025-12-13 01:28:49,810] Trial 39 pruned. \n",
      "[I 2025-12-13 01:31:58,269] Trial 40 finished with value: 0.7260379937909988 and parameters: {'learning_rate': 0.008719029581848876, 'max_depth': 8, 'subsample': 0.6946611687779244, 'colsample_bytree': 0.5715212558921801, 'alpha': 0.38892083177867565, 'gamma': 0.7434863875707097, 'lambda': 1.2490628103357335, 'min_child_weight': 97}. Best is trial 36 with value: 0.7261205687315853.\n",
      "[I 2025-12-13 01:33:34,870] Trial 41 pruned. \n",
      "[I 2025-12-13 01:34:20,001] Trial 42 pruned. \n",
      "[I 2025-12-13 01:38:23,317] Trial 43 finished with value: 0.7259732666303845 and parameters: {'learning_rate': 0.006124817446984271, 'max_depth': 9, 'subsample': 0.6967032591886467, 'colsample_bytree': 0.5180751476723217, 'alpha': 0.9120046460427316, 'gamma': 0.9935505625411464, 'lambda': 1.2082616807110784, 'min_child_weight': 91}. Best is trial 36 with value: 0.7261205687315853.\n",
      "[I 2025-12-13 01:39:08,192] Trial 44 pruned. \n",
      "[I 2025-12-13 01:42:41,136] Trial 45 finished with value: 0.7259962358825861 and parameters: {'learning_rate': 0.007049764179343096, 'max_depth': 8, 'subsample': 0.681975322519157, 'colsample_bytree': 0.535401812810612, 'alpha': 0.2146182559276328, 'gamma': 0.25047517530228414, 'lambda': 2.2583965255142675, 'min_child_weight': 75}. Best is trial 36 with value: 0.7261205687315853.\n",
      "[I 2025-12-13 01:47:42,586] Trial 46 finished with value: 0.7261302247468396 and parameters: {'learning_rate': 0.005030823498828381, 'max_depth': 8, 'subsample': 0.6997120232063498, 'colsample_bytree': 0.52708095440594, 'alpha': 0.3423595588889695, 'gamma': 0.7156027238456604, 'lambda': 1.0236430448349711, 'min_child_weight': 72}. Best is trial 46 with value: 0.7261302247468396.\n",
      "[I 2025-12-13 01:51:56,633] Trial 47 finished with value: 0.726032217998046 and parameters: {'learning_rate': 0.005987801188712882, 'max_depth': 8, 'subsample': 0.6500570916264189, 'colsample_bytree': 0.5080580926836153, 'alpha': 0.4828966319808674, 'gamma': 0.5406654365564284, 'lambda': 1.0266670859454319, 'min_child_weight': 82}. Best is trial 46 with value: 0.7261302247468396.\n",
      "[I 2025-12-13 01:53:05,552] Trial 48 pruned. \n",
      "[I 2025-12-13 01:57:56,942] Trial 49 finished with value: 0.7261547516542456 and parameters: {'learning_rate': 0.0053247908978040085, 'max_depth': 8, 'subsample': 0.6950794628228721, 'colsample_bytree': 0.5106710224245598, 'alpha': 0.7400375245551447, 'gamma': 0.5915154432840097, 'lambda': 1.3112412233171198, 'min_child_weight': 73}. Best is trial 49 with value: 0.7261547516542456.\n",
      "[I 2025-12-13 02:01:44,616] Trial 50 finished with value: 0.7259857659703792 and parameters: {'learning_rate': 0.007149223285382619, 'max_depth': 8, 'subsample': 0.671360601270471, 'colsample_bytree': 0.5716834328095651, 'alpha': 0.1178475376113528, 'gamma': 0.87325726593665, 'lambda': 1.12425971530795, 'min_child_weight': 67}. Best is trial 49 with value: 0.7261547516542456.\n",
      "[I 2025-12-13 02:06:50,930] Trial 51 finished with value: 0.7261583261761163 and parameters: {'learning_rate': 0.005067734926473041, 'max_depth': 8, 'subsample': 0.6998340354072068, 'colsample_bytree': 0.5207737887114892, 'alpha': 0.7334163084699356, 'gamma': 0.7082449472122779, 'lambda': 1.490977863063622, 'min_child_weight': 80}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:11:33,098] Trial 52 finished with value: 0.7261121214696136 and parameters: {'learning_rate': 0.005640952178978333, 'max_depth': 8, 'subsample': 0.6908855006618625, 'colsample_bytree': 0.5167288486857573, 'alpha': 0.3740827440764086, 'gamma': 0.7385636678514508, 'lambda': 2.7774083328032124, 'min_child_weight': 76}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:16:29,400] Trial 53 finished with value: 0.7261398425924276 and parameters: {'learning_rate': 0.005036988137042397, 'max_depth': 8, 'subsample': 0.6886630949995886, 'colsample_bytree': 0.5186512700459038, 'alpha': 0.3513885590439699, 'gamma': 0.6568814352248674, 'lambda': 1.2600165830338543, 'min_child_weight': 68}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:18:07,294] Trial 54 pruned. \n",
      "[I 2025-12-13 02:22:29,209] Trial 55 finished with value: 0.7260200887993619 and parameters: {'learning_rate': 0.005458599789975821, 'max_depth': 8, 'subsample': 0.699714889244342, 'colsample_bytree': 0.5488765573236366, 'alpha': 0.17361526346608494, 'gamma': 0.6176765845859475, 'lambda': 1.2850894258445429, 'min_child_weight': 72}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:25:24,389] Trial 56 pruned. \n",
      "[I 2025-12-13 02:30:20,432] Trial 57 finished with value: 0.7260978987019259 and parameters: {'learning_rate': 0.005246543714942215, 'max_depth': 8, 'subsample': 0.6991887820782673, 'colsample_bytree': 0.5382230413610762, 'alpha': 0.9851535063991107, 'gamma': 0.5214203525285616, 'lambda': 1.463496339602895, 'min_child_weight': 66}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:34:44,819] Trial 58 finished with value: 0.7260824955754289 and parameters: {'learning_rate': 0.0056553402667481305, 'max_depth': 8, 'subsample': 0.6869053560436695, 'colsample_bytree': 0.5158301166772548, 'alpha': 0.322513883936925, 'gamma': 0.9363053350749501, 'lambda': 1.0168259393816002, 'min_child_weight': 62}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:35:53,156] Trial 59 pruned. \n",
      "[I 2025-12-13 02:37:25,320] Trial 60 pruned. \n",
      "[I 2025-12-13 02:42:24,564] Trial 61 finished with value: 0.7259845773039704 and parameters: {'learning_rate': 0.005051994006782303, 'max_depth': 8, 'subsample': 0.6908961938168436, 'colsample_bytree': 0.5720979910588934, 'alpha': 2.262267202351753, 'gamma': 0.43870547425652845, 'lambda': 1.0001524155043107, 'min_child_weight': 70}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:46:38,179] Trial 62 finished with value: 0.7261171303168205 and parameters: {'learning_rate': 0.006153452247487703, 'max_depth': 8, 'subsample': 0.6841847298674627, 'colsample_bytree': 0.511217990454931, 'alpha': 0.7243338942029081, 'gamma': 0.5302153005726895, 'lambda': 1.623267785752834, 'min_child_weight': 74}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:51:22,919] Trial 63 finished with value: 0.7261050292408499 and parameters: {'learning_rate': 0.005177668869713798, 'max_depth': 8, 'subsample': 0.6897364376575169, 'colsample_bytree': 0.5004902836553844, 'alpha': 0.8887954531540323, 'gamma': 0.7363519435552208, 'lambda': 1.4224510908346018, 'min_child_weight': 86}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:55:50,091] Trial 64 finished with value: 0.7261214870055069 and parameters: {'learning_rate': 0.005433188750891042, 'max_depth': 8, 'subsample': 0.6981085881457493, 'colsample_bytree': 0.5227191754245752, 'alpha': 0.20527132299810713, 'gamma': 0.9078619167751465, 'lambda': 1.0455221286035983, 'min_child_weight': 100}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 02:57:10,514] Trial 65 pruned. \n",
      "[I 2025-12-13 02:58:16,310] Trial 66 pruned. \n",
      "[I 2025-12-13 03:02:17,583] Trial 67 finished with value: 0.7260554751789102 and parameters: {'learning_rate': 0.00661172080287715, 'max_depth': 8, 'subsample': 0.6480857192232968, 'colsample_bytree': 0.5453073544754138, 'alpha': 0.17974747595085314, 'gamma': 0.7435955774494334, 'lambda': 1.130434671742789, 'min_child_weight': 96}. Best is trial 51 with value: 0.7261583261761163.\n",
      "[I 2025-12-13 03:05:35,989] Trial 68 pruned. \n",
      "[I 2025-12-13 03:07:11,304] Trial 69 pruned. \n",
      "[I 2025-12-13 03:12:09,437] Trial 70 finished with value: 0.7261691246647887 and parameters: {'learning_rate': 0.005075221294647319, 'max_depth': 8, 'subsample': 0.6983369897762625, 'colsample_bytree': 0.5126939101671768, 'alpha': 0.48556868784850443, 'gamma': 0.6044863967984136, 'lambda': 1.5246050854007522, 'min_child_weight': 68}. Best is trial 70 with value: 0.7261691246647887.\n",
      "[I 2025-12-13 03:15:00,172] Trial 71 pruned. \n",
      "[I 2025-12-13 03:20:01,646] Trial 72 finished with value: 0.7261301703228248 and parameters: {'learning_rate': 0.005156752770257901, 'max_depth': 8, 'subsample': 0.6978896075987209, 'colsample_bytree': 0.5305364891001065, 'alpha': 0.528604494207869, 'gamma': 0.7245242094935028, 'lambda': 1.59438082629382, 'min_child_weight': 61}. Best is trial 70 with value: 0.7261691246647887.\n",
      "[I 2025-12-13 03:24:41,870] Trial 73 finished with value: 0.7260918240267739 and parameters: {'learning_rate': 0.0054894519092396395, 'max_depth': 8, 'subsample': 0.674612906014287, 'colsample_bytree': 0.5107450840384582, 'alpha': 0.12967924389956736, 'gamma': 0.9215614094758476, 'lambda': 1.5076157766628135, 'min_child_weight': 98}. Best is trial 70 with value: 0.7261691246647887.\n",
      "[I 2025-12-13 03:29:42,922] Trial 74 finished with value: 0.7260552392069638 and parameters: {'learning_rate': 0.005014194893967152, 'max_depth': 8, 'subsample': 0.6923470585714664, 'colsample_bytree': 0.5528749945237728, 'alpha': 0.4879009168204579, 'gamma': 0.7370865090700144, 'lambda': 1.0636178025793346, 'min_child_weight': 74}. Best is trial 70 with value: 0.7261691246647887.\n",
      "[I 2025-12-13 03:30:25,585] Trial 75 pruned. \n",
      "[I 2025-12-13 03:31:26,533] Trial 76 pruned. \n",
      "[I 2025-12-13 03:34:31,806] Trial 77 pruned. \n",
      "[I 2025-12-13 03:34:51,026] Trial 78 pruned. \n",
      "[I 2025-12-13 03:35:11,591] Trial 79 pruned. \n",
      "[I 2025-12-13 03:39:25,305] Trial 80 finished with value: 0.7261280982812934 and parameters: {'learning_rate': 0.006065312204460877, 'max_depth': 8, 'subsample': 0.6863876132081713, 'colsample_bytree': 0.5063104018720581, 'alpha': 0.3603992760803541, 'gamma': 0.8217154920655205, 'lambda': 1.0666432675337187, 'min_child_weight': 100}. Best is trial 70 with value: 0.7261691246647887.\n",
      "[I 2025-12-13 03:43:17,892] Trial 81 finished with value: 0.7261577712150387 and parameters: {'learning_rate': 0.00671117377922762, 'max_depth': 8, 'subsample': 0.6994471438267785, 'colsample_bytree': 0.5044852975459417, 'alpha': 0.48671380377474815, 'gamma': 0.6622621515423908, 'lambda': 1.0811725636966754, 'min_child_weight': 97}. Best is trial 70 with value: 0.7261691246647887.\n",
      "[I 2025-12-13 03:46:52,100] Trial 82 finished with value: 0.7260760510671714 and parameters: {'learning_rate': 0.00716276199205601, 'max_depth': 8, 'subsample': 0.6983533776106942, 'colsample_bytree': 0.5509163497883577, 'alpha': 0.1664397604805781, 'gamma': 0.5286985544044719, 'lambda': 1.003899582502958, 'min_child_weight': 89}. Best is trial 70 with value: 0.7261691246647887.\n",
      "[I 2025-12-13 03:47:33,726] Trial 83 pruned. \n",
      "[I 2025-12-13 03:52:28,910] Trial 84 finished with value: 0.7261753661722371 and parameters: {'learning_rate': 0.005276860018659972, 'max_depth': 8, 'subsample': 0.6990533025349923, 'colsample_bytree': 0.5193516027121639, 'alpha': 0.29056213472952724, 'gamma': 0.8615353011601763, 'lambda': 1.552105061486215, 'min_child_weight': 88}. Best is trial 84 with value: 0.7261753661722371.\n",
      "[I 2025-12-13 03:55:06,107] Trial 85 pruned. \n",
      "[I 2025-12-13 03:56:30,292] Trial 86 pruned. \n",
      "[I 2025-12-13 04:01:28,134] Trial 87 finished with value: 0.7260772301728244 and parameters: {'learning_rate': 0.0053947444098496385, 'max_depth': 8, 'subsample': 0.6931800433799234, 'colsample_bytree': 0.588674546830046, 'alpha': 0.8601276402616754, 'gamma': 0.5984684013121973, 'lambda': 1.0686150449805134, 'min_child_weight': 93}. Best is trial 84 with value: 0.7261753661722371.\n",
      "[I 2025-12-13 04:01:49,165] Trial 88 pruned. \n",
      "[I 2025-12-13 04:03:21,858] Trial 89 pruned. \n",
      "[I 2025-12-13 04:04:18,712] Trial 90 pruned. \n",
      "[I 2025-12-13 04:09:17,762] Trial 91 finished with value: 0.7261772014491857 and parameters: {'learning_rate': 0.005185616096586372, 'max_depth': 8, 'subsample': 0.6959203904168973, 'colsample_bytree': 0.5151986802179258, 'alpha': 0.35529858476441184, 'gamma': 0.8705668168882033, 'lambda': 1.2221222575600685, 'min_child_weight': 92}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:13:25,656] Trial 92 finished with value: 0.7261331831179524 and parameters: {'learning_rate': 0.006251599972935731, 'max_depth': 8, 'subsample': 0.6963505701561759, 'colsample_bytree': 0.5421575384495011, 'alpha': 0.4005075323797404, 'gamma': 0.7427993656499438, 'lambda': 1.759222544441839, 'min_child_weight': 86}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:16:06,376] Trial 93 pruned. \n",
      "[I 2025-12-13 04:16:51,559] Trial 94 pruned. \n",
      "[I 2025-12-13 04:19:59,738] Trial 95 pruned. \n",
      "[I 2025-12-13 04:24:42,282] Trial 96 finished with value: 0.7261029436671755 and parameters: {'learning_rate': 0.005471163814694901, 'max_depth': 8, 'subsample': 0.686527017654093, 'colsample_bytree': 0.5067894886001174, 'alpha': 0.4467029962942563, 'gamma': 0.7298424531258235, 'lambda': 1.9574604402315636, 'min_child_weight': 88}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:25:03,626] Trial 97 pruned. \n",
      "[I 2025-12-13 04:26:40,786] Trial 98 pruned. \n",
      "[I 2025-12-13 04:27:57,703] Trial 99 pruned. \n",
      "[I 2025-12-13 04:29:13,669] Trial 100 pruned. \n",
      "[I 2025-12-13 04:30:31,029] Trial 101 pruned. \n",
      "[I 2025-12-13 04:31:22,043] Trial 102 pruned. \n",
      "[I 2025-12-13 04:35:30,889] Trial 103 finished with value: 0.7261041518606253 and parameters: {'learning_rate': 0.0062425379105798835, 'max_depth': 8, 'subsample': 0.6918742008446684, 'colsample_bytree': 0.5242675416452537, 'alpha': 0.5434613432979656, 'gamma': 0.6829604736559745, 'lambda': 1.687722815628745, 'min_child_weight': 96}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:40:30,513] Trial 104 finished with value: 0.7261455464866264 and parameters: {'learning_rate': 0.005095049815323574, 'max_depth': 8, 'subsample': 0.6986479846835347, 'colsample_bytree': 0.5404399691460815, 'alpha': 0.374434611066144, 'gamma': 0.8759751028987339, 'lambda': 1.5418472077355514, 'min_child_weight': 83}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:41:23,940] Trial 105 pruned. \n",
      "[I 2025-12-13 04:41:50,012] Trial 106 pruned. \n",
      "[I 2025-12-13 04:45:55,590] Trial 107 finished with value: 0.7260994415442646 and parameters: {'learning_rate': 0.006322441038862875, 'max_depth': 8, 'subsample': 0.6979101202936484, 'colsample_bytree': 0.5537542291816185, 'alpha': 0.2170271989514712, 'gamma': 0.8341985644026368, 'lambda': 2.3837072435329323, 'min_child_weight': 82}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:50:48,471] Trial 108 finished with value: 0.7260283259968521 and parameters: {'learning_rate': 0.0050886355488554795, 'max_depth': 8, 'subsample': 0.6951207427836598, 'colsample_bytree': 0.5533125024261252, 'alpha': 0.5097778594277539, 'gamma': 0.9493384167183194, 'lambda': 1.8582945632773664, 'min_child_weight': 80}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:51:17,086] Trial 109 pruned. \n",
      "[I 2025-12-13 04:52:38,321] Trial 110 pruned. \n",
      "[I 2025-12-13 04:52:56,501] Trial 111 pruned. \n",
      "[I 2025-12-13 04:57:05,063] Trial 112 finished with value: 0.7261444996647821 and parameters: {'learning_rate': 0.006636069629993411, 'max_depth': 8, 'subsample': 0.6860285837450595, 'colsample_bytree': 0.505346125839044, 'alpha': 0.251617245946437, 'gamma': 0.7909424895940316, 'lambda': 1.1934883622342267, 'min_child_weight': 79}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 04:58:17,186] Trial 113 pruned. \n",
      "[I 2025-12-13 05:02:18,708] Trial 114 finished with value: 0.7260997772206235 and parameters: {'learning_rate': 0.006371409328929141, 'max_depth': 8, 'subsample': 0.6833102389598757, 'colsample_bytree': 0.5090973611921457, 'alpha': 0.25029971581718224, 'gamma': 0.7589313234341668, 'lambda': 1.080334285501192, 'min_child_weight': 80}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 05:03:47,275] Trial 115 pruned. \n",
      "[I 2025-12-13 05:04:25,803] Trial 116 pruned. \n",
      "[I 2025-12-13 05:05:18,128] Trial 117 pruned. \n",
      "[I 2025-12-13 05:05:58,666] Trial 118 pruned. \n",
      "[I 2025-12-13 05:07:38,117] Trial 119 pruned. \n",
      "[I 2025-12-13 05:09:11,151] Trial 120 pruned. \n",
      "[I 2025-12-13 05:09:36,166] Trial 121 pruned. \n",
      "[I 2025-12-13 05:10:35,771] Trial 122 pruned. \n",
      "[I 2025-12-13 05:14:38,450] Trial 123 finished with value: 0.7260970276819548 and parameters: {'learning_rate': 0.0062335343079142165, 'max_depth': 8, 'subsample': 0.6919512939664358, 'colsample_bytree': 0.5023709924152405, 'alpha': 0.5440257988686474, 'gamma': 0.8302441780227996, 'lambda': 1.1409670955153457, 'min_child_weight': 83}. Best is trial 91 with value: 0.7261772014491857.\n",
      "[I 2025-12-13 05:15:59,589] Trial 124 pruned. \n",
      "[I 2025-12-13 05:17:03,690] Trial 125 pruned. \n",
      "[I 2025-12-13 05:20:48,361] Trial 126 pruned. \n",
      "[I 2025-12-13 05:24:52,396] Trial 127 finished with value: 0.7261788058710615 and parameters: {'learning_rate': 0.006676968523789098, 'max_depth': 8, 'subsample': 0.6902291857256307, 'colsample_bytree': 0.5024566791396553, 'alpha': 0.6638620294860985, 'gamma': 0.7554326112922276, 'lambda': 1.0118027228506512, 'min_child_weight': 94}. Best is trial 127 with value: 0.7261788058710615.\n",
      "[I 2025-12-13 05:25:25,924] Trial 128 pruned. \n",
      "[I 2025-12-13 05:26:00,080] Trial 129 pruned. \n",
      "[I 2025-12-13 05:27:39,652] Trial 130 pruned. \n",
      "[I 2025-12-13 05:28:48,109] Trial 131 pruned. \n",
      "[I 2025-12-13 05:29:49,786] Trial 132 pruned. \n",
      "[I 2025-12-13 05:33:22,635] Trial 133 finished with value: 0.7261083421052824 and parameters: {'learning_rate': 0.007523683966156977, 'max_depth': 8, 'subsample': 0.6998502392862159, 'colsample_bytree': 0.5156545756712898, 'alpha': 1.2885847064228853, 'gamma': 0.6824040999309766, 'lambda': 1.0603155510303024, 'min_child_weight': 88}. Best is trial 127 with value: 0.7261788058710615.\n",
      "[I 2025-12-13 05:34:33,091] Trial 134 pruned. \n",
      "[I 2025-12-13 05:38:30,513] Trial 135 finished with value: 0.7260684278493125 and parameters: {'learning_rate': 0.006617026568147506, 'max_depth': 8, 'subsample': 0.6967202862638985, 'colsample_bytree': 0.5477209018061103, 'alpha': 0.6845348644816273, 'gamma': 0.6796006765623043, 'lambda': 1.1577047736734374, 'min_child_weight': 100}. Best is trial 127 with value: 0.7261788058710615.\n",
      "[I 2025-12-13 05:39:01,926] Trial 136 pruned. \n",
      "[I 2025-12-13 05:39:24,223] Trial 137 pruned. \n",
      "[I 2025-12-13 05:40:58,085] Trial 138 pruned. \n",
      "[I 2025-12-13 05:45:29,220] Trial 139 finished with value: 0.7260957291815341 and parameters: {'learning_rate': 0.005979760975911892, 'max_depth': 8, 'subsample': 0.6821529164576952, 'colsample_bytree': 0.5004245744383802, 'alpha': 0.5726208129177477, 'gamma': 0.7675838486689214, 'lambda': 1.9323717229653192, 'min_child_weight': 64}. Best is trial 127 with value: 0.7261788058710615.\n",
      "[I 2025-12-13 05:50:07,179] Trial 140 finished with value: 0.7261271875745087 and parameters: {'learning_rate': 0.005407744673403872, 'max_depth': 8, 'subsample': 0.6983165691565038, 'colsample_bytree': 0.5094773609151307, 'alpha': 0.3586396814123156, 'gamma': 0.911984199558211, 'lambda': 1.330503587581651, 'min_child_weight': 97}. Best is trial 127 with value: 0.7261788058710615.\n",
      "[I 2025-12-13 05:55:09,835] Trial 141 finished with value: 0.7261995858097773 and parameters: {'learning_rate': 0.005092159244819224, 'max_depth': 8, 'subsample': 0.6985482460232558, 'colsample_bytree': 0.5002716122370332, 'alpha': 0.5442317401534714, 'gamma': 0.9101677712528158, 'lambda': 1.4849248721792976, 'min_child_weight': 86}. Best is trial 141 with value: 0.7261995858097773.\n",
      "[I 2025-12-13 05:55:35,065] Trial 142 pruned. \n",
      "[I 2025-12-13 05:56:01,040] Trial 143 pruned. \n",
      "[I 2025-12-13 05:58:56,139] Trial 144 pruned. \n",
      "[I 2025-12-13 06:00:31,755] Trial 145 pruned. \n",
      "[I 2025-12-13 06:05:33,893] Trial 146 finished with value: 0.7261271102094101 and parameters: {'learning_rate': 0.005246230574607085, 'max_depth': 8, 'subsample': 0.6940769539570464, 'colsample_bytree': 0.5073943846190424, 'alpha': 1.3095723390796155, 'gamma': 0.7755271075191871, 'lambda': 2.044493182178345, 'min_child_weight': 77}. Best is trial 141 with value: 0.7261995858097773.\n",
      "[I 2025-12-13 06:08:22,600] Trial 147 pruned. \n",
      "[I 2025-12-13 06:08:41,129] Trial 148 pruned. \n",
      "[I 2025-12-13 06:10:03,021] Trial 149 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trials finished: 150\n",
      "Best trial AUC: 0.7261995858097773\n",
      "Best trial params:\n",
      "- learning_rate: 0.005092159244819224\n",
      "- max_depth: 8\n",
      "- subsample: 0.6985482460232558\n",
      "- colsample_bytree: 0.5002716122370332\n",
      "- alpha: 0.5442317401534714\n",
      "- gamma: 0.9101677712528158\n",
      "- lambda: 1.4849248721792976\n",
      "- min_child_weight: 86\n"
     ]
    }
   ],
   "source": [
    "if SKIP_BASE_MODEL_HYPERPARAMETER_TUNING:\n",
    "    print(\"Skipped base model hyperparameter tuning\")\n",
    "else:\n",
    "    print(f\"Started base model hyperparameter tuning for {BASE_MODEL_OPTUNA_STUDY_ESTIMATOR.value}\")\n",
    "    sampler = optuna.samplers.TPESampler(n_ei_candidates=48, multivariate=True)\n",
    "    study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "    study.optimize(base_model_optuna_study_objective, n_trials=BASE_MODEL_OPTUNA_STUDY_NUM_TRIALS)\n",
    "    \n",
    "    print(f\"# trials finished: {len(study.trials)}\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Best trial AUC: {trial.value}\")\n",
    "    print(f\"Best trial params:\")\n",
    "    for param_key, param_value in trial.params.items():\n",
    "        print(f\"- {param_key}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c45b90",
   "metadata": {
    "papermill": {
     "duration": 0.015225,
     "end_time": "2025-12-13T06:10:03.087977",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.072752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e906f22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.119645Z",
     "iopub.status.busy": "2025-12-13T06:10:03.118902Z",
     "iopub.status.idle": "2025-12-13T06:10:03.122521Z",
     "shell.execute_reply": "2025-12-13T06:10:03.121826Z"
    },
    "papermill": {
     "duration": 0.020679,
     "end_time": "2025-12-13T06:10:03.123673",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.102994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of splits to use for Stratified K-Fold Cross-Validation for base models\n",
    "BASE_MODEL_KFOLD_NUM_SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3626c",
   "metadata": {
    "papermill": {
     "duration": 0.015444,
     "end_time": "2025-12-13T06:10:03.154225",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.138781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.1 CatBoostClassifier\n",
    "\n",
    "### 8.1.1 Helper Methods (CatBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b9a8b30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.185924Z",
     "iopub.status.busy": "2025-12-13T06:10:03.185388Z",
     "iopub.status.idle": "2025-12-13T06:10:03.193538Z",
     "shell.execute_reply": "2025-12-13T06:10:03.192999Z"
    },
    "papermill": {
     "duration": 0.025109,
     "end_time": "2025-12-13T06:10:03.194546",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.169437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_catboostclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds_accumulator = np.zeros(len(train_data))\n",
    "    test_preds_accumulator = np.zeros(len(test_data))\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "\n",
    "        seed_oof_preds = np.zeros(len(train_data))\n",
    "    \n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = train_data.drop(target_col, axis=1).iloc[train_indices]\n",
    "            X_validation_fold = train_data.drop(target_col, axis=1).iloc[validation_indices]\n",
    "            y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "            y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "        \n",
    "            model = CatBoostClassifier(\n",
    "                **params_dict,\n",
    "                use_best_model=True,\n",
    "                cat_features=cat_features,\n",
    "                loss_function='Logloss',\n",
    "                eval_metric='AUC',\n",
    "                task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
    "                devices='0',\n",
    "                metric_period=1000,\n",
    "                random_seed=random_seed,\n",
    "                verbose=False,\n",
    "                allow_writing_files=False\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=(X_validation_fold, y_validation_fold),\n",
    "                early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS\n",
    "            )\n",
    "\n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            y_test_pred_proba = model.predict_proba(test_data)[:, 1]\n",
    "            seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "            test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "\n",
    "        oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "    final_oof_preds = oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "    final_test_preds = test_preds_accumulator / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(final_oof_preds), pd.Series(final_test_preds)\n",
    "\n",
    "def get_catboostclassifier_stacking_estimator(index, params_dict):\n",
    "    return StackingEstimator(\n",
    "        name=f\"CatBoostClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=train_data.columns.tolist(),\n",
    "        get_preds=get_catboostclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98848c9d",
   "metadata": {
    "papermill": {
     "duration": 0.015247,
     "end_time": "2025-12-13T06:10:03.224974",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.209727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.1.2 Add Estimators (CatBoostClassifier)\n",
    "\n",
    "Add CatBoostClassifier estimators to list that StackingPredictionsRetriever will process. Hyperparameters were found using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "174fd70e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.256351Z",
     "iopub.status.busy": "2025-12-13T06:10:03.255970Z",
     "iopub.status.idle": "2025-12-13T06:10:03.260675Z",
     "shell.execute_reply": "2025-12-13T06:10:03.260164Z"
    },
    "papermill": {
     "duration": 0.021443,
     "end_time": "2025-12-13T06:10:03.261609",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.240166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators += [\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=1,\n",
    "        params_dict={ # Optuna study AUC: 0.7261767336235222\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.03933473509871599,\n",
    "            'depth': 3,\n",
    "            'l2_leaf_reg': 14.932109771039046,\n",
    "            'bagging_temperature': 0.13345806085697987,\n",
    "            'random_strength': 7.486374538597635,\n",
    "            'min_data_in_leaf': 2,\n",
    "        }\n",
    "    ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=2,\n",
    "        params_dict={ # Optuna study AUC: 0.725842155230371\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.041779205681346576,\n",
    "            'depth': 4,\n",
    "            'l2_leaf_reg': 3.628892496718331,\n",
    "            'bagging_temperature': 0.1922242909320177,\n",
    "            'random_strength': 8.464699585881778,\n",
    "            'min_data_in_leaf': 5,\n",
    "        }\n",
    "    ),\n",
    "     get_catboostclassifier_stacking_estimator(\n",
    "        index=3,\n",
    "        params_dict={ # Optuna study AUC: 0.7257614687804782\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.08955773312600926,\n",
    "            'depth': 4,\n",
    "            'l2_leaf_reg': 8.952470035979275,\n",
    "            'bagging_temperature': 0.21150772067613666,\n",
    "            'random_strength': 14.741499198080962,\n",
    "            'min_data_in_leaf': 1,\n",
    "        }\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2fe19",
   "metadata": {
    "papermill": {
     "duration": 0.015105,
     "end_time": "2025-12-13T06:10:03.291897",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.276792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.2 XGBClassifier\n",
    "\n",
    "### 8.2.1 Helper Methods (XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e14bd98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.323307Z",
     "iopub.status.busy": "2025-12-13T06:10:03.323091Z",
     "iopub.status.idle": "2025-12-13T06:10:03.330498Z",
     "shell.execute_reply": "2025-12-13T06:10:03.330013Z"
    },
    "papermill": {
     "duration": 0.024306,
     "end_time": "2025-12-13T06:10:03.331425",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.307119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xgbclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds_accumulator = np.zeros(len(train_data))\n",
    "    test_preds_accumulator = np.zeros(len(test_data))\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(train_data.drop(target_col, axis=1), train_data[target_col])\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "\n",
    "        seed_oof_preds = np.zeros(len(train_data))\n",
    "\n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = train_data.drop(target_col, axis=1).iloc[train_indices]\n",
    "            X_validation_fold = train_data.drop(target_col, axis=1).iloc[validation_indices]\n",
    "            y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "            y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "            model = XGBClassifier(\n",
    "                **params_dict,\n",
    "                tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                enable_categorical=True,\n",
    "                objective='binary:logistic',\n",
    "                eval_metric='auc',\n",
    "                early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS,\n",
    "                n_jobs=-1,\n",
    "                random_state=random_seed,\n",
    "                verbosity=0\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            y_test_pred_proba = model.predict_proba(test_data)[:, 1]\n",
    "            seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "            test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "\n",
    "        oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "    final_oof_preds = oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "    final_test_preds = test_preds_accumulator / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(final_oof_preds), pd.Series(final_test_preds)\n",
    "\n",
    "def get_xgbclassifier_stacking_estimator(index, params_dict):\n",
    "    return StackingEstimator(\n",
    "        name=f\"XGBClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=train_data.columns.tolist(),\n",
    "        get_preds=get_xgbclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8770d",
   "metadata": {
    "papermill": {
     "duration": 0.015225,
     "end_time": "2025-12-13T06:10:03.361619",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.346394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.2.2 Add Estimators (XGBClassifier)\n",
    "\n",
    "Add XGBClassifier estimators to list that StackingPredictionsRetriever will process. Hyperparameters were found using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "219f118d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.392837Z",
     "iopub.status.busy": "2025-12-13T06:10:03.392601Z",
     "iopub.status.idle": "2025-12-13T06:10:03.398594Z",
     "shell.execute_reply": "2025-12-13T06:10:03.397952Z"
    },
    "papermill": {
     "duration": 0.022907,
     "end_time": "2025-12-13T06:10:03.399615",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.376708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators += [\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=1,\n",
    "        params_dict={ # Optuna study AUC: 0.7275219804910846\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.00985498815107458,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.975836120137461,\n",
    "            'colsample_bytree': 0.5411854284303592,\n",
    "            'alpha': 9.940781978752474,\n",
    "            'gamma': 0.008422323405815038,\n",
    "            'lambda': 0.025214960531620187,\n",
    "            'min_child_weight': 12,\n",
    "        }\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=2,\n",
    "        params_dict={ # Optuna study AUC: 0.7273817150393508\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.047179227853488916,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.9561594029099818,\n",
    "            'colsample_bytree': 0.5200809916944509,\n",
    "            'alpha': 9.323686821094613,\n",
    "            'gamma': 0.06513704074541844,\n",
    "            'lambda': 0.07573405175712218,\n",
    "            'min_child_weight': 14,\n",
    "        }\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=3,\n",
    "        params_dict={ # Optuna study AUC: 0.7274144144696422\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.06778303256075534,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.9750702612583769,\n",
    "            'colsample_bytree': 0.5164463777572837,\n",
    "            'alpha': 6.677223824702266,\n",
    "            'gamma': 0.06627215758548254,\n",
    "            'lambda': 0.10239210156952944,\n",
    "            'min_child_weight': 17,\n",
    "        }\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=4,\n",
    "        params_dict={ # Optuna study AUC: 0.7263868488191946\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.00992002978574334,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.6885700003314461,\n",
    "            'colsample_bytree': 0.5082842329050175,\n",
    "            'alpha': 4.042835803115786,\n",
    "            'gamma': 0.19033575052721494,\n",
    "            'lambda': 1.4531584526994292,\n",
    "            'min_child_weight': 79,\n",
    "        }\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f333e1",
   "metadata": {
    "papermill": {
     "duration": 0.015543,
     "end_time": "2025-12-13T06:10:03.430424",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.414881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.3 XGBRFClassifier\n",
    "\n",
    "### 8.3.1 Helper Methods (XGBRFClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "893cd413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.462524Z",
     "iopub.status.busy": "2025-12-13T06:10:03.462316Z",
     "iopub.status.idle": "2025-12-13T06:10:03.468439Z",
     "shell.execute_reply": "2025-12-13T06:10:03.467943Z"
    },
    "papermill": {
     "duration": 0.023817,
     "end_time": "2025-12-13T06:10:03.469469",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.445652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xgbrfclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds_accumulator = np.zeros(len(train_data_mlp))\n",
    "    test_preds_accumulator = np.zeros(len(test_data_mlp))\n",
    "    \n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        \n",
    "        seed_oof_preds = np.zeros(len(train_data_mlp))\n",
    "        \n",
    "        for fold, (train_indices, validation_indices) in enumerate(skf.split(train_data_mlp.drop(target_col, axis=1), train_data_mlp[target_col])):\n",
    "            X_train_fold = train_data_mlp.drop(target_col, axis=1).iloc[train_indices]\n",
    "            X_val_fold = train_data_mlp.drop(target_col, axis=1).iloc[validation_indices]\n",
    "            y_train_fold = train_data_mlp[target_col].iloc[train_indices]\n",
    "            \n",
    "            model = XGBRFClassifier(\n",
    "                **params_dict,\n",
    "                tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                learning_rate=1.0,\n",
    "                n_jobs=-1,\n",
    "                random_state=random_seed,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            seed_oof_preds[validation_indices] = model.predict_proba(X_val_fold)[:, 1]\n",
    "            test_preds_accumulator += model.predict_proba(test_data_mlp)[:, 1]\n",
    "            \n",
    "        oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "    final_oof_preds = oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "    final_test_preds = test_preds_accumulator / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    \n",
    "    return pd.Series(final_oof_preds), pd.Series(final_test_preds)\n",
    "\n",
    "def get_xgbrfclassifier_stacking_estimator(index, params_dict):\n",
    "    return StackingEstimator(\n",
    "        name=f\"XGBRFClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=train_data_mlp.columns.tolist(),\n",
    "        get_preds=get_xgbrfclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f87f5d",
   "metadata": {
    "papermill": {
     "duration": 0.015127,
     "end_time": "2025-12-13T06:10:03.500202",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.485075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.3.2 Add Estimators (XGBRFClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "450daa99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.531738Z",
     "iopub.status.busy": "2025-12-13T06:10:03.531157Z",
     "iopub.status.idle": "2025-12-13T06:10:03.535109Z",
     "shell.execute_reply": "2025-12-13T06:10:03.534588Z"
    },
    "papermill": {
     "duration": 0.020835,
     "end_time": "2025-12-13T06:10:03.536169",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.515334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators += [\n",
    "     get_xgbrfclassifier_stacking_estimator(\n",
    "        index=1,\n",
    "        params_dict={ # Optuna study AUC: 0.7093869754986559\n",
    "            'n_estimators': 385,\n",
    "            'max_depth': 16,\n",
    "            'subsample': 0.5315714592374865,\n",
    "            'colsample_bynode': 0.8874353486231008,\n",
    "            'reg_alpha': 0.0054867256964063835,\n",
    "            'reg_lambda': 0.007252617838414462,\n",
    "        }\n",
    "    ),\n",
    "    #  get_xgbrfclassifier_stacking_estimator(\n",
    "    #     index=2,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7092307295106085\n",
    "    #         'n_estimators': 415,\n",
    "    #         'max_depth': 16,\n",
    "    #         'subsample': 0.4857798345845685,\n",
    "    #         'colsample_bynode': 0.8965128787444345,\n",
    "    #         'reg_alpha': 0.18172738357674292,\n",
    "    #         'reg_lambda': 0.004947196570367552,\n",
    "    #     }\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d788992e",
   "metadata": {
    "papermill": {
     "duration": 0.015109,
     "end_time": "2025-12-13T06:10:03.566497",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.551388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.4 MLPClassifier\n",
    "\n",
    "### 8.4.1 Helper Methods (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6d59a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.598438Z",
     "iopub.status.busy": "2025-12-13T06:10:03.598224Z",
     "iopub.status.idle": "2025-12-13T06:10:03.604762Z",
     "shell.execute_reply": "2025-12-13T06:10:03.604106Z"
    },
    "papermill": {
     "duration": 0.023829,
     "end_time": "2025-12-13T06:10:03.605851",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.582022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mlpclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds_accumulator = np.zeros(len(train_data_mlp))\n",
    "    test_preds_accumulator = np.zeros(len(test_data_mlp))\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(train_data_mlp.drop(target_col, axis=1), train_data_mlp[target_col])\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "\n",
    "        seed_oof_preds = np.zeros(len(train_data_mlp))\n",
    "\n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = train_data_mlp.drop(target_col, axis=1).iloc[train_indices]\n",
    "            X_validation_fold = train_data_mlp.drop(target_col, axis=1).iloc[validation_indices]\n",
    "            y_train_fold = train_data_mlp[target_col].iloc[train_indices]\n",
    "            y_validation_fold = train_data_mlp[target_col].iloc[validation_indices]\n",
    "\n",
    "            model = MLPClassifier(\n",
    "                **params_dict,\n",
    "                input_dim=X_train_fold.shape[1],\n",
    "                epochs=100,\n",
    "                patience=10,\n",
    "                device=DEVICE\n",
    "            )\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            y_test_pred_proba = model.predict_proba(test_data_mlp)[:, 1]\n",
    "            seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "            test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "\n",
    "        oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "    final_oof_preds = oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "    final_test_preds = test_preds_accumulator / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(final_oof_preds), pd.Series(final_test_preds)\n",
    "\n",
    "def get_mlpclassifier_stacking_estimator(index, params_dict):\n",
    "    return StackingEstimator(\n",
    "        name=f\"MLPClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=train_data_mlp.columns.tolist(),\n",
    "        get_preds=get_mlpclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b9596",
   "metadata": {
    "papermill": {
     "duration": 0.015104,
     "end_time": "2025-12-13T06:10:03.636330",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.621226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.4.2 Add Estimators (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e22b99d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.667643Z",
     "iopub.status.busy": "2025-12-13T06:10:03.667214Z",
     "iopub.status.idle": "2025-12-13T06:10:03.670236Z",
     "shell.execute_reply": "2025-12-13T06:10:03.669568Z"
    },
    "papermill": {
     "duration": 0.019942,
     "end_time": "2025-12-13T06:10:03.671334",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.651392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# estimators += [\n",
    "#     get_mlpclassifier_stacking_estimator(\n",
    "#         index=1,\n",
    "#         params_dict={ # Optuna study AUC: 0.6962418548652664\n",
    "#             'hidden_layers': (128, 64, 32),\n",
    "#             'dropout': 0.35993977676783095,\n",
    "#             'learning_rate': 0.0022107162317045424,\n",
    "#             'batch_size': 1024,\n",
    "#             'weight_decay': 4.655295266533981e-06,\n",
    "#         }\n",
    "#     ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4692b5",
   "metadata": {
    "papermill": {
     "duration": 0.015608,
     "end_time": "2025-12-13T06:10:03.702379",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.686771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. Base Model Predictions\n",
    "\n",
    "## 9.1 Get Base Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1af91860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:10:03.734413Z",
     "iopub.status.busy": "2025-12-13T06:10:03.734195Z",
     "iopub.status.idle": "2025-12-13T06:22:32.227500Z",
     "shell.execute_reply": "2025-12-13T06:22:32.226668Z"
    },
    "papermill": {
     "duration": 748.511046,
     "end_time": "2025-12-13T06:22:32.228920",
     "exception": false,
     "start_time": "2025-12-13T06:10:03.717874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Importing predictions..\n",
      "[INFO] 7 train predictions were imported:\n",
      "CatBoostClassifier_1 (6eca2de83af2fea3676cc9382d0f1011), CatBoostClassifier_2 (b4347d306f6e52d59724382017b55f1b), CatBoostClassifier_3 (fad9fe0d13abe5377a9667ad2452550c), XGBClassifier_1 (3fd5db728b0f635ad3fb51e4ac3a5c8d), XGBClassifier_2 (cd0320203bc21b5b10db068b52204c49), XGBClassifier_3 (801128d9854f893393d31943ee000e82), XGBRFClassifier_1 (aca0224f49af4aff337e4a3bd4021211)\n",
      "[INFO] 7 test predictions were imported:\n",
      "CatBoostClassifier_1 (6eca2de83af2fea3676cc9382d0f1011), CatBoostClassifier_2 (b4347d306f6e52d59724382017b55f1b), CatBoostClassifier_3 (fad9fe0d13abe5377a9667ad2452550c), XGBClassifier_1 (3fd5db728b0f635ad3fb51e4ac3a5c8d), XGBClassifier_2 (cd0320203bc21b5b10db068b52204c49), XGBClassifier_3 (801128d9854f893393d31943ee000e82), XGBRFClassifier_1 (aca0224f49af4aff337e4a3bd4021211)\n",
      "[INFO] Finished importing predictions\n",
      "[INFO] Syncing predictions..\n",
      "[INFO] No columns for training predictions were dropped\n",
      "[INFO] No columns for test predictions were dropped\n",
      "[INFO] Finished syncing predictions\n",
      "[INFO] Getting predictions..\n",
      "[INFO] Getting predictions for estimator XGBClassifier_4 (9d4a18809c7642a3fc3412c67d01204f)\n",
      "[INFO] Saved predictions\n",
      "[INFO] Skipped retrieving predictions for following estimators as their current ones are not stale:\n",
      "CatBoostClassifier_1 (6eca2de83af2fea3676cc9382d0f1011), CatBoostClassifier_2 (b4347d306f6e52d59724382017b55f1b), CatBoostClassifier_3 (fad9fe0d13abe5377a9667ad2452550c), XGBClassifier_1 (3fd5db728b0f635ad3fb51e4ac3a5c8d), XGBClassifier_2 (cd0320203bc21b5b10db068b52204c49), XGBClassifier_3 (801128d9854f893393d31943ee000e82), XGBRFClassifier_1 (aca0224f49af4aff337e4a3bd4021211)\n",
      "[INFO] Finished getting all predictions\n"
     ]
    }
   ],
   "source": [
    "stacking_preds_retriever = StackingPredictionsRetriever(\n",
    "    estimators=estimators,\n",
    "    working_dir_path=\"/kaggle/working/\",\n",
    "    train_preds_filename=\"base_models_train_preds\",\n",
    "    test_preds_filename=\"base_models_test_preds\",\n",
    "    preds_save_interval=1\n",
    ")\n",
    "stacking_preds_retriever.import_preds(\"/kaggle/input/diabetes-prediction-challenge-base-model-preds/\")\n",
    "stacking_preds_retriever.sync_preds()\n",
    "stacking_preds_retriever.get_preds()\n",
    "\n",
    "base_model_train_preds, base_model_test_preds = stacking_preds_retriever.get_current_train_and_test_preds()\n",
    "base_model_train_preds.sort_index(axis=1, inplace=True, key=lambda index: index.map(lambda col_name: (col_name.split(\"_\")[0], int(col_name.split()[0].split(\"_\")[-1]))))\n",
    "base_model_test_preds.sort_index(axis=1, inplace=True, key=lambda index: index.map(lambda col_name: (col_name.split(\"_\")[0], int(col_name.split()[0].split(\"_\")[-1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e1d88",
   "metadata": {
    "papermill": {
     "duration": 0.01571,
     "end_time": "2025-12-13T06:22:32.261504",
     "exception": false,
     "start_time": "2025-12-13T06:22:32.245794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9.2 Base Models AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebe7b6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:32.293688Z",
     "iopub.status.busy": "2025-12-13T06:22:32.293464Z",
     "iopub.status.idle": "2025-12-13T06:22:33.595855Z",
     "shell.execute_reply": "2025-12-13T06:22:33.595123Z"
    },
    "papermill": {
     "duration": 1.319947,
     "end_time": "2025-12-13T06:22:33.597014",
     "exception": false,
     "start_time": "2025-12-13T06:22:32.277067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier_2 (cd0320203bc21b5b10db068b52204c49)         0.727895\n",
       "XGBClassifier_3 (801128d9854f893393d31943ee000e82)         0.727864\n",
       "XGBClassifier_1 (3fd5db728b0f635ad3fb51e4ac3a5c8d)         0.727811\n",
       "XGBClassifier_4 (9d4a18809c7642a3fc3412c67d01204f)         0.727165\n",
       "CatBoostClassifier_1 (6eca2de83af2fea3676cc9382d0f1011)    0.726697\n",
       "CatBoostClassifier_3 (fad9fe0d13abe5377a9667ad2452550c)    0.726597\n",
       "CatBoostClassifier_2 (b4347d306f6e52d59724382017b55f1b)    0.726549\n",
       "XGBRFClassifier_1 (aca0224f49af4aff337e4a3bd4021211)       0.710963\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_auc = pd.Series()\n",
    "for estimator in base_model_train_preds.columns:\n",
    "    base_model_auc[estimator] = roc_auc_score(train_data[target_col], base_model_train_preds[estimator])\n",
    "base_model_auc.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddeb51",
   "metadata": {
    "papermill": {
     "duration": 0.015824,
     "end_time": "2025-12-13T06:22:33.629494",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.613670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 10. Meta-Model\n",
    "\n",
    "## 10.1 Meta-Model Hyperparameter Tuning\n",
    "\n",
    "### 10.1.1 Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90653129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:33.662200Z",
     "iopub.status.busy": "2025-12-13T06:22:33.661588Z",
     "iopub.status.idle": "2025-12-13T06:22:33.665501Z",
     "shell.execute_reply": "2025-12-13T06:22:33.664993Z"
    },
    "papermill": {
     "duration": 0.021418,
     "end_time": "2025-12-13T06:22:33.666439",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.645021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip hyperparameter tuning when it's not needed; set to `False` to do the tuning & selection\n",
    "SKIP_META_MODEL_HYPERPARAMETER_TUNING = True\n",
    "\n",
    "# maximum number of trials Optuna will conduct for the optimization\n",
    "META_MODEL_OPTUNA_STUDY_NUM_TRIALS = 50\n",
    "\n",
    "# number of splits to use for K-Fold Cross-Validation\n",
    "META_MODEL_KFOLD_NUM_SPLITS = 5\n",
    "\n",
    "# use different random seeds from ones used to train base models to avoid\n",
    "# potential leakage or alignment artifacts from original splits\n",
    "META_MODEL_RANDOM_SEEDS = [77, 99]\n",
    "\n",
    "# fixed value set for early stopping rounds\n",
    "META_MODEL_EARLY_STOPPING_ROUNDS = 20\n",
    "\n",
    "# optuna study best parameters for meta model\n",
    "meta_model_optuna_study_best_params = {}\n",
    "\n",
    "# parameters selected for meta model\n",
    "meta_model_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "208512df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:33.699270Z",
     "iopub.status.busy": "2025-12-13T06:22:33.698731Z",
     "iopub.status.idle": "2025-12-13T06:22:33.706368Z",
     "shell.execute_reply": "2025-12-13T06:22:33.705845Z"
    },
    "papermill": {
     "duration": 0.025286,
     "end_time": "2025-12-13T06:22:33.707361",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.682075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_meta_model_optuna_params(trial):\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 5, 25),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 2),\n",
    "        'subsample': trial.suggest_float('subsample', 0.95, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.95, 1.0),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1e-1, log=True),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 1e-1, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 0.4),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "    }\n",
    "\n",
    "def meta_model_optuna_study_objective(trial):\n",
    "    meta_model_params = get_meta_model_optuna_params(trial)\n",
    "\n",
    "    meta_oof_preds_accumulator = np.zeros(len(train_data))\n",
    "\n",
    "    for random_seed in META_MODEL_RANDOM_SEEDS:\n",
    "        meta_skf = StratifiedKFold(n_splits=META_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        meta_skf_splits = meta_skf.split(base_model_train_preds, train_data[target_col])\n",
    "        meta_skf_enumeration = enumerate(meta_skf_splits)\n",
    "    \n",
    "        seed_oof_preds = np.zeros(len(train_data))\n",
    "    \n",
    "        for fold, (train_indices, validation_indices) in meta_skf_enumeration:\n",
    "            X_train_fold = base_model_train_preds.iloc[train_indices]\n",
    "            y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "            X_validation_fold = base_model_train_preds.iloc[validation_indices]\n",
    "            y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "    \n",
    "            model = XGBClassifier(\n",
    "                **meta_model_params,\n",
    "                tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                objective='binary:logistic',\n",
    "                eval_metric='auc',\n",
    "                early_stopping_rounds=META_MODEL_EARLY_STOPPING_ROUNDS,\n",
    "                n_jobs=-1,\n",
    "                verbosity=0\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "                verbose=False\n",
    "            )\n",
    "    \n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            seed_oof_preds[validation_indices] = y_validation_pred_proba\n",
    "    \n",
    "        meta_oof_preds_accumulator += seed_oof_preds\n",
    "    \n",
    "    final_meta_oof_preds = meta_oof_preds_accumulator / len(META_MODEL_RANDOM_SEEDS)\n",
    "\n",
    "    return roc_auc_score(train_data[target_col], final_meta_oof_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae922e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:33.740614Z",
     "iopub.status.busy": "2025-12-13T06:22:33.740382Z",
     "iopub.status.idle": "2025-12-13T06:22:33.745263Z",
     "shell.execute_reply": "2025-12-13T06:22:33.744449Z"
    },
    "papermill": {
     "duration": 0.02293,
     "end_time": "2025-12-13T06:22:33.746283",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.723353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped hyperparameter tuning for meta model\n"
     ]
    }
   ],
   "source": [
    "if SKIP_META_MODEL_HYPERPARAMETER_TUNING:\n",
    "    print(\"Skipped hyperparameter tuning for meta model\")\n",
    "else:\n",
    "    print(\"Started hyperparameter tuning for meta model\")\n",
    "    sampler = optuna.samplers.TPESampler(n_ei_candidates=48, multivariate=True)\n",
    "    study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "    study.optimize(meta_model_optuna_study_objective, n_trials=META_MODEL_OPTUNA_STUDY_NUM_TRIALS)\n",
    "    \n",
    "    print(f\"# trials finished: {len(study.trials)}\")\n",
    "    trial = study.best_trial\n",
    "    meta_model_optuna_study_best_params = study.best_params\n",
    "    print(f\"Best trial AUC: {trial.value}\")\n",
    "    print(f\"Best trial params:\")\n",
    "    for param_key, param_value in meta_model_optuna_study_best_params.items():\n",
    "        print(f\"- {param_key}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62dc07e",
   "metadata": {
    "papermill": {
     "duration": 0.016447,
     "end_time": "2025-12-13T06:22:33.779115",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.762668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 10.1.2 Tuned Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7ec45a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:33.812495Z",
     "iopub.status.busy": "2025-12-13T06:22:33.811895Z",
     "iopub.status.idle": "2025-12-13T06:22:33.818264Z",
     "shell.execute_reply": "2025-12-13T06:22:33.817606Z"
    },
    "papermill": {
     "duration": 0.024257,
     "end_time": "2025-12-13T06:22:33.819295",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.795038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following tuned parameters will be used for the meta model:\n",
      "- n_estimators: 28\n",
      "- learning_rate: 0.1549619758916973\n",
      "- max_depth: 2\n",
      "- subsample: 0.9628607950034527\n",
      "- colsample_bytree: 0.9883747386630549\n",
      "- alpha: 0.04355046472776896\n",
      "- gamma: 0.19182991978484562\n",
      "- lambda: 0.0024107325767637354\n",
      "- min_child_weight: 1\n"
     ]
    }
   ],
   "source": [
    "# default values (most found from previous tuning/selection)\n",
    "META_MODEL_DEFAULT_N_ESTIMATORS = 28\n",
    "META_MODEL_DEFAULT_LEARNING_RATE = 0.1549619758916973\n",
    "META_MODEL_DEFAULT_MAX_DEPTH = 2\n",
    "META_MODEL_DEFAULT_SUBSAMPLE = 0.9628607950034527\n",
    "META_MODEL_DEFAULT_COLSAMPLE_BY_TREE = 0.9883747386630549\n",
    "META_MODEL_DEFAULT_ALPHA = 0.04355046472776896\n",
    "META_MODEL_DEFAULT_GAMMA = 0.19182991978484562\n",
    "META_MODEL_DEFAULT_LAMBDA = 0.0024107325767637354\n",
    "META_MODEL_DEFAULT_MIN_CHILD_WEIGHT = 1\n",
    "\n",
    "# meta model parameters\n",
    "meta_model_params['n_estimators'] = meta_model_optuna_study_best_params.get('n_estimators', META_MODEL_DEFAULT_N_ESTIMATORS)\n",
    "meta_model_params['learning_rate'] = meta_model_optuna_study_best_params.get('learning_rate', META_MODEL_DEFAULT_LEARNING_RATE)\n",
    "meta_model_params['max_depth'] = meta_model_optuna_study_best_params.get('max_depth', META_MODEL_DEFAULT_MAX_DEPTH)\n",
    "meta_model_params['subsample'] = meta_model_optuna_study_best_params.get('subsample', META_MODEL_DEFAULT_SUBSAMPLE)\n",
    "meta_model_params['colsample_bytree'] = meta_model_optuna_study_best_params.get('colsample_bytree', META_MODEL_DEFAULT_COLSAMPLE_BY_TREE)\n",
    "meta_model_params['alpha'] = meta_model_optuna_study_best_params.get('alpha', META_MODEL_DEFAULT_ALPHA)\n",
    "meta_model_params['gamma'] = meta_model_optuna_study_best_params.get('gamma', META_MODEL_DEFAULT_GAMMA)\n",
    "meta_model_params['lambda'] = meta_model_optuna_study_best_params.get('lambda', META_MODEL_DEFAULT_LAMBDA)\n",
    "meta_model_params['min_child_weight'] = meta_model_optuna_study_best_params.get('min_child_weight', META_MODEL_DEFAULT_MIN_CHILD_WEIGHT)\n",
    "print(f\"The following tuned parameters will be used for the meta model:\")\n",
    "for param_key, param_value in meta_model_params.items():\n",
    "        print(f\"- {param_key}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ee54a",
   "metadata": {
    "papermill": {
     "duration": 0.016386,
     "end_time": "2025-12-13T06:22:33.852022",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.835636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.2 Meta-Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "608b9072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:33.887626Z",
     "iopub.status.busy": "2025-12-13T06:22:33.887411Z",
     "iopub.status.idle": "2025-12-13T06:22:41.513655Z",
     "shell.execute_reply": "2025-12-13T06:22:41.512865Z"
    },
    "papermill": {
     "duration": 7.645674,
     "end_time": "2025-12-13T06:22:41.515287",
     "exception": false,
     "start_time": "2025-12-13T06:22:33.869613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_oof_preds_accumulator = np.zeros(len(train_data))\n",
    "meta_test_preds_accumulator = np.zeros(len(test_data))\n",
    "meta_train_feature_importances_accumulator = np.zeros(len(base_model_train_preds.columns))\n",
    "\n",
    "for random_seed in META_MODEL_RANDOM_SEEDS:\n",
    "    meta_skf = StratifiedKFold(n_splits=META_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "    meta_skf_splits = meta_skf.split(base_model_train_preds, train_data[target_col])\n",
    "    meta_skf_enumeration = enumerate(meta_skf_splits)\n",
    "\n",
    "    seed_oof_preds = np.zeros(len(train_data))\n",
    "\n",
    "    for fold, (train_indices, validation_indices) in meta_skf_enumeration:\n",
    "        X_train_fold = base_model_train_preds.iloc[train_indices]\n",
    "        y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "        X_validation_fold = base_model_train_preds.iloc[validation_indices]\n",
    "        y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "        meta_model = XGBClassifier(\n",
    "            **meta_model_params,\n",
    "            tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='auc',\n",
    "            early_stopping_rounds=META_MODEL_EARLY_STOPPING_ROUNDS,\n",
    "            n_jobs=-1,\n",
    "            verbosity=0\n",
    "        )\n",
    "        meta_model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        y_validation_pred_proba = meta_model.predict_proba(X_validation_fold)[:, 1]\n",
    "        y_test_pred_proba = meta_model.predict_proba(base_model_test_preds)[:, 1]\n",
    "        seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "        meta_test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "        meta_train_feature_importances_accumulator += np.array(meta_model.feature_importances_)\n",
    "\n",
    "    meta_oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "final_meta_oof_preds = meta_oof_preds_accumulator / len(META_MODEL_RANDOM_SEEDS)\n",
    "final_meta_test_preds = meta_test_preds_accumulator / (META_MODEL_KFOLD_NUM_SPLITS * len(META_MODEL_RANDOM_SEEDS))\n",
    "meta_train_feature_importances = meta_train_feature_importances_accumulator / (META_MODEL_KFOLD_NUM_SPLITS * len(META_MODEL_RANDOM_SEEDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8361f5",
   "metadata": {
    "papermill": {
     "duration": 0.015922,
     "end_time": "2025-12-13T06:22:41.549257",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.533335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.3 Meta-Model Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "650452f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:41.581744Z",
     "iopub.status.busy": "2025-12-13T06:22:41.581511Z",
     "iopub.status.idle": "2025-12-13T06:22:41.587472Z",
     "shell.execute_reply": "2025-12-13T06:22:41.586929Z"
    },
    "papermill": {
     "duration": 0.023543,
     "end_time": "2025-12-13T06:22:41.588520",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.564977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier_2 (cd0320203bc21b5b10db068b52204c49)         0.360936\n",
       "XGBClassifier_3 (801128d9854f893393d31943ee000e82)         0.322433\n",
       "XGBClassifier_1 (3fd5db728b0f635ad3fb51e4ac3a5c8d)         0.123717\n",
       "CatBoostClassifier_3 (fad9fe0d13abe5377a9667ad2452550c)    0.066482\n",
       "CatBoostClassifier_1 (6eca2de83af2fea3676cc9382d0f1011)    0.056833\n",
       "XGBClassifier_4 (9d4a18809c7642a3fc3412c67d01204f)         0.036370\n",
       "CatBoostClassifier_2 (b4347d306f6e52d59724382017b55f1b)    0.033230\n",
       "XGBRFClassifier_1 (aca0224f49af4aff337e4a3bd4021211)       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model_feature_importances = pd.Series(meta_train_feature_importances)\n",
    "meta_model_feature_importances.index = base_model_train_preds.columns\n",
    "meta_model_feature_importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95ca88",
   "metadata": {
    "papermill": {
     "duration": 0.016054,
     "end_time": "2025-12-13T06:22:41.621001",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.604947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.4 Final Adjustments to Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f31df96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:41.654081Z",
     "iopub.status.busy": "2025-12-13T06:22:41.653854Z",
     "iopub.status.idle": "2025-12-13T06:22:41.663932Z",
     "shell.execute_reply": "2025-12-13T06:22:41.663210Z"
    },
    "papermill": {
     "duration": 0.027931,
     "end_time": "2025-12-13T06:22:41.665075",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.637144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_max_scale(preds):\n",
    "    min_val = preds.min()\n",
    "    max_val = preds.max()\n",
    "    if max_val > min_val:\n",
    "        return (preds - min_val) / (max_val - min_val)\n",
    "    return preds\n",
    "\n",
    "# scale final meta oof/test preds\n",
    "scaled_final_meta_oof_preds = min_max_scale(final_meta_oof_preds)\n",
    "scaled_final_meta_test_preds = min_max_scale(final_meta_test_preds)\n",
    "\n",
    "# just in case floating point math leaves values very slightly below 0 or above 1\n",
    "scaled_final_meta_oof_preds = np.clip(scaled_final_meta_oof_preds, 0, 1)\n",
    "scaled_final_meta_test_preds = np.clip(scaled_final_meta_test_preds, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ded2c",
   "metadata": {
    "papermill": {
     "duration": 0.016331,
     "end_time": "2025-12-13T06:22:41.699876",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.683545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.5 Meta-Model AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dedf10c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:41.733859Z",
     "iopub.status.busy": "2025-12-13T06:22:41.733190Z",
     "iopub.status.idle": "2025-12-13T06:22:41.865209Z",
     "shell.execute_reply": "2025-12-13T06:22:41.864255Z"
    },
    "papermill": {
     "duration": 0.150381,
     "end_time": "2025-12-13T06:22:41.866578",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.716197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7277892187092612\n"
     ]
    }
   ],
   "source": [
    "meta_model_auc = roc_auc_score(train_data[target_col], scaled_final_meta_oof_preds)\n",
    "print(meta_model_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc73fe6",
   "metadata": {
    "papermill": {
     "duration": 0.017136,
     "end_time": "2025-12-13T06:22:41.903689",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.886553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 11. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0e82b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T06:22:41.938782Z",
     "iopub.status.busy": "2025-12-13T06:22:41.938085Z",
     "iopub.status.idle": "2025-12-13T06:22:42.484996Z",
     "shell.execute_reply": "2025-12-13T06:22:42.484157Z"
    },
    "papermill": {
     "duration": 0.565945,
     "end_time": "2025-12-13T06:22:42.486241",
     "exception": false,
     "start_time": "2025-12-13T06:22:41.920296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file prepared.\n"
     ]
    }
   ],
   "source": [
    "# prepare submission\n",
    "submission = pd.DataFrame({'id': test_data.index, target_col: scaled_final_meta_test_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file prepared.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14272474,
     "sourceId": 91723,
     "sourceType": "competition"
    },
    {
     "datasetId": 8925440,
     "sourceId": 14082085,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23583.105534,
   "end_time": "2025-12-13T06:22:44.767369",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T23:49:41.661835",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
