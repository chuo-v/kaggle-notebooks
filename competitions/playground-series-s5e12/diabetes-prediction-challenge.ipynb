{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87910012",
   "metadata": {
    "papermill": {
     "duration": 0.016422,
     "end_time": "2025-12-31T04:23:15.735807",
     "exception": false,
     "start_time": "2025-12-31T04:23:15.719385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Overview\n",
    "\n",
    "This is a notebook for training models to submit predictions to the \"Diabetes Prediction Challenge\" Kaggle competition ([playground-series-s5e12](https://www.kaggle.com/competitions/playground-series-s5e12)).\n",
    "\n",
    "Synthetic data is used for this playground competition, and the objective is to, for each patient in the test set, predict the probability that the patient will be diagnosed with diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5644d88",
   "metadata": {
    "papermill": {
     "duration": 0.013816,
     "end_time": "2025-12-31T04:23:15.764639",
     "exception": false,
     "start_time": "2025-12-31T04:23:15.750823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Setup\n",
    "\n",
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044efdff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:15.795524Z",
     "iopub.status.busy": "2025-12-31T04:23:15.795073Z",
     "iopub.status.idle": "2025-12-31T04:23:35.386885Z",
     "shell.execute_reply": "2025-12-31T04:23:35.385639Z"
    },
    "papermill": {
     "duration": 19.609699,
     "end_time": "2025-12-31T04:23:35.389568",
     "exception": false,
     "start_time": "2025-12-31T04:23:15.779869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import copy\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import os\n",
    "import hashlib as hl # for StackingEstimator\n",
    "import inspect # for StackingEstimator\n",
    "import random\n",
    "import warnings\n",
    "from catboost import CatBoostClassifier\n",
    "from enum import Enum\n",
    "from pathlib import Path # for StackingPredictionsRetriever\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression # for meta model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from types import FunctionType\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) # Display full column content\n",
    "pd.set_option('display.max_rows', None) # Display all rows\n",
    "pd.set_option('display.width', 1000) # Set larger display width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb0860",
   "metadata": {
    "papermill": {
     "duration": 0.01612,
     "end_time": "2025-12-31T04:23:35.420297",
     "exception": false,
     "start_time": "2025-12-31T04:23:35.404177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.2 Reproducibility\n",
    "\n",
    "For reproducibility of results, an arbitrary number will be used for the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5bdccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:35.450556Z",
     "iopub.status.busy": "2025-12-31T04:23:35.449888Z",
     "iopub.status.idle": "2025-12-31T04:23:35.466667Z",
     "shell.execute_reply": "2025-12-31T04:23:35.465625Z"
    },
    "papermill": {
     "duration": 0.033751,
     "end_time": "2025-12-31T04:23:35.468450",
     "exception": false,
     "start_time": "2025-12-31T04:23:35.434699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEEDS = [11, 42]\n",
    "random.seed(RANDOM_SEEDS[0])\n",
    "np.random.seed(RANDOM_SEEDS[0])\n",
    "torch.manual_seed(RANDOM_SEEDS[0])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEEDS[0])\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEEDS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c503b",
   "metadata": {
    "papermill": {
     "duration": 0.015467,
     "end_time": "2025-12-31T04:23:35.499215",
     "exception": false,
     "start_time": "2025-12-31T04:23:35.483748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.3 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d54b466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:35.529040Z",
     "iopub.status.busy": "2025-12-31T04:23:35.528701Z",
     "iopub.status.idle": "2025-12-31T04:23:35.533587Z",
     "shell.execute_reply": "2025-12-31T04:23:35.532487Z"
    },
    "papermill": {
     "duration": 0.02266,
     "end_time": "2025-12-31T04:23:35.535163",
     "exception": false,
     "start_time": "2025-12-31T04:23:35.512503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf57bc7",
   "metadata": {
    "papermill": {
     "duration": 0.016703,
     "end_time": "2025-12-31T04:23:35.566244",
     "exception": false,
     "start_time": "2025-12-31T04:23:35.549541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.4 DataFrames\n",
    "\n",
    "Read the data provided for the competition into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3122a11f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:35.596172Z",
     "iopub.status.busy": "2025-12-31T04:23:35.595817Z",
     "iopub.status.idle": "2025-12-31T04:23:38.490300Z",
     "shell.execute_reply": "2025-12-31T04:23:38.488922Z"
    },
    "papermill": {
     "duration": 2.912756,
     "end_time": "2025-12-31T04:23:38.492585",
     "exception": false,
     "start_time": "2025-12-31T04:23:35.579829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '/kaggle/input'\n",
    "orig_train_data = pd.read_csv(os.path.join(INPUT_DIR, 'playground-series-s5e12/train.csv'))\n",
    "orig_test_data = pd.read_csv(os.path.join(INPUT_DIR, 'playground-series-s5e12/test.csv'))\n",
    "\n",
    "# set index\n",
    "orig_train_data.set_index('id', inplace=True)\n",
    "orig_test_data.set_index('id', inplace=True)\n",
    "\n",
    "# target column\n",
    "target_col = \"diagnosed_diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5d4e5",
   "metadata": {
    "papermill": {
     "duration": 0.01389,
     "end_time": "2025-12-31T04:23:38.519935",
     "exception": false,
     "start_time": "2025-12-31T04:23:38.506045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38dd21d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:38.549277Z",
     "iopub.status.busy": "2025-12-31T04:23:38.548887Z",
     "iopub.status.idle": "2025-12-31T04:23:38.553383Z",
     "shell.execute_reply": "2025-12-31T04:23:38.552350Z"
    },
    "papermill": {
     "duration": 0.021407,
     "end_time": "2025-12-31T04:23:38.554852",
     "exception": false,
     "start_time": "2025-12-31T04:23:38.533445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip the generation of plots (e.g. KDE) in this section that take time; set to False to generate the plots \n",
    "SKIP_PLOTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f6624d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:38.585622Z",
     "iopub.status.busy": "2025-12-31T04:23:38.584950Z",
     "iopub.status.idle": "2025-12-31T04:23:39.288113Z",
     "shell.execute_reply": "2025-12-31T04:23:39.287112Z"
    },
    "papermill": {
     "duration": 0.719454,
     "end_time": "2025-12-31T04:23:39.289914",
     "exception": false,
     "start_time": "2025-12-31T04:23:38.570460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "      <td>700000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.359734</td>\n",
       "      <td>2.072411</td>\n",
       "      <td>80.230803</td>\n",
       "      <td>5.963695</td>\n",
       "      <td>7.002200</td>\n",
       "      <td>6.012733</td>\n",
       "      <td>25.874684</td>\n",
       "      <td>0.858766</td>\n",
       "      <td>116.294193</td>\n",
       "      <td>75.440924</td>\n",
       "      <td>70.167749</td>\n",
       "      <td>186.818801</td>\n",
       "      <td>53.823214</td>\n",
       "      <td>102.905854</td>\n",
       "      <td>123.081850</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.181990</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>0.623296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.655520</td>\n",
       "      <td>1.048189</td>\n",
       "      <td>51.195071</td>\n",
       "      <td>1.463336</td>\n",
       "      <td>0.901907</td>\n",
       "      <td>2.022707</td>\n",
       "      <td>2.860705</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>11.010390</td>\n",
       "      <td>6.825775</td>\n",
       "      <td>6.938722</td>\n",
       "      <td>16.730832</td>\n",
       "      <td>8.266545</td>\n",
       "      <td>19.022416</td>\n",
       "      <td>24.739397</td>\n",
       "      <td>0.356484</td>\n",
       "      <td>0.385837</td>\n",
       "      <td>0.171478</td>\n",
       "      <td>0.484560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  alcohol_consumption_per_week  physical_activity_minutes_per_week     diet_score  sleep_hours_per_day  screen_time_hours_per_day            bmi  waist_to_hip_ratio    systolic_bp   diastolic_bp     heart_rate  cholesterol_total  hdl_cholesterol  ldl_cholesterol  triglycerides  family_history_diabetes  hypertension_history  cardiovascular_history  diagnosed_diabetes\n",
       "count  700000.000000                 700000.000000                       700000.000000  700000.000000        700000.000000              700000.000000  700000.000000       700000.000000  700000.000000  700000.000000  700000.000000      700000.000000    700000.000000    700000.000000  700000.000000            700000.000000         700000.000000           700000.000000       700000.000000\n",
       "mean       50.359734                      2.072411                           80.230803       5.963695             7.002200                   6.012733      25.874684            0.858766     116.294193      75.440924      70.167749         186.818801        53.823214       102.905854     123.081850                 0.149401              0.181990                0.030324            0.623296\n",
       "std        11.655520                      1.048189                           51.195071       1.463336             0.901907                   2.022707       2.860705            0.037980      11.010390       6.825775       6.938722          16.730832         8.266545        19.022416      24.739397                 0.356484              0.385837                0.171478            0.484560\n",
       "min        19.000000                      1.000000                            1.000000       0.100000             3.100000                   0.600000      15.100000            0.680000      91.000000      51.000000      42.000000         117.000000        21.000000        51.000000      31.000000                 0.000000              0.000000                0.000000            0.000000\n",
       "25%        42.000000                      1.000000                           49.000000       5.000000             6.400000                   4.600000      23.900000            0.830000     108.000000      71.000000      65.000000         175.000000        48.000000        89.000000     106.000000                 0.000000              0.000000                0.000000            0.000000\n",
       "50%        50.000000                      2.000000                           71.000000       6.000000             7.000000                   6.000000      25.900000            0.860000     116.000000      75.000000      70.000000         187.000000        54.000000       103.000000     123.000000                 0.000000              0.000000                0.000000            1.000000\n",
       "75%        58.000000                      3.000000                           96.000000       7.000000             7.600000                   7.400000      27.800000            0.880000     124.000000      80.000000      75.000000         199.000000        59.000000       116.000000     139.000000                 0.000000              0.000000                0.000000            1.000000\n",
       "max        89.000000                      9.000000                          747.000000       9.900000             9.900000                  16.500000      38.400000            1.050000     163.000000     104.000000     101.000000         289.000000        90.000000       205.000000     290.000000                 1.000000              1.000000                1.000000            1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7cacf36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:39.320189Z",
     "iopub.status.busy": "2025-12-31T04:23:39.319825Z",
     "iopub.status.idle": "2025-12-31T04:23:39.605489Z",
     "shell.execute_reply": "2025-12-31T04:23:39.604406Z"
    },
    "papermill": {
     "duration": 0.302806,
     "end_time": "2025-12-31T04:23:39.607223",
     "exception": false,
     "start_time": "2025-12-31T04:23:39.304417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>diet_score</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>screen_time_hours_per_day</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_to_hip_ratio</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>cholesterol_total</th>\n",
       "      <th>hdl_cholesterol</th>\n",
       "      <th>ldl_cholesterol</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>family_history_diabetes</th>\n",
       "      <th>hypertension_history</th>\n",
       "      <th>cardiovascular_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "      <td>300000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.432397</td>\n",
       "      <td>2.089693</td>\n",
       "      <td>92.349087</td>\n",
       "      <td>5.945838</td>\n",
       "      <td>6.997795</td>\n",
       "      <td>6.011278</td>\n",
       "      <td>25.881906</td>\n",
       "      <td>0.859007</td>\n",
       "      <td>116.374117</td>\n",
       "      <td>75.396013</td>\n",
       "      <td>70.048350</td>\n",
       "      <td>187.308620</td>\n",
       "      <td>53.813557</td>\n",
       "      <td>103.416083</td>\n",
       "      <td>123.538480</td>\n",
       "      <td>0.152920</td>\n",
       "      <td>0.184410</td>\n",
       "      <td>0.033110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.938741</td>\n",
       "      <td>1.066214</td>\n",
       "      <td>62.187399</td>\n",
       "      <td>1.481068</td>\n",
       "      <td>0.914693</td>\n",
       "      <td>2.060472</td>\n",
       "      <td>2.894289</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>11.252146</td>\n",
       "      <td>6.950340</td>\n",
       "      <td>7.090543</td>\n",
       "      <td>18.413053</td>\n",
       "      <td>8.398126</td>\n",
       "      <td>20.571855</td>\n",
       "      <td>28.965441</td>\n",
       "      <td>0.359911</td>\n",
       "      <td>0.387819</td>\n",
       "      <td>0.178924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>38.300000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  alcohol_consumption_per_week  physical_activity_minutes_per_week     diet_score  sleep_hours_per_day  screen_time_hours_per_day            bmi  waist_to_hip_ratio    systolic_bp   diastolic_bp     heart_rate  cholesterol_total  hdl_cholesterol  ldl_cholesterol  triglycerides  family_history_diabetes  hypertension_history  cardiovascular_history\n",
       "count  300000.000000                 300000.000000                       300000.000000  300000.000000        300000.000000              300000.000000  300000.000000       300000.000000  300000.000000  300000.000000  300000.000000      300000.000000    300000.000000    300000.000000  300000.000000            300000.000000         300000.000000           300000.000000\n",
       "mean       50.432397                      2.089693                           92.349087       5.945838             6.997795                   6.011278      25.881906            0.859007     116.374117      75.396013      70.048350         187.308620        53.813557       103.416083     123.538480                 0.152920              0.184410                0.033110\n",
       "std        11.938741                      1.066214                           62.187399       1.481068             0.914693                   2.060472       2.894289            0.038523      11.252146       6.950340       7.090543          18.413053         8.398126        20.571855      28.965441                 0.359911              0.387819                0.178924\n",
       "min        19.000000                      1.000000                            1.000000       0.100000             3.100000                   0.600000      15.100000            0.690000      91.000000      51.000000      42.000000         107.000000        22.000000        51.000000      31.000000                 0.000000              0.000000                0.000000\n",
       "25%        42.000000                      1.000000                           51.000000       5.000000             6.400000                   4.600000      23.900000            0.830000     108.000000      71.000000      65.000000         174.000000        48.000000        89.000000     104.000000                 0.000000              0.000000                0.000000\n",
       "50%        50.000000                      2.000000                           77.000000       6.000000             7.000000                   6.000000      25.900000            0.860000     116.000000      75.000000      70.000000         187.000000        54.000000       103.000000     123.000000                 0.000000              0.000000                0.000000\n",
       "75%        59.000000                      3.000000                          115.000000       7.000000             7.600000                   7.400000      27.800000            0.890000     124.000000      80.000000      75.000000         200.000000        60.000000       117.000000     142.000000                 0.000000              0.000000                0.000000\n",
       "max        89.000000                      9.000000                          748.000000       9.900000             9.900000                  15.900000      38.300000            1.050000     170.000000     104.000000     101.000000         285.000000        91.000000       226.000000     290.000000                 1.000000              1.000000                1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae87e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:39.639234Z",
     "iopub.status.busy": "2025-12-31T04:23:39.638883Z",
     "iopub.status.idle": "2025-12-31T04:23:39.777775Z",
     "shell.execute_reply": "2025-12-31T04:23:39.776800Z"
    },
    "papermill": {
     "duration": 0.157643,
     "end_time": "2025-12-31T04:23:39.779524",
     "exception": false,
     "start_time": "2025-12-31T04:23:39.621881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_col_names = orig_train_data.select_dtypes(include='number').columns.to_series()\n",
    "categorical_col_names = orig_train_data.select_dtypes(include='object').columns.to_series()\n",
    "assert numeric_col_names.size + categorical_col_names.size == orig_train_data.shape[1]\n",
    "\n",
    "# drop target column from numeric column names\n",
    "numeric_col_names.drop(target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0fb820a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:39.809972Z",
     "iopub.status.busy": "2025-12-31T04:23:39.809661Z",
     "iopub.status.idle": "2025-12-31T04:23:40.139778Z",
     "shell.execute_reply": "2025-12-31T04:23:40.138462Z"
    },
    "papermill": {
     "duration": 0.347008,
     "end_time": "2025-12-31T04:23:40.141362",
     "exception": false,
     "start_time": "2025-12-31T04:23:39.794354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train data missing values #####\n",
      "age                                   0\n",
      "alcohol_consumption_per_week          0\n",
      "physical_activity_minutes_per_week    0\n",
      "diet_score                            0\n",
      "sleep_hours_per_day                   0\n",
      "screen_time_hours_per_day             0\n",
      "bmi                                   0\n",
      "waist_to_hip_ratio                    0\n",
      "systolic_bp                           0\n",
      "diastolic_bp                          0\n",
      "heart_rate                            0\n",
      "cholesterol_total                     0\n",
      "hdl_cholesterol                       0\n",
      "ldl_cholesterol                       0\n",
      "triglycerides                         0\n",
      "gender                                0\n",
      "ethnicity                             0\n",
      "education_level                       0\n",
      "income_level                          0\n",
      "smoking_status                        0\n",
      "employment_status                     0\n",
      "family_history_diabetes               0\n",
      "hypertension_history                  0\n",
      "cardiovascular_history                0\n",
      "diagnosed_diabetes                    0\n",
      "dtype: int64\n",
      "\n",
      "##### Test data missing values #####\n",
      "age                                   0\n",
      "alcohol_consumption_per_week          0\n",
      "physical_activity_minutes_per_week    0\n",
      "diet_score                            0\n",
      "sleep_hours_per_day                   0\n",
      "screen_time_hours_per_day             0\n",
      "bmi                                   0\n",
      "waist_to_hip_ratio                    0\n",
      "systolic_bp                           0\n",
      "diastolic_bp                          0\n",
      "heart_rate                            0\n",
      "cholesterol_total                     0\n",
      "hdl_cholesterol                       0\n",
      "ldl_cholesterol                       0\n",
      "triglycerides                         0\n",
      "gender                                0\n",
      "ethnicity                             0\n",
      "education_level                       0\n",
      "income_level                          0\n",
      "smoking_status                        0\n",
      "employment_status                     0\n",
      "family_history_diabetes               0\n",
      "hypertension_history                  0\n",
      "cardiovascular_history                0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (dataset_name, dataset) in [('Train data', orig_train_data), ('Test data', orig_test_data)]:\n",
    "    print(f\"##### {dataset_name} missing values #####\")\n",
    "    print(dataset.isnull().sum())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cb075fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:40.171646Z",
     "iopub.status.busy": "2025-12-31T04:23:40.171330Z",
     "iopub.status.idle": "2025-12-31T04:23:40.557795Z",
     "shell.execute_reply": "2025-12-31T04:23:40.556544Z"
    },
    "papermill": {
     "duration": 0.403707,
     "end_time": "2025-12-31T04:23:40.559559",
     "exception": false,
     "start_time": "2025-12-31T04:23:40.155852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Train data categorical cols unique values #####\n",
      "gender:\n",
      "['Female' 'Male' 'Other']\n",
      "ethnicity:\n",
      "['Hispanic' 'White' 'Asian' 'Black' 'Other']\n",
      "education_level:\n",
      "['Highschool' 'Graduate' 'Postgraduate' 'No formal']\n",
      "income_level:\n",
      "['Lower-Middle' 'Upper-Middle' 'Low' 'Middle' 'High']\n",
      "smoking_status:\n",
      "['Current' 'Never' 'Former']\n",
      "employment_status:\n",
      "['Employed' 'Retired' 'Student' 'Unemployed']\n",
      "\n",
      "##### Test data categorical cols unique values #####\n",
      "gender:\n",
      "['Female' 'Male' 'Other']\n",
      "ethnicity:\n",
      "['White' 'Hispanic' 'Black' 'Asian' 'Other']\n",
      "education_level:\n",
      "['Highschool' 'Graduate' 'Postgraduate' 'No formal']\n",
      "income_level:\n",
      "['Middle' 'Low' 'Lower-Middle' 'Upper-Middle' 'High']\n",
      "smoking_status:\n",
      "['Former' 'Never' 'Current']\n",
      "employment_status:\n",
      "['Employed' 'Unemployed' 'Retired' 'Student']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (dataset_name, dataset) in [('Train data', orig_train_data), ('Test data', orig_test_data)]:\n",
    "    print(f\"##### {dataset_name} categorical cols unique values #####\")\n",
    "    for categorical_col_name in categorical_col_names:\n",
    "        print(f\"{categorical_col_name}:\")\n",
    "        print(dataset[categorical_col_name].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a873c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:40.597162Z",
     "iopub.status.busy": "2025-12-31T04:23:40.596550Z",
     "iopub.status.idle": "2025-12-31T04:23:40.605850Z",
     "shell.execute_reply": "2025-12-31T04:23:40.604566Z"
    },
    "papermill": {
     "duration": 0.031223,
     "end_time": "2025-12-31T04:23:40.607863",
     "exception": false,
     "start_time": "2025-12-31T04:23:40.576640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KDE plots of target variable and numerical features\n",
    "if not SKIP_PLOTS:\n",
    "    plt.figure(figsize=(12, 24))\n",
    "    kdeplot_col_names = [target_col]\n",
    "    kdeplot_col_names.extend(numeric_col_names)\n",
    "    for i, col in enumerate(kdeplot_col_names, start=1):\n",
    "        plt.subplot(10, 2, i)\n",
    "        sns.kdeplot(data=orig_train_data, x=col, fill=True)\n",
    "        plt.tight_layout()\n",
    "        plt.title(f\"KDE plot of {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a37dc31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:40.645452Z",
     "iopub.status.busy": "2025-12-31T04:23:40.645016Z",
     "iopub.status.idle": "2025-12-31T04:23:40.650904Z",
     "shell.execute_reply": "2025-12-31T04:23:40.650155Z"
    },
    "papermill": {
     "duration": 0.02927,
     "end_time": "2025-12-31T04:23:40.652653",
     "exception": false,
     "start_time": "2025-12-31T04:23:40.623383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SKIP_PLOTS:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        orig_train_data[numeric_col_names].corr(),\n",
    "        cmap='Reds',\n",
    "        annot=True,\n",
    "        linewidths=2,\n",
    "        fmt='.2f',\n",
    "        vmin=-1,\n",
    "        vmax=1\n",
    "    )\n",
    "    plt.title('Correlation Matrix of Numerical Features', fontsize=18, pad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d38e55b",
   "metadata": {
    "papermill": {
     "duration": 0.021937,
     "end_time": "2025-12-31T04:23:40.693944",
     "exception": false,
     "start_time": "2025-12-31T04:23:40.672007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "289233a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:40.735281Z",
     "iopub.status.busy": "2025-12-31T04:23:40.734804Z",
     "iopub.status.idle": "2025-12-31T04:23:40.901704Z",
     "shell.execute_reply": "2025-12-31T04:23:40.900825Z"
    },
    "papermill": {
     "duration": 0.190535,
     "end_time": "2025-12-31T04:23:40.903586",
     "exception": false,
     "start_time": "2025-12-31T04:23:40.713051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = orig_train_data.copy()\n",
    "test_data = orig_test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813220b",
   "metadata": {
    "papermill": {
     "duration": 0.01433,
     "end_time": "2025-12-31T04:23:40.933954",
     "exception": false,
     "start_time": "2025-12-31T04:23:40.919624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1 Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8838855e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:40.965895Z",
     "iopub.status.busy": "2025-12-31T04:23:40.964899Z",
     "iopub.status.idle": "2025-12-31T04:23:41.985413Z",
     "shell.execute_reply": "2025-12-31T04:23:41.984368Z"
    },
    "papermill": {
     "duration": 1.038914,
     "end_time": "2025-12-31T04:23:41.987051",
     "exception": false,
     "start_time": "2025-12-31T04:23:40.948137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_level_encoded:\n",
      "{'No formal': 0, 'Highschool': 1, 'Graduate': 2, 'Postgraduate': 3}\n",
      "income_level_encoded:\n",
      "{'Low': 0, 'Lower-Middle': 1, 'Middle': 2, 'Upper-Middle': 3, 'High': 4}\n",
      "smoking_status_encoded:\n",
      "{'Never': 0, 'Former': 1, 'Current': 2}\n"
     ]
    }
   ],
   "source": [
    "# education level\n",
    "education_level_encoder = OrdinalEncoder(categories=[['No formal', 'Highschool', 'Graduate', 'Postgraduate']])\n",
    "train_data['education_level_encoded'] = education_level_encoder.fit_transform(train_data[['education_level']])\n",
    "test_data['education_level_encoded'] = education_level_encoder.fit_transform(test_data[['education_level']])\n",
    "\n",
    "# income level\n",
    "income_level_encoder = OrdinalEncoder(categories=[['Low', 'Lower-Middle','Middle', 'Upper-Middle', 'High']])\n",
    "train_data['income_level_encoded'] = income_level_encoder.fit_transform(train_data[['income_level']])\n",
    "test_data['income_level_encoded'] = income_level_encoder.fit_transform(test_data[['income_level']])\n",
    "\n",
    "# smoking status\n",
    "smoking_status_encoder = OrdinalEncoder(categories=[['Never', 'Former', 'Current']])\n",
    "train_data['smoking_status_encoded'] = smoking_status_encoder.fit_transform(train_data[['smoking_status']])\n",
    "test_data['smoking_status_encoded'] = smoking_status_encoder.fit_transform(test_data[['smoking_status']])\n",
    "\n",
    "# drop original cols\n",
    "for col in ['income_level', 'education_level', 'smoking_status']:\n",
    "    train_data.drop(col, axis=1, inplace=True)\n",
    "    test_data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# print out value maps to check assigned values are as expected\n",
    "for (encoded_col_name, encoder) in [\n",
    "    ('education_level_encoded', education_level_encoder),\n",
    "    ('income_level_encoded', income_level_encoder),\n",
    "    ('smoking_status_encoded', smoking_status_encoder),\n",
    "]:\n",
    "    categories = encoder.categories_[0]\n",
    "    value_map = { category: i for i, category in enumerate(categories) }\n",
    "    print(f\"{encoded_col_name}:\\n{value_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb8aed",
   "metadata": {
    "papermill": {
     "duration": 0.016538,
     "end_time": "2025-12-31T04:23:42.019519",
     "exception": false,
     "start_time": "2025-12-31T04:23:42.002981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c79f048e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:42.052537Z",
     "iopub.status.busy": "2025-12-31T04:23:42.051647Z",
     "iopub.status.idle": "2025-12-31T04:23:42.075006Z",
     "shell.execute_reply": "2025-12-31T04:23:42.073789Z"
    },
    "papermill": {
     "duration": 0.041914,
     "end_time": "2025-12-31T04:23:42.076749",
     "exception": false,
     "start_time": "2025-12-31T04:23:42.034835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_blood_pressure(df):\n",
    "    mask = df['diastolic_bp'] > df['systolic_bp']\n",
    "    df.loc[mask, ['systolic_bp', 'diastolic_bp']] = (\n",
    "        df.loc[mask, ['diastolic_bp', 'systolic_bp']].values\n",
    "    )\n",
    "    return df\n",
    "\n",
    "train_data = fix_blood_pressure(train_data)\n",
    "test_data = fix_blood_pressure(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb1fce",
   "metadata": {
    "papermill": {
     "duration": 0.014245,
     "end_time": "2025-12-31T04:23:42.105532",
     "exception": false,
     "start_time": "2025-12-31T04:23:42.091287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3 Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f603c3ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:42.136340Z",
     "iopub.status.busy": "2025-12-31T04:23:42.135979Z",
     "iopub.status.idle": "2025-12-31T04:23:42.151529Z",
     "shell.execute_reply": "2025-12-31T04:23:42.150415Z"
    },
    "papermill": {
     "duration": 0.033406,
     "end_time": "2025-12-31T04:23:42.153346",
     "exception": false,
     "start_time": "2025-12-31T04:23:42.119940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_generated_features(df):\n",
    "    # log transforms for skewed data\n",
    "    for col in ['triglycerides', 'ldl_cholesterol', 'cholesterol_total']:\n",
    "        df[f'log_{col}'] = np.log1p(df[col])\n",
    "\n",
    "    # medical ratios & interactions\n",
    "    df['cholesterol_ratio'] = df['cholesterol_total'] / (df['hdl_cholesterol'] + 1e-5)\n",
    "    df['ldl_hdl_ratio'] = df['ldl_cholesterol'] / (df['hdl_cholesterol'] + 1e-5)\n",
    "    df['pulse_pressure'] = df['systolic_bp'] - df['diastolic_bp']\n",
    "    df['mean_arterial_pressure'] = (df['systolic_bp'] + 2 * df['diastolic_bp']) / 3\n",
    "    df['age_x_bmi'] = df['age'] * df['bmi']\n",
    "    df['waist_x_bmi'] = df['waist_to_hip_ratio'] * df['bmi']\n",
    "    df['family_history_diabetes_x_log_triglycerides'] = df['family_history_diabetes'] * df['log_triglycerides']\n",
    "    df['hypertension_history_x_systolic_bp'] = df['hypertension_history'] * df['systolic_bp']\n",
    "    df['activity_x_diet'] = df['physical_activity_minutes_per_week'] * df['diet_score']\n",
    "    df['atherogenic_index'] = np.log((df['triglycerides'] / (df['hdl_cholesterol'] + 1e-5)) + 1e-5)\n",
    "    df['non_hdl_cholesterol'] = df['cholesterol_total'] - df['hdl_cholesterol']\n",
    "    df['map_x_bmi'] = df['mean_arterial_pressure'] * df['bmi']\n",
    "    df['lipid_accumulation_proxy'] = df['waist_to_hip_ratio'] * df['log_triglycerides']\n",
    "    df['visceral_adiposity_proxy'] = (df['bmi'] * df['triglycerides']) / (df['hdl_cholesterol'] + 1e-5)\n",
    "\n",
    "    # squared\n",
    "    df['age_sq'] = df['age'] ** 2\n",
    "    df['bmi_sq'] = df['bmi'] ** 2\n",
    "    df['waist_to_hip_ratio_sq'] = df['waist_to_hip_ratio'] ** 2\n",
    "    df['systolic_bp_sq'] = df['systolic_bp'] ** 2\n",
    "\n",
    "    # risk grouping\n",
    "    df['comorbidity_count'] = (\n",
    "        df['hypertension_history'] + df['cardiovascular_history'] + df['family_history_diabetes']\n",
    "    )\n",
    "\n",
    "    # binning\n",
    "    df['bmi_cat'] = pd.cut(df['bmi'], bins=[-1, 25, 30, 100], labels=[0, 1, 2]).astype(int)\n",
    "    df['bp_cat'] = pd.cut(\n",
    "        df['systolic_bp'], \n",
    "        bins=[-1, 120, 130, 140, 300], # AHA Guidelines: Normal < 120, Elevated 120-129, Stage 1 130-139, Stage 2 >= 140\n",
    "        labels=[0, 1, 2, 3] # Normal, Elevated, Stage 1, Stage 2\n",
    "    ).astype(int)\n",
    "    df['cholesterol_cat'] = pd.cut(\n",
    "        df['cholesterol_total'], \n",
    "        bins=[-1, 200, 240, 1000], # ATP III Guidelines: Optimal < 200, Borderline 200-239, High >= 240\n",
    "        labels=[0, 1, 2]\n",
    "    ).astype(int)\n",
    "    df['hdl_cat'] = pd.cut(\n",
    "        df['hdl_cholesterol'], \n",
    "        bins=[-1, 40, 60, 200], # Inverted Risk: Risk < 40, Normal 40-60, Protective > 60\n",
    "        labels=[2, 1, 0] # 2 is worst (Low HDL)\n",
    "    ).astype(int)\n",
    "    df['ldl_cat'] = pd.cut(\n",
    "        df['ldl_cholesterol'], \n",
    "        bins=[-1, 100, 130, 160, 190, 1000], # ATP III Guidelines: Optimal < 100, Near Optimal 100-129, Borderline High 130-159, High 160-189, Very High >= 190\n",
    "        labels=[0, 1, 2, 3, 4] # 0 is best (Optimal), 4 is worst (Very High)\n",
    "    ).astype(int)\n",
    "\n",
    "    # quantile binning\n",
    "    quantile_cols = [\n",
    "        'triglycerides', 'waist_to_hip_ratio', 'bmi', 'mean_arterial_pressure'\n",
    "    ]\n",
    "    for col in quantile_cols:\n",
    "        df[f'{col}_decile'] = pd.qcut(df[col], q=10, labels=False, duplicates='drop').astype(int)\n",
    "\n",
    "    # relative BMI, BP and cholesterol\n",
    "    df['age_decade'] = (df['age'] // 10).astype(int)\n",
    "    for group_col in ['age_decade', 'hypertension_history']:\n",
    "        for num_col in ['bmi', 'systolic_bp', 'cholesterol_total']:\n",
    "            group_means = df.groupby(group_col)[num_col].transform('mean')\n",
    "            df[f'{num_col}_relative_to_{group_col}'] = df[num_col] - group_means\n",
    "\n",
    "    # bin interactions\n",
    "    df['age_bp_interaction'] = df['age_decade'].astype(str) + '_' + df['bp_cat'].astype(str)\n",
    "    df['age_bp_interaction'] = df['age_bp_interaction'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58d0f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:42.187476Z",
     "iopub.status.busy": "2025-12-31T04:23:42.186795Z",
     "iopub.status.idle": "2025-12-31T04:23:42.195329Z",
     "shell.execute_reply": "2025-12-31T04:23:42.193958Z"
    },
    "papermill": {
     "duration": 0.027351,
     "end_time": "2025-12-31T04:23:42.197317",
     "exception": false,
     "start_time": "2025-12-31T04:23:42.169966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_kmeans_features(train_df, test_df, n_clusters):\n",
    "    features_to_cluster = [\n",
    "        'age', 'bmi', 'mean_arterial_pressure', 'cholesterol_ratio', 'log_triglycerides'\n",
    "    ]\n",
    "    \n",
    "    combined = pd.concat([train_df[features_to_cluster], test_df[features_to_cluster]], axis=0)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(combined)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_SEEDS[0], n_init=10)\n",
    "    clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "    train_dists = kmeans.transform(scaled_data[:len(train_df)])\n",
    "    test_dists = kmeans.transform(scaled_data[len(train_df):])\n",
    "\n",
    "    train_df['cluster_label'] = clusters[:len(train_df)].astype(object)\n",
    "    test_df['cluster_label'] = clusters[len(train_df):].astype(object)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        train_df[f'dist_to_cluster_{i}'] = train_dists[:, i]\n",
    "        test_df[f'dist_to_cluster_{i}'] = test_dists[:, i]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d323058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:42.229826Z",
     "iopub.status.busy": "2025-12-31T04:23:42.229263Z",
     "iopub.status.idle": "2025-12-31T04:23:59.421048Z",
     "shell.execute_reply": "2025-12-31T04:23:59.419841Z"
    },
    "papermill": {
     "duration": 17.209848,
     "end_time": "2025-12-31T04:23:59.423104",
     "exception": false,
     "start_time": "2025-12-31T04:23:42.213256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add generated features\n",
    "add_generated_features(train_data)\n",
    "add_generated_features(test_data)\n",
    "\n",
    "# apply clustering\n",
    "train_data, test_data = add_kmeans_features(train_data, test_data, n_clusters=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "713bdbb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:59.460793Z",
     "iopub.status.busy": "2025-12-31T04:23:59.460136Z",
     "iopub.status.idle": "2025-12-31T04:23:59.467873Z",
     "shell.execute_reply": "2025-12-31T04:23:59.466600Z"
    },
    "papermill": {
     "duration": 0.028571,
     "end_time": "2025-12-31T04:23:59.469565",
     "exception": false,
     "start_time": "2025-12-31T04:23:59.440994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'gender', 'ethnicity', 'employment_status', 'family_history_diabetes', 'hypertension_history', 'cardiovascular_history', 'diagnosed_diabetes', 'education_level_encoded', 'income_level_encoded', 'smoking_status_encoded', 'log_triglycerides', 'log_ldl_cholesterol', 'log_cholesterol_total', 'cholesterol_ratio', 'ldl_hdl_ratio', 'pulse_pressure', 'mean_arterial_pressure', 'age_x_bmi', 'waist_x_bmi', 'family_history_diabetes_x_log_triglycerides', 'hypertension_history_x_systolic_bp', 'activity_x_diet', 'atherogenic_index', 'non_hdl_cholesterol', 'map_x_bmi', 'lipid_accumulation_proxy', 'visceral_adiposity_proxy', 'age_sq', 'bmi_sq', 'waist_to_hip_ratio_sq', 'systolic_bp_sq', 'comorbidity_count',\n",
       "       'bmi_cat', 'bp_cat', 'cholesterol_cat', 'hdl_cat', 'ldl_cat', 'triglycerides_decile', 'waist_to_hip_ratio_decile', 'bmi_decile', 'mean_arterial_pressure_decile', 'age_decade', 'bmi_relative_to_age_decade', 'systolic_bp_relative_to_age_decade', 'cholesterol_total_relative_to_age_decade', 'bmi_relative_to_hypertension_history', 'systolic_bp_relative_to_hypertension_history', 'cholesterol_total_relative_to_hypertension_history', 'age_bp_interaction', 'cluster_label', 'dist_to_cluster_0', 'dist_to_cluster_1', 'dist_to_cluster_2', 'dist_to_cluster_3', 'dist_to_cluster_4', 'dist_to_cluster_5', 'dist_to_cluster_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053edfd3",
   "metadata": {
    "papermill": {
     "duration": 0.015821,
     "end_time": "2025-12-31T04:23:59.500598",
     "exception": false,
     "start_time": "2025-12-31T04:23:59.484777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4 Remaining Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2102c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:23:59.537609Z",
     "iopub.status.busy": "2025-12-31T04:23:59.536588Z",
     "iopub.status.idle": "2025-12-31T04:24:00.251795Z",
     "shell.execute_reply": "2025-12-31T04:24:00.250396Z"
    },
    "papermill": {
     "duration": 0.735682,
     "end_time": "2025-12-31T04:24:00.254225",
     "exception": false,
     "start_time": "2025-12-31T04:23:59.518543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_features = train_data.drop(target_col, axis=1).select_dtypes(include='object').columns.to_list()\n",
    "if len(cat_features) > 0:\n",
    "    for col in cat_features:\n",
    "        train_data[col] = train_data[col].astype('category')\n",
    "        test_data[col] = test_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f27d29",
   "metadata": {
    "papermill": {
     "duration": 0.01495,
     "end_time": "2025-12-31T04:24:00.284059",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.269109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Stacking Initial Setup\n",
    "\n",
    "We'll use stacking, an [ensemble learning](https://en.wikipedia.org/wiki/Ensemble_learning) strategy, to generate the predictions. As we'll need to gather predictions from various base models (a.k.a. level-0 models) to feed as input features to a meta model (a.k.a. level-1 model), in order to streamline the process of experimenting with different combinations of base models, some helper classes will be defined in this section. These classes can also be found [here](https://github.com/chuo-v/machine-learning-utils/blob/master/ensemble-learning/stacking/stacking_predictions_retriever.py) at one of my GitHub repositories used to organize some utilities I implemented for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faeda41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.321531Z",
     "iopub.status.busy": "2025-12-31T04:24:00.321185Z",
     "iopub.status.idle": "2025-12-31T04:24:00.360504Z",
     "shell.execute_reply": "2025-12-31T04:24:00.359494Z"
    },
    "papermill": {
     "duration": 0.059768,
     "end_time": "2025-12-31T04:24:00.362795",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.303027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackingEstimator:\n",
    "    \"\"\"\n",
    "    A class representing an estimator that will be used for stacking, an ensemble learning strategy.\n",
    "\n",
    "    Intended to be used in conjunction with the `StackingPredictionsRetriever` class, which helps\n",
    "    retrieve predictions for multiple instances of `StackingEstimator`; as the predictions are saved\n",
    "    in files, on subsequent requests to retrieve predictions, even as the set of estimators has been\n",
    "    modified, the `StackingPredictionsRetriever` class can determine the predictions of estimators\n",
    "    that are non-stale and available (if any) by using the `get_hash` method of the `StackingEstimator`\n",
    "    class to determine the relevance and staleness of any saved predictions.\n",
    "\n",
    "    Proper usage of this class requires one important condition to be satisfied: the predictions made\n",
    "    using the estimator are determinstic, i.e. they are exactly the same everytime the estimator is\n",
    "    run with the same inputs (`name`, `params_dict`, `feature_names`, `get_predictions`).\n",
    "    \"\"\"\n",
    "    name = \"\"\n",
    "    params_dict = {}\n",
    "    feature_names = []\n",
    "    get_predictions = lambda: None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        feature_names: [str],\n",
    "        params_dict: {},\n",
    "        get_preds: FunctionType\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of `StackingEstimator`.\n",
    "\n",
    "        :param name:\n",
    "            A string representing a name for the estimator. It is used for the column names of\n",
    "            the training and test predictions for each estimator, and is also used as an input\n",
    "            to calculate a hash value for the estimator. It is recommended to use a different\n",
    "            name from the names used for other estimators passed to `StackingPredictionsRetriever`.\n",
    "        :param feature_names:\n",
    "            A list of strings representing the names of the features that will be used for the\n",
    "            estimator. It will be passed as an argument to `get_preds`. Internally, it is only\n",
    "            used as an input to calculate a hash value for the estimator.\n",
    "        :param params_dict:\n",
    "            A dictionary of parameters that will be specified for the estimator. It will be\n",
    "            passed as an argument to `get_preds`. Internally, it is only used as an input\n",
    "            to calculate a hash value for the estimator.\n",
    "        :param get_preds:\n",
    "            A function for getting the predictions for the estimator. It should only take two\n",
    "            arguments: 'params_dict' and 'feature_names', and should return predictions for\n",
    "            the training and test data (in that order) as a tuple of two `pandas.Series`.\n",
    "        \"\"\"\n",
    "        # parameter check\n",
    "        if not isinstance(name, str):\n",
    "            raise ValueError(\"`name` argument should be of type `str`\")\n",
    "        if not isinstance(feature_names, list):\n",
    "            raise ValueError(f\"`feature_names` argument for estimator \\\"{name}\\\" should be of type `list`\")\n",
    "        elif not all(isinstance(feature_name, str) for feature_name in feature_names):\n",
    "            raise ValueError(f\"`feature_names` argument for estimator \\\"{name}\\\" should only contain instances of `str`\")\n",
    "        if not isinstance(params_dict, dict):\n",
    "            raise ValueError(f\"`params_dict` argument for estimator \\\"{name}\\\" should be of type `dict`\")\n",
    "        get_preds_params = inspect.signature(get_preds).parameters.values()\n",
    "        get_preds_param_names = [param.name for param in get_preds_params]\n",
    "        if len(get_preds_param_names) != 2:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take two arguments\")\n",
    "        elif \"params_dict\" not in get_preds_param_names:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take a \\\"params_dict\\\" argument\")\n",
    "        elif \"feature_names\" not in get_preds_param_names:\n",
    "            raise ValueError(f\"`get_preds` function for estimator \\\"{name}\\\" should take a \\\"feature_names\\\" argument\")\n",
    "\n",
    "        self.name = name\n",
    "        self.feature_names = feature_names\n",
    "        self.params_dict = params_dict\n",
    "        self.get_preds = get_preds\n",
    "\n",
    "    def get_hash_value(self):\n",
    "        \"\"\"\n",
    "        Calculates and returns a hash value for the estimator using\n",
    "        `name`, `feature_names` and `params_dict` as inputs.\n",
    "        \"\"\"\n",
    "        feature_names_str = \"_\".join(sorted(self.feature_names))\n",
    "        params_dict_str = \"_\".join(f\"{key}-{value}\" for (key, value) in sorted(self.params_dict.items()))\n",
    "        hash_input_str = \"_\".join([self.name, feature_names_str, params_dict_str])\n",
    "        md5_hash = hl.md5(hash_input_str.encode('utf-8')).hexdigest()\n",
    "        return md5_hash\n",
    "\n",
    "class StackingPredictionsRetriever:\n",
    "    \"\"\"\n",
    "    A class for streamlining stacking (an ensemble learning strategy) that saves predictions\n",
    "    from estimators to file so that when trying out different combinations of (base) estimators,\n",
    "    the predictions that are not stale can be reused, saving the time of having the estimators\n",
    "    make predictions again.\n",
    "\n",
    "    Intended to be used in conjunction with the `StackingEstimator` class. The `hash_value` of\n",
    "    `StackingEstimator` is used to determine the staleness and relevance of the predictions for\n",
    "    an estimator. The implementation for making predictions using an estimator needs to be\n",
    "    provided as a function to `get_preds` for `StackingEstimator`; when predictions need to be\n",
    "    made using an estimator, this class will call `get_preds` for the `StackingEstimator` instance.\n",
    "\n",
    "    Proper usage of this class requires one important condition to be satisfied: the predictions made\n",
    "    using the estimators are determinstic, i.e. they are exactly the same everytime a\n",
    "    `StackingEstimator` instance is run with the same inputs.\n",
    "    \"\"\"\n",
    "    estimators = []\n",
    "    working_dir_path = \"\"\n",
    "    train_preds_filename = \"\"\n",
    "    test_preds_filename = \"\"\n",
    "    preds_save_interval = 0\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators: [StackingEstimator],\n",
    "        working_dir_path: str,\n",
    "        train_preds_filename: str = \"train_preds\",\n",
    "        test_preds_filename: str = \"test_preds\",\n",
    "        preds_save_interval: int = 5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of `StackingPredictionsRetriever`.\n",
    "\n",
    "        :param estimators:\n",
    "            A list of `StackingEstimator` instances for which the class will retrieve predictions.\n",
    "        :param working_dir_path:\n",
    "            The path for the working directory where the files with predictions will be saved.\n",
    "        :param train_preds_filename:\n",
    "            The name of the file in which predictions for the training set will be stored.\n",
    "        :param test_preds_filename:\n",
    "            The name of the file in which predictions for the test set will be stored.\n",
    "        :param preds_save_interval:\n",
    "            An integer which specifies the interval at which predictions will be saved when\n",
    "            `get_preds` is called, corresponding to the number of estimators whose predictions\n",
    "            have been retrieved since the predictions were previously saved. Any estimators\n",
    "            whose predictions are not stale and therefore were not required to make predictions\n",
    "            again are not included in this number.\n",
    "        \"\"\"\n",
    "        # parameter check\n",
    "        if not isinstance(estimators, list):\n",
    "            raise ValueError(\"`estimators` must be passed as a list\")\n",
    "        if not all(isinstance(e, StackingEstimator) for e in estimators):\n",
    "            raise ValueError(\"`estimators` should only contain instances of `StackingEstimator`\")\n",
    "        if not isinstance(working_dir_path, str):\n",
    "            raise ValueError(\"`working_dir_path` argument should be of type `str`\")\n",
    "        if not isinstance(preds_save_interval, int):\n",
    "            raise ValueError(\"`preds_save_interval` argument should be of type `int`\")\n",
    "\n",
    "        self.estimators = estimators\n",
    "        self.working_dir_path = working_dir_path\n",
    "        self.train_preds_filename = train_preds_filename\n",
    "        self.test_preds_filename = test_preds_filename\n",
    "        self.preds_save_interval = preds_save_interval\n",
    "\n",
    "    def get_train_preds_file_path(self):\n",
    "        \"\"\"\n",
    "        Returns the file path for storing predictions for training data.\n",
    "        \"\"\"\n",
    "        return Path(f\"{self.working_dir_path}/{self.train_preds_filename}.csv\")\n",
    "\n",
    "    def get_test_preds_file_path(self):\n",
    "        \"\"\"\n",
    "        Returns the file path for storing predictions for test data.\n",
    "        \"\"\"\n",
    "        return Path(f\"{self.working_dir_path}/{self.test_preds_filename}.csv\")\n",
    "\n",
    "    def get_current_train_and_test_preds(self):\n",
    "        \"\"\"\n",
    "        Returns the current predictions for training and test data (in that order)\n",
    "        as a tuple of two `pandas.DataFrame`.\n",
    "\n",
    "        The predictions are attempted to be retrieved from the file paths returned\n",
    "        by `get_train_preds_file_path` and `get_test_preds_file_path`; if there are\n",
    "        any issues with doing so (e.g. file does not exist, dataframe is empty),\n",
    "        empty dataframes will be returned instead.\n",
    "        In the case an `pandas.errors.EmptyDataError` exception is raised when\n",
    "        reading from a file, the corresponding file will be removed.\n",
    "        \"\"\"\n",
    "        curr_train_preds = pd.DataFrame()\n",
    "        curr_test_preds = pd.DataFrame()\n",
    "        train_preds_file_path = self.get_train_preds_file_path()\n",
    "        test_preds_file_path = self.get_test_preds_file_path()\n",
    "\n",
    "        if train_preds_file_path.is_file():\n",
    "            try:\n",
    "                curr_train_preds = pd.read_csv(train_preds_file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                train_preds_file_path.unlink()\n",
    "        if test_preds_file_path.is_file():\n",
    "            try:\n",
    "                curr_test_preds = pd.read_csv(test_preds_file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                test_preds_file_path.unlink()\n",
    "\n",
    "        return curr_train_preds, curr_test_preds\n",
    "\n",
    "    def get_preds(self):\n",
    "        \"\"\"\n",
    "        Retrieves predictions from all estimators in `estimators`, storing them in\n",
    "        two files at the file paths specified by `working_dir_path`,\n",
    "        `train_preds_filename` and `test_preds_filename`.\n",
    "\n",
    "        If non-stale (relevant) predictions are found for an estimator, retrieval\n",
    "        of predictions by calling `get_preds` on the estimator will be skipped,\n",
    "        and the existing predictions for the estimator will be kept.\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Getting predictions..\")\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "\n",
    "        preds_retrieved_count = 0\n",
    "        num_preds_retrieved_but_not_yet_saved = 0\n",
    "        estimators_skipped = []\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            estimator_hash_value = estimator.get_hash_value()\n",
    "            estimator_name = f\"{estimator.name} ({estimator_hash_value})\"\n",
    "\n",
    "            # skip retrieving predictions for estimator if non-stale predictions are already available\n",
    "            train_preds_available = any(estimator_hash_value in col_name for col_name in curr_train_preds.columns)\n",
    "            test_preds_available = any(estimator_hash_value in col_name for col_name in curr_test_preds.columns)\n",
    "            if train_preds_available and test_preds_available:\n",
    "                estimators_skipped += [estimator_name]\n",
    "                continue\n",
    "\n",
    "            print(f\"[INFO] Getting predictions for estimator {estimator_name}\")\n",
    "            train_preds, test_preds = estimator.get_preds(estimator.params_dict, estimator.feature_names)\n",
    "            if not isinstance(train_preds, pd.core.series.Series):\n",
    "                raise ValueError(\"`train_preds` should be of type `pandas.Series`\")\n",
    "            if not isinstance(test_preds, pd.core.series.Series):\n",
    "                raise ValueError(\"`test_preds` should be of type `pandas.Series`\")\n",
    "            curr_train_preds[estimator_name] = train_preds\n",
    "            curr_test_preds[estimator_name] = test_preds\n",
    "            preds_retrieved_count += 1\n",
    "\n",
    "            # save predictions at an interval of `preds_save_interval`\n",
    "            if preds_retrieved_count % self.preds_save_interval == 0:\n",
    "                curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "                curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "                num_preds_retrieved_but_not_yet_saved = 0\n",
    "                print(\"[INFO] Saved predictions\")\n",
    "            else:\n",
    "                num_preds_retrieved_but_not_yet_saved += 1\n",
    "\n",
    "        if estimators_skipped:\n",
    "            estimators_skipped.sort()\n",
    "            formatted_estimators = \", \".join(estimators_skipped)\n",
    "            print(f\"[INFO] Skipped retrieving predictions for following estimators as their current ones are not stale:\\n{formatted_estimators}\")\n",
    "\n",
    "        if num_preds_retrieved_but_not_yet_saved != 0:\n",
    "            curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            print(\"[INFO] Saved predictions\")\n",
    "\n",
    "        print(\"[INFO] Finished getting all predictions\")\n",
    "\n",
    "    def sync_preds(self):\n",
    "        \"\"\"\n",
    "        Syncs the predictions stored at the two file paths specified by\n",
    "        `working_dir_path`, `train_preds_filename` and `test_preds_filename` by\n",
    "        removing predictions for any estimator that is not currently in `estimators`.\n",
    "\n",
    "        Note that new predictions for estimators that do not currently have predictions\n",
    "        in the files will not be added; `get_preds` should be used for this purpose\n",
    "        instead.\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Syncing predictions..\")\n",
    "        estimator_hash_values = [estimator.get_hash_value() for estimator in self.estimators]\n",
    "        should_remove_col = lambda col_name: not any(hash_value in col_name for hash_value in estimator_hash_values)\n",
    "\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "\n",
    "        if not curr_train_preds.empty:\n",
    "            col_names_to_remove = [col_name for col_name in curr_train_preds.columns if should_remove_col(col_name)]\n",
    "            if col_names_to_remove:\n",
    "                print(f\"[INFO] Dropping columns for following estimators from training predictions:\\n{col_names_to_remove}\")\n",
    "                curr_train_preds.drop(columns=col_names_to_remove, inplace=True)\n",
    "                curr_train_preds.to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            else:\n",
    "                print(f\"[INFO] No columns for training predictions were dropped\")\n",
    "        if not curr_test_preds.empty:\n",
    "            col_names_to_remove = [col_name for col_name in curr_test_preds.columns if should_remove_col(col_name)]\n",
    "            if col_names_to_remove:\n",
    "                print(f\"[INFO] Dropping columns for following estimators from test predictions:\\n{col_names_to_remove}\")\n",
    "                curr_test_preds.drop(columns=col_names_to_remove, inplace=True)\n",
    "                curr_test_preds.to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            else:\n",
    "                print(f\"[INFO] No columns for test predictions were dropped\")\n",
    "\n",
    "        print(\"[INFO] Finished syncing predictions\")\n",
    "\n",
    "    def import_preds(self, input_dir_path):\n",
    "        \"\"\"\n",
    "        Imports predictions stored at the two file paths at `input_dir_path` with\n",
    "        `train_preds_filename` and `test_preds_filename` as their filenames. If no\n",
    "        such files are found, no predictions will be imported.\n",
    "\n",
    "        Only predictions for estimators specified in `estimators` will be imported.\n",
    "        Any predictions for estimators that were already available will be overwritten\n",
    "        with predictions for the same estimators found in the files at `input_dir_path`.\n",
    "\n",
    "        :param input_dir_path:\n",
    "            The path to the directory for the training and test predictions files.\n",
    "            The file names are expected to be the same as `train_preds_filename`\n",
    "            and `test_preds_filename`\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Importing predictions..\")\n",
    "        curr_train_preds, curr_test_preds = self.get_current_train_and_test_preds()\n",
    "        input_train_preds = pd.DataFrame()\n",
    "        input_test_preds = pd.DataFrame()\n",
    "\n",
    "        input_train_preds_path = Path(f\"{input_dir_path}/{self.train_preds_filename}.csv\")\n",
    "        input_test_preds_path = Path(f\"{input_dir_path}/{self.test_preds_filename}.csv\")\n",
    "        if input_train_preds_path.is_file():\n",
    "            try:\n",
    "                input_train_preds = pd.read_csv(input_train_preds_path)\n",
    "            except: pass\n",
    "        if input_test_preds_path.is_file():\n",
    "            try:\n",
    "                input_test_preds = pd.read_csv(input_test_preds_path)\n",
    "            except: pass\n",
    "\n",
    "        estimators_with_imported_train_preds = []\n",
    "        estimators_with_imported_test_preds = []\n",
    "        for estimator in self.estimators:\n",
    "            estimator_hash_value = estimator.get_hash_value()\n",
    "            estimator_name = f\"{estimator.name} ({estimator_hash_value})\"\n",
    "            train_preds_available = any(estimator_hash_value in col_name for col_name in input_train_preds.columns)\n",
    "            test_preds_available = any(estimator_hash_value in col_name for col_name in input_test_preds.columns)\n",
    "\n",
    "            if train_preds_available:\n",
    "                curr_train_preds[estimator_name] = input_train_preds[estimator_name]\n",
    "                estimators_with_imported_train_preds += [estimator_name]\n",
    "            if test_preds_available:\n",
    "                curr_test_preds[estimator_name] = input_test_preds[estimator_name]\n",
    "                estimators_with_imported_test_preds += [estimator_name]\n",
    "\n",
    "        if not estimators_with_imported_train_preds:\n",
    "            print(\"[INFO] No train predictions were imported\")\n",
    "        else:\n",
    "            curr_train_preds.sort_index(axis=1).to_csv(self.get_train_preds_file_path(), index=False)\n",
    "            formatted_estimators = \", \".join(estimators_with_imported_train_preds)\n",
    "            print(f\"[INFO] {len(estimators_with_imported_train_preds)} train predictions were imported:\\n{formatted_estimators}\")\n",
    "        if not estimators_with_imported_test_preds:\n",
    "            print(\"[INFO] No test predictions were imported\")\n",
    "        else:\n",
    "            curr_test_preds.sort_index(axis=1).to_csv(self.get_test_preds_file_path(), index=False)\n",
    "            formatted_estimators = \", \".join(estimators_with_imported_test_preds)\n",
    "            print(f\"[INFO] {len(estimators_with_imported_test_preds)} test predictions were imported:\\n{formatted_estimators}\")\n",
    "        \n",
    "        print(\"[INFO] Finished importing predictions\")\n",
    "\n",
    "    def clear_preds(self):\n",
    "        \"\"\"\n",
    "        Removes all stored predictions by deleting the two files at filepaths specified\n",
    "        by `working_dir_path`, `train_preds_filename` and `test_preds_filename`.\n",
    "        \"\"\"\n",
    "        train_preds_file_path = self.get_train_preds_file_path()\n",
    "        test_preds_file_path = self.get_test_preds_file_path()\n",
    "\n",
    "        if train_preds_file_path.is_file():\n",
    "            train_preds_file_path.unlink()\n",
    "        if test_preds_file_path.is_file():\n",
    "            test_preds_file_path.unlink()\n",
    "\n",
    "        print(\"[INFO] Finished clearing predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd72cfe",
   "metadata": {
    "papermill": {
     "duration": 0.01821,
     "end_time": "2025-12-31T04:24:00.396558",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.378348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we'll simply create a variable for storing the estimators (`StackingEstimator` instances) that we'll pass to the `StackingPredictionsRetriever` class for getting all the predictions from our base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7b37498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.433209Z",
     "iopub.status.busy": "2025-12-31T04:24:00.432828Z",
     "iopub.status.idle": "2025-12-31T04:24:00.439464Z",
     "shell.execute_reply": "2025-12-31T04:24:00.438125Z"
    },
    "papermill": {
     "duration": 0.028758,
     "end_time": "2025-12-31T04:24:00.442387",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.413629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495ed0a",
   "metadata": {
    "papermill": {
     "duration": 0.015583,
     "end_time": "2025-12-31T04:24:00.478183",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.462600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c9cf3d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.511336Z",
     "iopub.status.busy": "2025-12-31T04:24:00.510905Z",
     "iopub.status.idle": "2025-12-31T04:24:00.523269Z",
     "shell.execute_reply": "2025-12-31T04:24:00.521676Z"
    },
    "papermill": {
     "duration": 0.032574,
     "end_time": "2025-12-31T04:24:00.525452",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.492878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base feature set\n",
    "FEATURE_SET_1 = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day',\n",
    "    'bmi', 'waist_to_hip_ratio', 'systolic_bp',\n",
    "    'diastolic_bp', 'heart_rate', 'cholesterol_total',\n",
    "    'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides',\n",
    "    'gender', 'ethnicity', 'employment_status',\n",
    "    'family_history_diabetes', 'hypertension_history', 'cardiovascular_history',\n",
    "    'education_level_encoded', 'income_level_encoded', 'smoking_status_encoded',\n",
    "    'log_triglycerides', 'log_ldl_cholesterol', 'log_cholesterol_total',\n",
    "    'cholesterol_ratio', 'ldl_hdl_ratio', 'pulse_pressure',\n",
    "    'mean_arterial_pressure', 'age_x_bmi', 'waist_x_bmi',\n",
    "    'family_history_diabetes_x_log_triglycerides', 'hypertension_history_x_systolic_bp', 'activity_x_diet',\n",
    "    'age_sq', 'bmi_sq', 'waist_to_hip_ratio_sq',\n",
    "    'systolic_bp_sq', 'comorbidity_count', 'bmi_cat',\n",
    "    'cluster_label',\n",
    "]\n",
    "\n",
    "# FEATURE_SET_2 = FEATURE_SET_1 + proxies + binned/relative features + clusters\n",
    "FEATURE_SET_2 = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day',\n",
    "    'bmi', 'waist_to_hip_ratio', 'systolic_bp',\n",
    "    'diastolic_bp', 'heart_rate', 'cholesterol_total',\n",
    "    'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides',\n",
    "    'gender', 'ethnicity', 'employment_status',\n",
    "    'family_history_diabetes', 'hypertension_history', 'cardiovascular_history',\n",
    "    'education_level_encoded', 'income_level_encoded', 'smoking_status_encoded',\n",
    "    'log_triglycerides', 'log_ldl_cholesterol', 'log_cholesterol_total',\n",
    "    'cholesterol_ratio', 'ldl_hdl_ratio', 'pulse_pressure',\n",
    "    'mean_arterial_pressure', 'age_x_bmi', 'waist_x_bmi',\n",
    "    'family_history_diabetes_x_log_triglycerides', 'hypertension_history_x_systolic_bp', 'activity_x_diet',\n",
    "    'atherogenic_index', 'non_hdl_cholesterol', 'map_x_bmi',\n",
    "    'lipid_accumulation_proxy', 'visceral_adiposity_proxy', 'age_sq',\n",
    "    'bmi_sq', 'waist_to_hip_ratio_sq', 'systolic_bp_sq',\n",
    "    'comorbidity_count', 'bmi_cat', 'bmi_relative_to_age_decade',\n",
    "    'systolic_bp_relative_to_age_decade', 'cholesterol_total_relative_to_age_decade', 'bmi_relative_to_hypertension_history',\n",
    "    'systolic_bp_relative_to_hypertension_history', 'cholesterol_total_relative_to_hypertension_history', 'cluster_label',\n",
    "    'dist_to_cluster_0', 'dist_to_cluster_1', 'dist_to_cluster_2',\n",
    "    'dist_to_cluster_3', 'dist_to_cluster_4', 'dist_to_cluster_5',\n",
    "    'dist_to_cluster_6',\n",
    "]\n",
    "\n",
    "# FEATURE_SET_3 = FEATURE_SET_2 + additional binned features\n",
    "FEATURE_SET_3 = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day',\n",
    "    'bmi', 'waist_to_hip_ratio', 'systolic_bp',\n",
    "    'diastolic_bp', 'heart_rate', 'cholesterol_total',\n",
    "    'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides',\n",
    "    'gender', 'ethnicity', 'employment_status',\n",
    "    'family_history_diabetes', 'hypertension_history', 'cardiovascular_history',\n",
    "    'education_level_encoded', 'income_level_encoded', 'smoking_status_encoded',\n",
    "    'log_triglycerides', 'log_ldl_cholesterol', 'log_cholesterol_total',\n",
    "    'cholesterol_ratio', 'ldl_hdl_ratio', 'pulse_pressure',\n",
    "    'mean_arterial_pressure', 'age_x_bmi', 'waist_x_bmi',\n",
    "    'family_history_diabetes_x_log_triglycerides', 'hypertension_history_x_systolic_bp', 'activity_x_diet',\n",
    "    'atherogenic_index', 'non_hdl_cholesterol', 'map_x_bmi',\n",
    "    'lipid_accumulation_proxy', 'visceral_adiposity_proxy', 'age_sq',\n",
    "    'bmi_sq', 'waist_to_hip_ratio_sq', 'systolic_bp_sq',\n",
    "    'comorbidity_count', 'bmi_cat', 'bp_cat',\n",
    "    'cholesterol_cat', 'hdl_cat', 'ldl_cat',\n",
    "    'triglycerides_decile', 'waist_to_hip_ratio_decile', 'bmi_decile',\n",
    "    'mean_arterial_pressure_decile', 'age_decade', 'bmi_relative_to_age_decade',\n",
    "    'systolic_bp_relative_to_age_decade', 'cholesterol_total_relative_to_age_decade', 'bmi_relative_to_hypertension_history',\n",
    "    'systolic_bp_relative_to_hypertension_history', 'cholesterol_total_relative_to_hypertension_history', 'age_bp_interaction',\n",
    "    'cluster_label', 'dist_to_cluster_0', 'dist_to_cluster_1',\n",
    "    'dist_to_cluster_2', 'dist_to_cluster_3', 'dist_to_cluster_4',\n",
    "    'dist_to_cluster_5', 'dist_to_cluster_6',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc5e5f",
   "metadata": {
    "papermill": {
     "duration": 0.015772,
     "end_time": "2025-12-31T04:24:00.557188",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.541416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Base Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44bb744a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.592776Z",
     "iopub.status.busy": "2025-12-31T04:24:00.592460Z",
     "iopub.status.idle": "2025-12-31T04:24:00.598195Z",
     "shell.execute_reply": "2025-12-31T04:24:00.596603Z"
    },
    "papermill": {
     "duration": 0.026688,
     "end_time": "2025-12-31T04:24:00.600646",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.573958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip hyperparameter tuning when it's not needed; set to `False` to do the tuning\n",
    "SKIP_BASE_MODEL_HYPERPARAMETER_TUNING = True\n",
    "\n",
    "# value set for early stopping for base models that support it; this value will be used for actual model training as well\n",
    "BASE_MODEL_EARLY_STOPPING_ROUNDS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3458fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.639696Z",
     "iopub.status.busy": "2025-12-31T04:24:00.639280Z",
     "iopub.status.idle": "2025-12-31T04:24:00.646659Z",
     "shell.execute_reply": "2025-12-31T04:24:00.645434Z"
    },
    "papermill": {
     "duration": 0.032888,
     "end_time": "2025-12-31T04:24:00.648871",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.615983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseModelOptunaStudyEstimator(Enum):\n",
    "    CATBOOSTCLASSIFIER = \"CatBoostClassifier\"\n",
    "    LGBMCLASSIFIER = \"LGBMClassifier\"\n",
    "    XGBCLASSIFIER = \"XGBClassifier\"\n",
    "    XGBCLASSIFIER_DART = \"XGBClassifier_DART\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2442c09",
   "metadata": {
    "papermill": {
     "duration": 0.033759,
     "end_time": "2025-12-31T04:24:00.702548",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.668789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Manually configure the values for the following variables for different studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "323ceb44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.750544Z",
     "iopub.status.busy": "2025-12-31T04:24:00.750145Z",
     "iopub.status.idle": "2025-12-31T04:24:00.756514Z",
     "shell.execute_reply": "2025-12-31T04:24:00.754985Z"
    },
    "papermill": {
     "duration": 0.031748,
     "end_time": "2025-12-31T04:24:00.759125",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.727377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# estimator to use for Optuna study\n",
    "BASE_MODEL_OPTUNA_STUDY_ESTIMATOR = BaseModelOptunaStudyEstimator.CATBOOSTCLASSIFIER\n",
    "\n",
    "# feature set to use for Optuna study\n",
    "BASE_MODEL_OPTUNA_STUDY_FEATURE_SET = FEATURE_SET_3\n",
    "\n",
    "# maximum number of trials Optuna will conduct for the optimization\n",
    "BASE_MODEL_OPTUNA_STUDY_NUM_TRIALS = 100\n",
    "\n",
    "# number of splits to use for Stratified K-Fold Cross-Validation for Optuna study\n",
    "BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00adcb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.795620Z",
     "iopub.status.busy": "2025-12-31T04:24:00.795273Z",
     "iopub.status.idle": "2025-12-31T04:24:00.838232Z",
     "shell.execute_reply": "2025-12-31T04:24:00.836808Z"
    },
    "papermill": {
     "duration": 0.064249,
     "end_time": "2025-12-31T04:24:00.840366",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.776117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_base_model_optuna_params(trial, study_estimator):\n",
    "    if study_estimator == BaseModelOptunaStudyEstimator.CATBOOSTCLASSIFIER:\n",
    "        if BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_1:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.015, 0.04),\n",
    "                'depth': trial.suggest_int('depth', 5, 7),\n",
    "                'border_count': trial.suggest_int('border_count', 200, 254),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3.0, 50.0, log=True),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 0.5),\n",
    "                'random_strength': trial.suggest_float('random_strength', 5.0, 20.0),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 100),\n",
    "            }\n",
    "        elif BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_2:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.10),\n",
    "                'depth': trial.suggest_int('depth', 5, 8),\n",
    "                'border_count': trial.suggest_int('border_count', 128, 254),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 10.0, 100.0, log=True),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "                'random_strength': trial.suggest_float('random_strength', 1.0, 10.0, log=True),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 100),\n",
    "            }\n",
    "        elif BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_3:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.20),\n",
    "                'depth': trial.suggest_int('depth', 3, 16),\n",
    "                'border_count': trial.suggest_int('border_count', 32, 254),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 150.0, log=True),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "                'random_strength': trial.suggest_float('random_strength', 1.0, 10.0, log=True),\n",
    "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 200),\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Search space for feature set for Optuna study not yet specified for CatBoostClassifier.\")\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.LGBMCLASSIFIER:\n",
    "        if BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_1:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.03),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 35),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 350, 550),\n",
    "                'min_split_gain': trial.suggest_float('min_split_gain', 0.001, 0.1, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.25, 0.45),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 50.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 50.0, log=True),\n",
    "            }\n",
    "        elif BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_2:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.015, 0.045),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 30, 45),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 300, 500),\n",
    "                'min_split_gain': trial.suggest_float('min_split_gain', 1e-4, 0.2, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.35, 0.55),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 20.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 20.0, 100.0, log=True),\n",
    "            }\n",
    "        elif BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_3:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.04),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 15, 30),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 100, 300),\n",
    "                'min_split_gain': trial.suggest_float('min_split_gain', 1e-4, 0.1, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 0.95),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.40, 0.65),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 50.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 50.0, log=True),\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Search space for feature set for Optuna study not yet specified for LGBMClassifier.\")\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER:\n",
    "        if BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_1:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.008, 0.05),\n",
    "                'max_depth': trial.suggest_int('max_depth', 2, 5),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 1.0),\n",
    "                'alpha': trial.suggest_float('alpha', 0.1, 10.0, log=True),\n",
    "                'gamma': trial.suggest_float('gamma', 1.0, 3.0),\n",
    "                'lambda': trial.suggest_float('lambda', 0.1, 10.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 50, 200),\n",
    "            }\n",
    "        elif BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_2:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.008),\n",
    "                'max_depth': trial.suggest_int('max_depth', 8, 11),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.25),\n",
    "                'alpha': trial.suggest_float('alpha', 0.1, 10.0, log=True),\n",
    "                'gamma': trial.suggest_float('gamma', 1.0, 5.0),\n",
    "                'lambda': trial.suggest_float('lambda', 1.0, 10.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 40, 100),\n",
    "            }\n",
    "        elif BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_3:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.08),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 5),\n",
    "                'subsample': trial.suggest_float('subsample', 0.75, 0.95),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.10, 0.25),\n",
    "                'alpha': trial.suggest_float('alpha', 0.1, 5.0, log=True),\n",
    "                'gamma': trial.suggest_float('gamma', 0.1, 1.0),\n",
    "                'lambda': trial.suggest_float('lambda', 1.0, 10.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 5, 25),\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Search space for feature set for Optuna study not yet specified for XGBClassifier.\")\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER_DART:\n",
    "        if BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_1:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.015, 0.035),\n",
    "                'max_depth': trial.suggest_int('max_depth', 7, 9),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.5),\n",
    "                'alpha': trial.suggest_float('alpha', 0.01, 2.0, log=True),\n",
    "                'gamma': trial.suggest_float('gamma', 1.0, 3.0),\n",
    "                'lambda': trial.suggest_float('lambda', 0.1, 5.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 30, 70),\n",
    "                'rate_drop': trial.suggest_float('rate_drop', 0.05, 0.15),\n",
    "                'skip_drop': trial.suggest_float('skip_drop', 0.3, 0.6),\n",
    "                'one_drop': trial.suggest_categorical('one_drop', [0, 1]),\n",
    "            }\n",
    "        elif BASE_MODEL_OPTUNA_STUDY_FEATURE_SET == FEATURE_SET_2:\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.015, 0.035),\n",
    "                'max_depth': trial.suggest_int('max_depth', 7, 9),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.5),\n",
    "                'alpha': trial.suggest_float('alpha', 0.01, 2.0, log=True),\n",
    "                'gamma': trial.suggest_float('gamma', 1.0, 3.0),\n",
    "                'lambda': trial.suggest_float('lambda', 0.1, 5.0, log=True),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 30, 70),\n",
    "                'rate_drop': trial.suggest_float('rate_drop', 0.05, 0.15),\n",
    "                'skip_drop': trial.suggest_float('skip_drop', 0.3, 0.6),\n",
    "                'one_drop': trial.suggest_categorical('one_drop', [0, 1]),\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Search space for feature set for Optuna study not yet specified for XGBClassifier (DART).\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optuna study estimator\")\n",
    "\n",
    "def get_base_model_predictions(study_estimator, trial_params, X_train_fold, y_train_fold, X_validation_fold, y_validation_fold):\n",
    "    if study_estimator == BaseModelOptunaStudyEstimator.CATBOOSTCLASSIFIER:\n",
    "        model = CatBoostClassifier(\n",
    "            **trial_params,\n",
    "            iterations=30000,\n",
    "            use_best_model=True,\n",
    "            cat_features=cat_features,\n",
    "            loss_function='Logloss',\n",
    "            eval_metric='AUC',\n",
    "            task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
    "            devices='0',\n",
    "            metric_period=5,\n",
    "            random_seed=RANDOM_SEEDS[0],\n",
    "            verbose=False,\n",
    "            allow_writing_files=False\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_validation_fold, y_validation_fold),\n",
    "            early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.LGBMCLASSIFIER:\n",
    "        model = lgb.LGBMClassifier(\n",
    "            **trial_params,\n",
    "            n_estimators=30000,\n",
    "            objective='binary',\n",
    "            metric='auc',\n",
    "            verbose=-1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_validation_fold, y_validation_fold),\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS, verbose=0)]\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER:\n",
    "        model = XGBClassifier(\n",
    "            **trial_params,\n",
    "            n_estimators=30000,\n",
    "            tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            enable_categorical=True,\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='auc',\n",
    "            early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_SEEDS[0],\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "            verbose=False\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    elif study_estimator == BaseModelOptunaStudyEstimator.XGBCLASSIFIER_DART:\n",
    "        model = XGBClassifier(\n",
    "            **trial_params,\n",
    "            n_estimators=2500,\n",
    "            booster='dart',\n",
    "            tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            enable_categorical=True,\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='auc',\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_SEEDS[0],\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "            verbose=False\n",
    "        )\n",
    "        return model.predict_proba(X_validation_fold)[:, 1]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optuna study estimator\")\n",
    "\n",
    "def base_model_optuna_study_objective(trial):\n",
    "    base_model_params = get_base_model_optuna_params(trial, BASE_MODEL_OPTUNA_STUDY_ESTIMATOR)\n",
    "\n",
    "    X_train = train_data[BASE_MODEL_OPTUNA_STUDY_FEATURE_SET]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    base_model_optuna_study_skf = StratifiedKFold(n_splits=BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS, shuffle=True, random_state=RANDOM_SEEDS[0])\n",
    "    base_model_optuna_study_skf_splits = base_model_optuna_study_skf.split(X_train, y_train)\n",
    "    base_model_optuna_study_skf_enumeration = enumerate(base_model_optuna_study_skf_splits)\n",
    "\n",
    "    total_roc_auc = 0\n",
    "\n",
    "    for fold, (train_indices, validation_indices) in base_model_optuna_study_skf_enumeration:\n",
    "        X_train_fold = X_train.iloc[train_indices]\n",
    "        X_validation_fold = X_train.iloc[validation_indices]\n",
    "        y_train_fold = y_train.iloc[train_indices]\n",
    "        y_validation_fold = y_train.iloc[validation_indices]\n",
    "\n",
    "        y_validation_pred_proba = get_base_model_predictions(\n",
    "            BASE_MODEL_OPTUNA_STUDY_ESTIMATOR,\n",
    "            base_model_params,\n",
    "            X_train_fold, y_train_fold,\n",
    "            X_validation_fold, y_validation_fold\n",
    "        )\n",
    "        roc_auc_fold = roc_auc_score(y_validation_fold, y_validation_pred_proba)\n",
    "        total_roc_auc += roc_auc_fold\n",
    "\n",
    "        trial.report(roc_auc_fold, step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    average_roc_auc = total_roc_auc / BASE_MODEL_OPTUNA_STUDY_KFOLD_NUM_SPLITS\n",
    "    return average_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b977e242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.874412Z",
     "iopub.status.busy": "2025-12-31T04:24:00.873972Z",
     "iopub.status.idle": "2025-12-31T04:24:00.882863Z",
     "shell.execute_reply": "2025-12-31T04:24:00.881017Z"
    },
    "papermill": {
     "duration": 0.029433,
     "end_time": "2025-12-31T04:24:00.884860",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.855427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped base model hyperparameter tuning\n"
     ]
    }
   ],
   "source": [
    "if SKIP_BASE_MODEL_HYPERPARAMETER_TUNING:\n",
    "    print(\"Skipped base model hyperparameter tuning\")\n",
    "else:\n",
    "    print(f\"Started base model hyperparameter tuning for {BASE_MODEL_OPTUNA_STUDY_ESTIMATOR.value}\")\n",
    "    sampler = optuna.samplers.TPESampler(n_ei_candidates=48, multivariate=True)\n",
    "    study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "    study.optimize(base_model_optuna_study_objective, n_trials=BASE_MODEL_OPTUNA_STUDY_NUM_TRIALS)\n",
    "    \n",
    "    print(f\"# trials finished: {len(study.trials)}\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"Best trial AUC: {trial.value}\")\n",
    "    print(f\"Best trial params:\")\n",
    "    for param_key, param_value in trial.params.items():\n",
    "        print(f\"- {param_key}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb8e397",
   "metadata": {
    "papermill": {
     "duration": 0.015928,
     "end_time": "2025-12-31T04:24:00.916780",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.900852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Base Model Candidates\n",
    "\n",
    "The base models that are candidates for the ensemble are specified. Instead of only relying on the meta-model to filter out unhelpful base model predictions, Optuna studies will also be conducted to find the feature set (set of base model predictions) that should be used for the meta-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "439d87be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:00.951438Z",
     "iopub.status.busy": "2025-12-31T04:24:00.950815Z",
     "iopub.status.idle": "2025-12-31T04:24:00.955476Z",
     "shell.execute_reply": "2025-12-31T04:24:00.954342Z"
    },
    "papermill": {
     "duration": 0.023683,
     "end_time": "2025-12-31T04:24:00.957044",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.933361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of splits to use for Stratified K-Fold Cross-Validation for base models\n",
    "BASE_MODEL_KFOLD_NUM_SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92963e31",
   "metadata": {
    "papermill": {
     "duration": 0.015575,
     "end_time": "2025-12-31T04:24:00.988832",
     "exception": false,
     "start_time": "2025-12-31T04:24:00.973257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.1 CatBoostClassifier\n",
    "\n",
    "### 8.1.1 Helper Methods (CatBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "334b323f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.024360Z",
     "iopub.status.busy": "2025-12-31T04:24:01.023985Z",
     "iopub.status.idle": "2025-12-31T04:24:01.036461Z",
     "shell.execute_reply": "2025-12-31T04:24:01.035163Z"
    },
    "papermill": {
     "duration": 0.032846,
     "end_time": "2025-12-31T04:24:01.038552",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.005706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_catboostclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds_accumulator = np.zeros(len(train_data))\n",
    "    test_preds_accumulator = np.zeros(len(test_data))\n",
    "\n",
    "    X_train = train_data[feature_names]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(train_data[feature_names], train_data[target_col])\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "\n",
    "        seed_oof_preds = np.zeros(len(train_data))\n",
    "    \n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = X_train.iloc[train_indices]\n",
    "            X_validation_fold = X_train.iloc[validation_indices]\n",
    "            y_train_fold = y_train.iloc[train_indices]\n",
    "            y_validation_fold = y_train.iloc[validation_indices]\n",
    "        \n",
    "            model = CatBoostClassifier(\n",
    "                **params_dict,\n",
    "                use_best_model=True,\n",
    "                cat_features=cat_features,\n",
    "                loss_function='Logloss',\n",
    "                eval_metric='AUC',\n",
    "                task_type='GPU' if torch.cuda.is_available() else 'CPU',\n",
    "                devices='0',\n",
    "                metric_period=5,\n",
    "                random_seed=random_seed,\n",
    "                verbose=False,\n",
    "                allow_writing_files=False\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=(X_validation_fold, y_validation_fold),\n",
    "                early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS\n",
    "            )\n",
    "\n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            y_test_pred_proba = model.predict_proba(test_data[feature_names])[:, 1]\n",
    "            seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "            test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "\n",
    "        oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "    final_oof_preds = oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "    final_test_preds = test_preds_accumulator / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(final_oof_preds), pd.Series(final_test_preds)\n",
    "\n",
    "def get_catboostclassifier_stacking_estimator(index, params_dict, feature_names):\n",
    "    return StackingEstimator(\n",
    "        name=f\"CatBoostClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=feature_names,\n",
    "        get_preds=get_catboostclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e285d5",
   "metadata": {
    "papermill": {
     "duration": 0.017116,
     "end_time": "2025-12-31T04:24:01.072592",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.055476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.1.2 Add Estimators (CatBoostClassifier)\n",
    "\n",
    "Add CatBoostClassifier estimators to list that StackingPredictionsRetriever will process. Hyperparameters were found using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "073fdffa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.116031Z",
     "iopub.status.busy": "2025-12-31T04:24:01.115623Z",
     "iopub.status.idle": "2025-12-31T04:24:01.136169Z",
     "shell.execute_reply": "2025-12-31T04:24:01.134839Z"
    },
    "papermill": {
     "duration": 0.045301,
     "end_time": "2025-12-31T04:24:01.137914",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.092613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier base models using FEATURE_SET_1\n",
    "estimators += [\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=1,\n",
    "        params_dict={ # Optuna study AUC: 0.7261767336235222\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.03933473509871599,\n",
    "            'depth': 3,\n",
    "            'l2_leaf_reg': 14.932109771039046,\n",
    "            'bagging_temperature': 0.13345806085697987,\n",
    "            'random_strength': 7.486374538597635,\n",
    "            'min_data_in_leaf': 2,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=2,\n",
    "    #     params_dict={ # Optuna study AUC: 0.725842155230371\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.041779205681346576,\n",
    "    #         'depth': 4,\n",
    "    #         'l2_leaf_reg': 3.628892496718331,\n",
    "    #         'bagging_temperature': 0.1922242909320177,\n",
    "    #         'random_strength': 8.464699585881778,\n",
    "    #         'min_data_in_leaf': 5,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=3,\n",
    "        params_dict={ # Optuna study AUC: 0.7257614687804782\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.08955773312600926,\n",
    "            'depth': 4,\n",
    "            'l2_leaf_reg': 8.952470035979275,\n",
    "            'bagging_temperature': 0.21150772067613666,\n",
    "            'random_strength': 14.741499198080962,\n",
    "            'min_data_in_leaf': 1,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=4,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7268829540444225\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.020565190920085484,\n",
    "    #         'depth': 5,\n",
    "    #         'border_count': 244,\n",
    "    #         'l2_leaf_reg': 5.425795328172981,\n",
    "    #         'bagging_temperature': 0.40465921452779574,\n",
    "    #         'random_strength': 16.633797525335456,\n",
    "    #         'min_data_in_leaf': 81,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=5,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7270256119357182\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.018463696564527392,\n",
    "    #         'depth': 5,\n",
    "    #         'border_count': 227,\n",
    "    #         'l2_leaf_reg': 38.86122949114052,\n",
    "    #         'bagging_temperature': 0.3006204146898439,\n",
    "    #         'random_strength': 15.551270889153717,\n",
    "    #         'min_data_in_leaf': 74,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "]\n",
    "\n",
    "# CatBoostClassifier base models using FEATURE_SET_2\n",
    "estimators += [\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=100,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7262278647675813\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.009903259488412045,\n",
    "    #         'depth': 5,\n",
    "    #         'border_count': 229,\n",
    "    #         'l2_leaf_reg': 27.552992645787203,\n",
    "    #         'bagging_temperature': 0.29260010262333336,\n",
    "    #         'random_strength': 6.378831014965193,\n",
    "    #         'min_data_in_leaf': 79,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=101,\n",
    "        params_dict={ # Optuna study AUC: 0.7261694357436603\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.027995785656753255,\n",
    "            'depth': 5,\n",
    "            'border_count': 227,\n",
    "            'l2_leaf_reg': 37.089033893184045,\n",
    "            'bagging_temperature': 0.14510428700751374,\n",
    "            'random_strength': 16.707054253585802,\n",
    "            'min_data_in_leaf': 74,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=102,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7261505685174567\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.0144075596799417,\n",
    "    #         'depth': 5,\n",
    "    #         'border_count': 246,\n",
    "    #         'l2_leaf_reg': 12.579095618077156,\n",
    "    #         'bagging_temperature': 0.29812637308837886,\n",
    "    #         'random_strength': 17.813848681334914,\n",
    "    #         'min_data_in_leaf': 98,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=103,\n",
    "    #     params_dict={ # Optuna study AUC: 0.726110986436845\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.018075722182856198,\n",
    "    #         'depth': 4,\n",
    "    #         'border_count': 238,\n",
    "    #         'l2_leaf_reg': 3.703935032484741,\n",
    "    #         'bagging_temperature': 0.4113827574385829,\n",
    "    #         'random_strength': 45.932408424577005,\n",
    "    #         'min_data_in_leaf': 33,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=104,\n",
    "        params_dict={ # Optuna study AUC: 0.7262024541725216\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.06682939989294684,\n",
    "            'depth': 5,\n",
    "            'border_count': 247,\n",
    "            'l2_leaf_reg': 87.98761404785203,\n",
    "            'bagging_temperature': 0.18097158882519226,\n",
    "            'random_strength': 2.1764370649792166,\n",
    "            'min_data_in_leaf': 96,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=105,\n",
    "        params_dict={ # Optuna study AUC: 0.7261804551734349\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.041371759542327295,\n",
    "            'depth': 5,\n",
    "            'border_count': 233,\n",
    "            'l2_leaf_reg': 79.72030402752588,\n",
    "            'bagging_temperature': 0.1745366308337077,\n",
    "            'random_strength': 3.247152923456543,\n",
    "            'min_data_in_leaf': 91,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "]\n",
    "\n",
    "# CatBoostClassifier base models using FEATURE_SET_3\n",
    "estimators += [\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=200,\n",
    "        params_dict={ # Optuna study AUC: 0.7261085382272944\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.033098694832699,\n",
    "            'depth': 5,\n",
    "            'border_count': 252,\n",
    "            'l2_leaf_reg': 75.49841384168623,\n",
    "            'bagging_temperature': 0.3157931590124562,\n",
    "            'random_strength': 0.3883253343704605,\n",
    "            'min_data_in_leaf': 27,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=201,\n",
    "    #     params_dict={ # Optuna study AUC: 0.726058121823289\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.030129689158590805,\n",
    "    #         'depth': 6,\n",
    "    #         'border_count': 249,\n",
    "    #         'l2_leaf_reg': 68.34193455262071,\n",
    "    #         'bagging_temperature': 0.04614353821535644,\n",
    "    #         'random_strength': 0.1091487165354567,\n",
    "    #         'min_data_in_leaf': 66,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=202,\n",
    "        params_dict={ # Optuna study AUC: 0.7263177506115929\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.13239545573836314,\n",
    "            'depth': 3,\n",
    "            'border_count': 204,\n",
    "            'l2_leaf_reg': 139.14047722098894,\n",
    "            'bagging_temperature': 0.16284158872170643,\n",
    "            'random_strength': 2.9876361959550803,\n",
    "            'min_data_in_leaf': 26,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=203,\n",
    "        params_dict={ # Optuna study AUC: 0.7262124228299923\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.14321977040789668,\n",
    "            'depth': 3,\n",
    "            'border_count': 206,\n",
    "            'l2_leaf_reg': 148.36720184486228,\n",
    "            'bagging_temperature': 0.20006682099634276,\n",
    "            'random_strength': 3.851450877580644,\n",
    "            'min_data_in_leaf': 28,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=204,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7263178538203411\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.046767485493212024,\n",
    "    #         'depth': 3,\n",
    "    #         'border_count': 244,\n",
    "    #         'l2_leaf_reg': 33.89635456878698,\n",
    "    #         'bagging_temperature': 0.30387606432928704,\n",
    "    #         'random_strength': 8.669275355108477,\n",
    "    #         'min_data_in_leaf': 195,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "    # get_catboostclassifier_stacking_estimator(\n",
    "    #     index=205,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7263132156054604\n",
    "    #         'iterations': 30000,\n",
    "    #         'learning_rate': 0.04318470230255951,\n",
    "    #         'depth': 3,\n",
    "    #         'border_count': 237,\n",
    "    #         'l2_leaf_reg': 30.05254548933462,\n",
    "    #         'bagging_temperature': 0.21182488120340903,\n",
    "    #         'random_strength': 9.467948433869887,\n",
    "    #         'min_data_in_leaf': 197,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "    get_catboostclassifier_stacking_estimator(\n",
    "        index=206,\n",
    "        params_dict={ # Optuna study AUC: 0.7261617335276132\n",
    "            'iterations': 30000,\n",
    "            'learning_rate': 0.09707927895048607,\n",
    "            'depth': 3,\n",
    "            'border_count': 198,\n",
    "            'l2_leaf_reg': 38.30141967381568,\n",
    "            'bagging_temperature': 0.0405377771311029,\n",
    "            'random_strength': 9.771109944558193,\n",
    "            'min_data_in_leaf': 177,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f257f",
   "metadata": {
    "papermill": {
     "duration": 0.015907,
     "end_time": "2025-12-31T04:24:01.169221",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.153314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.2 LGBMClassifier\n",
    "\n",
    "### 8.2.1 Helper Methods (LGBMClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18b14208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.200637Z",
     "iopub.status.busy": "2025-12-31T04:24:01.199715Z",
     "iopub.status.idle": "2025-12-31T04:24:01.210963Z",
     "shell.execute_reply": "2025-12-31T04:24:01.209801Z"
    },
    "papermill": {
     "duration": 0.029223,
     "end_time": "2025-12-31T04:24:01.212966",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.183743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lgbmclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds_accumulator = np.zeros(len(train_data))\n",
    "    test_preds_accumulator = np.zeros(len(test_data))\n",
    "\n",
    "    X_train = train_data[feature_names]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(train_data[feature_names], train_data[target_col])\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "\n",
    "        seed_oof_preds = np.zeros(len(train_data))\n",
    "\n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = X_train.iloc[train_indices]\n",
    "            X_validation_fold = X_train.iloc[validation_indices]\n",
    "            y_train_fold = y_train.iloc[train_indices]\n",
    "            y_validation_fold = y_train.iloc[validation_indices]\n",
    "\n",
    "            model = lgb.LGBMClassifier(\n",
    "                **params_dict,\n",
    "                n_estimators=30000,\n",
    "                objective='binary',\n",
    "                metric='auc',\n",
    "                verbose=-1,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=(X_validation_fold, y_validation_fold),\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS, verbose=0)]\n",
    "            )\n",
    "\n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            y_test_pred_proba = model.predict_proba(test_data[feature_names])[:, 1]\n",
    "            seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "            test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "\n",
    "        oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "    final_oof_preds = oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "    final_test_preds = test_preds_accumulator / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(final_oof_preds), pd.Series(final_test_preds)\n",
    "\n",
    "def get_lgbmclassifier_stacking_estimator(index, params_dict, feature_names):\n",
    "    return StackingEstimator(\n",
    "        name=f\"LGBMClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=feature_names,\n",
    "        get_preds=get_lgbmclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28be8c",
   "metadata": {
    "papermill": {
     "duration": 0.016135,
     "end_time": "2025-12-31T04:24:01.247029",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.230894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.2.2 Add Estimators (LGBMClassifier)\n",
    "\n",
    "Add XGBClassifier estimators to list that StackingPredictionsRetriever will process. Hyperparameters were found using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfafc2bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.280763Z",
     "iopub.status.busy": "2025-12-31T04:24:01.280177Z",
     "iopub.status.idle": "2025-12-31T04:24:01.308798Z",
     "shell.execute_reply": "2025-12-31T04:24:01.307637Z"
    },
    "papermill": {
     "duration": 0.047234,
     "end_time": "2025-12-31T04:24:01.310578",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.263344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LGBMClassifier base models using FEATURE_SET_1\n",
    "estimators += [\n",
    "    # get_lgbmclassifier_stacking_estimator(\n",
    "    #     index=1,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7276280474276193\n",
    "    #         'learning_rate': 0.01125492919087445,\n",
    "    #         'num_leaves': 18,\n",
    "    #         'min_child_samples': 11,\n",
    "    #         'subsample': 0.999676392356712,\n",
    "    #         'colsample_bytree': 0.5319864181594173,\n",
    "    #         'reg_alpha': 9.584221562909311,\n",
    "    #         'reg_lambda': 3.3831986318550724,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=2,\n",
    "        params_dict={ # Optuna study AUC: 0.7277311734147552\n",
    "            'learning_rate': 0.060449260107967834,\n",
    "            'num_leaves': 7,\n",
    "            'min_child_samples': 55,\n",
    "            'subsample': 0.923934087842396,\n",
    "            'colsample_bytree': 0.5313004056194756,\n",
    "            'reg_alpha': 9.481239127684901,\n",
    "            'reg_lambda': 0.001336263986782526,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=3,\n",
    "        params_dict={ # Optuna study AUC: 0.7277063286096981\n",
    "            'learning_rate': 0.028103753111304447,\n",
    "            'num_leaves': 8,\n",
    "            'min_child_samples': 50,\n",
    "            'subsample': 0.5917000582350134,\n",
    "            'colsample_bytree': 0.4222659398825859,\n",
    "            'reg_alpha': 17.056836702128017,\n",
    "            'reg_lambda': 0.005161430844595434,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    # get_lgbmclassifier_stacking_estimator(\n",
    "    #     index=4,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7277637392447089\n",
    "    #         'learning_rate': 0.021776422228844104,\n",
    "    #         'num_leaves': 34,\n",
    "    #         'min_child_samples': 124,\n",
    "    #         'subsample': 0.7672542347544175,\n",
    "    #         'colsample_bytree': 0.40540262525095094,\n",
    "    #         'reg_alpha': 13.154165547218854,\n",
    "    #         'reg_lambda': 1.6421360904189628,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    # get_lgbmclassifier_stacking_estimator(\n",
    "    #     index=5,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7280265610367231\n",
    "    #         'learning_rate': 0.005372538919315431,\n",
    "    #         'num_leaves': 40,\n",
    "    #         'min_child_samples': 494,\n",
    "    #         'subsample': 0.9625276144224274,\n",
    "    #         'colsample_bytree': 0.3279562120965377,\n",
    "    #         'reg_alpha': 1.5142522813882282,\n",
    "    #         'reg_lambda': 4.088524578916788,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=6,\n",
    "        params_dict={ # Optuna study AUC: 0.7285206901236\n",
    "            'learning_rate': 0.010514959295597044,\n",
    "            'num_leaves': 59,\n",
    "            'min_child_samples': 459,\n",
    "            'subsample': 0.9801456440779619,\n",
    "            'colsample_bytree': 0.21788689229472508,\n",
    "            'reg_alpha': 1.0879584848361499,\n",
    "            'reg_lambda': 2.824035430134392,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=7,\n",
    "        params_dict={ # Optuna study AUC: 0.7284107120755644\n",
    "            'learning_rate': 0.005337402645739864,\n",
    "            'num_leaves': 63,\n",
    "            'min_child_samples': 164,\n",
    "            'subsample': 0.8344370152901462,\n",
    "            'colsample_bytree': 0.24907941694655586,\n",
    "            'reg_alpha': 11.033723247954274,\n",
    "            'reg_lambda': 7.232987300526449,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=8,\n",
    "        params_dict={ # Optuna study AUC: 0.728549293987892\n",
    "            'learning_rate': 0.004891609003233232,\n",
    "            'num_leaves': 68,\n",
    "            'min_child_samples': 353,\n",
    "            'subsample': 0.7702836237568972,\n",
    "            'colsample_bytree': 0.21758736308082194,\n",
    "            'reg_alpha': 9.248200173575938,\n",
    "            'reg_lambda': 4.933963326601708,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=9,\n",
    "        params_dict={ # Optuna study AUC: 0.7283907091185537\n",
    "            'learning_rate': 0.030612552463613538,\n",
    "            'num_leaves': 43,\n",
    "            'min_child_samples': 386,\n",
    "            'subsample': 0.8154301174001749,\n",
    "            'colsample_bytree': 0.21385466094527275,\n",
    "            'reg_alpha': 10.72316200951412,\n",
    "            'reg_lambda': 7.779911584913586,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=10,\n",
    "        params_dict={ # Optuna study AUC: 0.7279906712847776\n",
    "            'learning_rate': 0.03919138962200246,\n",
    "            'num_leaves': 35,\n",
    "            'min_child_samples': 225,\n",
    "            'min_split_gain': 0.05023146411991609,\n",
    "            'subsample': 0.5961539507977773,\n",
    "            'colsample_bytree': 0.10669519745358953,\n",
    "            'reg_alpha': 0.3254954147190218,\n",
    "            'reg_lambda': 0.6390811014828014,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=11,\n",
    "        params_dict={ # Optuna study AUC: 0.7283403568881219\n",
    "            'learning_rate': 0.03014041766182314,\n",
    "            'num_leaves': 43,\n",
    "            'min_child_samples': 196,\n",
    "            'min_split_gain': 0.07870382373940327,\n",
    "            'subsample': 0.5710456562570112,\n",
    "            'colsample_bytree': 0.10539998953309211,\n",
    "            'reg_alpha': 1.8812331750385778,\n",
    "            'reg_lambda': 2.805371927939983,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    # get_lgbmclassifier_stacking_estimator(\n",
    "    #     index=12,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7280725479607385\n",
    "    #         'learning_rate': 0.013909787667698213,\n",
    "    #         'num_leaves': 34,\n",
    "    #         'min_child_samples': 518,\n",
    "    #         'min_split_gain': 0.005739067126630592,\n",
    "    #         'subsample': 0.8126258628224535,\n",
    "    #         'colsample_bytree': 0.3068383256714443,\n",
    "    #         'reg_alpha': 9.463557129813784,\n",
    "    #         'reg_lambda': 1.3632810164682128,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=13,\n",
    "        params_dict={ # Optuna study AUC: 0.728229455142913\n",
    "            'learning_rate': 0.023180932970380642,\n",
    "            'num_leaves': 33,\n",
    "            'min_child_samples': 495,\n",
    "            'min_split_gain': 0.0018314783202541777,\n",
    "            'subsample': 0.7808188761780435,\n",
    "            'colsample_bytree': 0.26435056293492076,\n",
    "            'reg_alpha': 12.727574938499398,\n",
    "            'reg_lambda': 5.9249848233276365,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=14,\n",
    "        params_dict={ # Optuna study AUC: 0.7281215093811463\n",
    "            'learning_rate': 0.019683073930799457,\n",
    "            'num_leaves': 29,\n",
    "            'min_child_samples': 355,\n",
    "            'min_split_gain': 0.029562222032764107,\n",
    "            'subsample': 0.639641578887935,\n",
    "            'colsample_bytree': 0.27722076729613665,\n",
    "            'reg_alpha': 9.121114441023241,\n",
    "            'reg_lambda': 1.801694790272159,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "]\n",
    "\n",
    "# LGBMClassifier base models using FEATURE_SET_2\n",
    "estimators += [\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=100,\n",
    "        params_dict={ # Optuna study AUC: 0.7267113594654058\n",
    "            'learning_rate': 0.08030213631902122,\n",
    "            'num_leaves': 10,\n",
    "            'min_child_samples': 36,\n",
    "            'subsample': 0.9736572187439243,\n",
    "            'colsample_bytree': 0.6862436315985779,\n",
    "            'reg_alpha': 19.485115558852872,\n",
    "            'reg_lambda': 0.11379340962435365,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=101,\n",
    "        params_dict={ # Optuna study AUC: 0.7267412352672019\n",
    "            'learning_rate': 0.04180757514768784,\n",
    "            'num_leaves': 13,\n",
    "            'min_child_samples': 15,\n",
    "            'subsample': 0.7602307843844437,\n",
    "            'colsample_bytree': 0.6064219998341494,\n",
    "            'reg_alpha': 11.137420503168325,\n",
    "            'reg_lambda': 0.1206423560374285,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=102,\n",
    "        params_dict={ # Optuna study AUC: 0.7278304844725403\n",
    "            'learning_rate': 0.019123325048105728,\n",
    "            'num_leaves': 59,\n",
    "            'min_child_samples': 359,\n",
    "            'subsample': 0.606454771687896,\n",
    "            'colsample_bytree': 0.1444776504941246,\n",
    "            'reg_alpha': 10.581402527437783,\n",
    "            'reg_lambda': 7.154631032638869,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=103,\n",
    "        params_dict={ # Optuna study AUC: 0.7277193627577382\n",
    "            'learning_rate': 0.027309419421707757,\n",
    "            'num_leaves': 55,\n",
    "            'min_child_samples': 295,\n",
    "            'subsample': 0.475071029536569,\n",
    "            'colsample_bytree': 0.1810707161175214,\n",
    "            'reg_alpha': 8.15812166880756,\n",
    "            'reg_lambda': 9.046841588127366,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=104,\n",
    "        params_dict={ # Optuna study AUC: 0.7279646885679995\n",
    "            'learning_rate': 0.010480214785661916,\n",
    "            'num_leaves': 93,\n",
    "            'min_child_samples': 272,\n",
    "            'subsample': 0.5425209884935407,\n",
    "            'colsample_bytree': 0.14762561375602756,\n",
    "            'reg_alpha': 5.201985796455309,\n",
    "            'reg_lambda': 2.8864194162653183,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=105,\n",
    "        params_dict={ # Optuna study AUC: 0.72798144497887\n",
    "            'learning_rate': 0.01479512136381228,\n",
    "            'num_leaves': 79,\n",
    "            'min_child_samples': 429,\n",
    "            'min_split_gain': 0.03969422372541601,\n",
    "            'subsample': 0.6634754944047546,\n",
    "            'colsample_bytree': 0.14034794303042006,\n",
    "            'reg_alpha': 1.1940667970743344,\n",
    "            'reg_lambda': 18.626636485550414,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    # get_lgbmclassifier_stacking_estimator(\n",
    "    #     index=106,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7274190398812063\n",
    "    #         'learning_rate': 0.021284907294550612,\n",
    "    #         'num_leaves': 43,\n",
    "    #         'min_child_samples': 189,\n",
    "    #         'min_split_gain': 0.08941374139898667,\n",
    "    #         'subsample': 0.6066732253347482,\n",
    "    #         'colsample_bytree': 0.2954477929296213,\n",
    "    #         'reg_alpha': 12.836889013195314,\n",
    "    #         'reg_lambda': 3.9894464387126454,      \n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=107,\n",
    "        params_dict={ # Optuna study AUC: 0.7272209204742971\n",
    "            'learning_rate': 0.024870110418668975,\n",
    "            'num_leaves': 32,\n",
    "            'min_child_samples': 494,\n",
    "            'min_split_gain': 0.0005913639234297586,\n",
    "            'subsample': 0.7587055420676849,\n",
    "            'colsample_bytree': 0.37000848536901887,\n",
    "            'reg_alpha': 2.160187945675459,\n",
    "            'reg_lambda': 28.862050376184836,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "]\n",
    "\n",
    "# LGBMClassifier base models using FEATURE_SET_3\n",
    "estimators += [\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=200,\n",
    "        params_dict={ # Optuna study AUC: 0.7276949434259791\n",
    "            'learning_rate': 0.02440401367741379,\n",
    "            'num_leaves': 47,\n",
    "            'min_child_samples': 257,\n",
    "            'min_split_gain': 0.0032121199918099664,\n",
    "            'subsample': 0.7936633846441812,\n",
    "            'colsample_bytree': 0.20767719549306815,\n",
    "            'reg_alpha': 6.0582293684829365,\n",
    "            'reg_lambda': 2.4407051521707515,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=201,\n",
    "        params_dict={ # Optuna study AUC: 0.7275512006104322\n",
    "            'learning_rate': 0.028043335648358536,\n",
    "            'num_leaves': 55,\n",
    "            'min_child_samples': 468,\n",
    "            'min_split_gain': 0.0007136696565902894,\n",
    "            'subsample': 0.8806276921497183,\n",
    "            'colsample_bytree': 0.2182810816503329,\n",
    "            'reg_alpha': 6.672897403557166,\n",
    "            'reg_lambda': 4.315365922939719,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=202,\n",
    "        params_dict={ # Optuna study AUC: 0.7267595056022728\n",
    "            'learning_rate': 0.03139400478939389,\n",
    "            'num_leaves': 14,\n",
    "            'min_child_samples': 230,\n",
    "            'min_split_gain': 0.002362112652730475,\n",
    "            'subsample': 0.668240094229581,\n",
    "            'colsample_bytree': 0.35751393630320255,\n",
    "            'reg_alpha': 0.13810005003251896,\n",
    "            'reg_lambda': 0.7113206310887704,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    get_lgbmclassifier_stacking_estimator(\n",
    "        index=203,\n",
    "        params_dict={ # Optuna study AUC: 0.7272005583249114\n",
    "            'learning_rate': 0.023919133050357203,\n",
    "            'num_leaves': 23,\n",
    "            'min_child_samples': 270,\n",
    "            'min_split_gain': 0.01757643438315908,\n",
    "            'subsample': 0.9216319828366681,\n",
    "            'colsample_bytree': 0.25307535834543227,\n",
    "            'reg_alpha': 0.15840694806695113,\n",
    "            'reg_lambda': 3.9473500486818325,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    # get_lgbmclassifier_stacking_estimator(\n",
    "    #     index=204,\n",
    "    #     params_dict={ # Optuna study AUC: 0.726895431577648\n",
    "    #         'learning_rate': 0.0297665473868245,\n",
    "    #         'num_leaves': 23,\n",
    "    #         'min_child_samples': 223,\n",
    "    #         'min_split_gain': 0.08777450218531875,\n",
    "    #         'subsample': 0.8001257513311284,\n",
    "    #         'colsample_bytree': 0.4063046200565479,\n",
    "    #         'reg_alpha': 8.753771452700681,\n",
    "    #         'reg_lambda': 16.828130088381638,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "    # get_lgbmclassifier_stacking_estimator(\n",
    "    #     index=205,\n",
    "    #     params_dict={ # Optuna study AUC: 0.726806215190524\n",
    "    #         'learning_rate': 0.0226239202805405,\n",
    "    #         'num_leaves': 16,\n",
    "    #         'min_child_samples': 187,\n",
    "    #         'min_split_gain': 0.0008562657172401912,\n",
    "    #         'subsample': 0.6675455599332893,\n",
    "    #         'colsample_bytree': 0.527771427312258,\n",
    "    #         'reg_alpha': 5.554497850709915,\n",
    "    #         'reg_lambda': 28.82487683301403,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d193d8f",
   "metadata": {
    "papermill": {
     "duration": 0.01953,
     "end_time": "2025-12-31T04:24:01.347659",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.328129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.3 XGBClassifier\n",
    "\n",
    "### 8.3.1 Helper Methods (XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95726d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.382480Z",
     "iopub.status.busy": "2025-12-31T04:24:01.381870Z",
     "iopub.status.idle": "2025-12-31T04:24:01.394508Z",
     "shell.execute_reply": "2025-12-31T04:24:01.393137Z"
    },
    "papermill": {
     "duration": 0.032046,
     "end_time": "2025-12-31T04:24:01.397053",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.365007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xgbclassifier_preds(params_dict, feature_names):\n",
    "    oof_preds_accumulator = np.zeros(len(train_data))\n",
    "    test_preds_accumulator = np.zeros(len(test_data))\n",
    "\n",
    "    X_train = train_data[feature_names]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    for random_seed in RANDOM_SEEDS:\n",
    "        skf = StratifiedKFold(n_splits=BASE_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "        skf_splits = skf.split(X_train, y_train)\n",
    "        skf_enumeration = enumerate(skf_splits)\n",
    "\n",
    "        seed_oof_preds = np.zeros(len(train_data))\n",
    "\n",
    "        for fold, (train_indices, validation_indices) in skf_enumeration:\n",
    "            X_train_fold = X_train.iloc[train_indices]\n",
    "            X_validation_fold = X_train.iloc[validation_indices]\n",
    "            y_train_fold = y_train.iloc[train_indices]\n",
    "            y_validation_fold = y_train.iloc[validation_indices]\n",
    "\n",
    "            model = XGBClassifier(\n",
    "                **params_dict,\n",
    "                tree_method='hist' if torch.cuda.is_available() else 'auto',\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "                enable_categorical=True,\n",
    "                objective='binary:logistic',\n",
    "                eval_metric='auc',\n",
    "                early_stopping_rounds=BASE_MODEL_EARLY_STOPPING_ROUNDS,\n",
    "                n_jobs=-1,\n",
    "                random_state=random_seed,\n",
    "                verbosity=0\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=[(X_validation_fold, y_validation_fold)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "            y_test_pred_proba = model.predict_proba(test_data[feature_names])[:, 1]\n",
    "            seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "            test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "\n",
    "        oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "    final_oof_preds = oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "    final_test_preds = test_preds_accumulator / (BASE_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "    return pd.Series(final_oof_preds), pd.Series(final_test_preds)\n",
    "\n",
    "def get_xgbclassifier_stacking_estimator(index, params_dict, feature_names):\n",
    "    return StackingEstimator(\n",
    "        name=f\"XGBClassifier_{index}\",\n",
    "        params_dict=params_dict,\n",
    "        feature_names=feature_names,\n",
    "        get_preds=get_xgbclassifier_preds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb9f65",
   "metadata": {
    "papermill": {
     "duration": 0.015955,
     "end_time": "2025-12-31T04:24:01.429207",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.413252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.3.2 Add Estimators (XGBClassifier)\n",
    "\n",
    "Add XGBClassifier estimators to list that StackingPredictionsRetriever will process. Hyperparameters were found using Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e89453a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.466266Z",
     "iopub.status.busy": "2025-12-31T04:24:01.465029Z",
     "iopub.status.idle": "2025-12-31T04:24:01.488851Z",
     "shell.execute_reply": "2025-12-31T04:24:01.487563Z"
    },
    "papermill": {
     "duration": 0.045367,
     "end_time": "2025-12-31T04:24:01.490614",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.445247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBClassifier base models using FEATURE_SET_1\n",
    "estimators += [\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=1,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7275219804910846\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.00985498815107458,\n",
    "    #         'max_depth': 3,\n",
    "    #         'subsample': 0.975836120137461,\n",
    "    #         'colsample_bytree': 0.5411854284303592,\n",
    "    #         'alpha': 9.940781978752474,\n",
    "    #         'gamma': 0.008422323405815038,\n",
    "    #         'lambda': 0.025214960531620187,\n",
    "    #         'min_child_weight': 12,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=2,\n",
    "        params_dict={ # Optuna study AUC: 0.7273817150393508\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.047179227853488916,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.9561594029099818,\n",
    "            'colsample_bytree': 0.5200809916944509,\n",
    "            'alpha': 9.323686821094613,\n",
    "            'gamma': 0.06513704074541844,\n",
    "            'lambda': 0.07573405175712218,\n",
    "            'min_child_weight': 14,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=3,\n",
    "        params_dict={ # Optuna study AUC: 0.7274144144696422\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.06778303256075534,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.9750702612583769,\n",
    "            'colsample_bytree': 0.5164463777572837,\n",
    "            'alpha': 6.677223824702266,\n",
    "            'gamma': 0.06627215758548254,\n",
    "            'lambda': 0.10239210156952944,\n",
    "            'min_child_weight': 17,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=4,\n",
    "        params_dict={ # Optuna study AUC: 0.7263868488191946\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.00992002978574334,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.6885700003314461,\n",
    "            'colsample_bytree': 0.5082842329050175,\n",
    "            'alpha': 4.042835803115786,\n",
    "            'gamma': 0.19033575052721494,\n",
    "            'lambda': 1.4531584526994292,\n",
    "            'min_child_weight': 79,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=5,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7261995858097773\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.005092159244819224,\n",
    "    #         'max_depth': 8,\n",
    "    #         'subsample': 0.6985482460232558,\n",
    "    #         'colsample_bytree': 0.5002716122370332,\n",
    "    #         'alpha': 0.5442317401534714,\n",
    "    #         'gamma': 0.9101677712528158,\n",
    "    #         'lambda': 1.4849248721792976,\n",
    "    #         'min_child_weight': 86,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=6,\n",
    "        params_dict={ # Optuna study AUC: 0.7276697068781471\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.02372054087355925,\n",
    "            'max_depth': 15,\n",
    "            'subsample': 0.926157066763106,\n",
    "            'colsample_bytree': 0.08129535635192518,\n",
    "            'alpha': 0.8089388335721612,\n",
    "            'gamma': 2.155286395452771,\n",
    "            'lambda': 0.0032987476048184643,\n",
    "            'min_child_weight': 106,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=7,\n",
    "        params_dict={ # Optuna study AUC: 0.7275829624569639\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.03082838156810333,\n",
    "            'max_depth': 15,\n",
    "            'subsample': 0.9355182595718994,\n",
    "            'colsample_bytree': 0.04726638467138021,\n",
    "            'alpha': 0.0006789202250200641,\n",
    "            'gamma': 2.0423438455052727,\n",
    "            'lambda': 0.0011440505027664526,\n",
    "            'min_child_weight': 99,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=8,\n",
    "    #     params_dict={ # Optuna study AUC: 0.726481873087293\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.016778981442240135,\n",
    "    #         'max_depth': 7,\n",
    "    #         'subsample': 0.8535639994326161,\n",
    "    #         'colsample_bytree': 0.3601691434581828,\n",
    "    #         'alpha': 0.11594863371568545,\n",
    "    #         'gamma': 1.7534917855981467,\n",
    "    #         'lambda': 90.18952430127791,\n",
    "    #         'min_child_weight': 232,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=9,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7269334752728761\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.006633818069700181,\n",
    "    #         'max_depth': 6,\n",
    "    #         'subsample': 0.8928869407116772,\n",
    "    #         'colsample_bytree': 0.302247524251857,\n",
    "    #         'alpha': 0.7271655035016035,\n",
    "    #         'gamma': 0.10791293819417,\n",
    "    #         'lambda': 31.358637398115444,\n",
    "    #         'min_child_weight': 211,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_1\n",
    "    # ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=10,\n",
    "        params_dict={ # Optuna study AUC: 0.7267016243216274\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.01541504042919444,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.898530669203575,\n",
    "            'colsample_bytree': 0.44350929512696624,\n",
    "            'alpha': 0.11291553156416392,\n",
    "            'gamma': 0.22741023384123787,\n",
    "            'lambda': 4.885615406166625,\n",
    "            'min_child_weight': 204,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=11,\n",
    "        params_dict={ # Optuna study AUC: 0.7268725441663415\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.008722544820454547,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.9322104305014642,\n",
    "            'colsample_bytree': 0.8603707435128638,\n",
    "            'alpha': 0.4706079902529737,\n",
    "            'gamma': 1.1134986358862557,\n",
    "            'lambda': 0.2571975355765451,\n",
    "            'min_child_weight': 178,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_1\n",
    "    ),\n",
    "]\n",
    "\n",
    "# XGBClassifier base models using FEATURE_SET_2\n",
    "estimators += [\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=100,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7262159108318079\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.011859808032021718,\n",
    "    #         'max_depth': 3,\n",
    "    #         'subsample': 0.9372116555018073,\n",
    "    #         'colsample_bytree': 0.9755650095828481,\n",
    "    #         'alpha': 11.83079224267289,\n",
    "    #         'gamma': 0.47957759727475824,\n",
    "    #         'lambda': 1.5631226520724053,\n",
    "    #         'min_child_weight': 38,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=101,\n",
    "        params_dict={ # Optuna study AUC: 0.7273837184769656\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.027980355641639105,\n",
    "            'max_depth': 22,\n",
    "            'subsample': 0.9470465534609164,\n",
    "            'colsample_bytree': 0.037050915293494434,\n",
    "            'alpha': 5.919291266337225e-07,\n",
    "            'gamma': 2.2947298746512588,\n",
    "            'lambda': 0.00937046969544808,\n",
    "            'min_child_weight': 109,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=102,\n",
    "        params_dict={ # Optuna study AUC: 0.7273458047806104\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.046164174619963895,\n",
    "            'max_depth': 15,\n",
    "            'subsample': 0.990211202548381,\n",
    "            'colsample_bytree': 0.03512726983073455,\n",
    "            'alpha': 3.6758967225029957e-06,\n",
    "            'gamma': 2.367535362401481,\n",
    "            'lambda': 0.007800881812139096,\n",
    "            'min_child_weight': 59,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=103,\n",
    "        params_dict={ # Optuna study AUC: 0.7271766457975763\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.029608261279916184,\n",
    "            'max_depth': 12,\n",
    "            'subsample': 0.8302439848584828,\n",
    "            'colsample_bytree': 0.03599141865024359,\n",
    "            'alpha': 2.370851147241027e-08,\n",
    "            'gamma': 2.488161026703388,\n",
    "            'lambda': 0.03579562780682341,\n",
    "            'min_child_weight': 79,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_2\n",
    "    ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=104,\n",
    "    #     params_dict={ # Optuna study AUC: 0.727313377922011\n",
    "    #         'learning_rate': 0.018830984253997193,\n",
    "    #         'max_depth': 17,\n",
    "    #         'subsample': 0.9721977334617213,\n",
    "    #         'colsample_bytree': 0.04297481358590687,\n",
    "    #         'alpha': 1.0510194593417237,\n",
    "    #         'gamma': 1.9540524911604567,\n",
    "    #         'lambda': 0.20230023217673998,\n",
    "    #         'min_child_weight': 96,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=105,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7271054074166622\n",
    "    #         'learning_rate': 0.016139246094996982,\n",
    "    #         'max_depth': 18,\n",
    "    #         'subsample': 0.9564519772365436,\n",
    "    #         'colsample_bytree': 0.04057400543991785,\n",
    "    #         'alpha': 0.13886943367841298,\n",
    "    #         'gamma': 2.103458500140603,\n",
    "    #         'lambda': 0.271808754880666,\n",
    "    #         'min_child_weight': 189,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=106,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7267722841676081\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.0065043250205180534,\n",
    "    #         'max_depth': 10,\n",
    "    #         'subsample': 0.8945044057959924,\n",
    "    #         'colsample_bytree': 0.10087167584713677,\n",
    "    #         'alpha': 1.8921170347131862,\n",
    "    #         'gamma': 2.865040204519563,\n",
    "    #         'lambda': 3.335272814695635,\n",
    "    #         'min_child_weight': 83,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=107,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7266176698378618\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.007924773077477808,\n",
    "    #         'max_depth': 11,\n",
    "    #         'subsample': 0.8016340992158001,\n",
    "    #         'colsample_bytree': 0.11042333005514733,\n",
    "    #         'alpha': 3.794091823169151,\n",
    "    #         'gamma': 2.0651797737669173,\n",
    "    #         'lambda': 9.274540244581045,\n",
    "    #         'min_child_weight': 100,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_2\n",
    "    # ),\n",
    "]\n",
    "\n",
    "# XGBClassifier base models using FEATURE_SET_3\n",
    "estimators += [\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=200,\n",
    "    #     params_dict={ # Optuna study AUC: 0.72662484358974\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.004722170637610488,\n",
    "    #         'max_depth': 8,\n",
    "    #         'subsample': 0.9463619229520444,\n",
    "    #         'colsample_bytree': 0.10815535487923243,\n",
    "    #         'alpha': 0.2266410700990591,\n",
    "    #         'gamma': 1.5254201232797373,\n",
    "    #         'lambda': 1.1151246586327885,\n",
    "    #         'min_child_weight': 59,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=201,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7263789553843397\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.004111790393241001,\n",
    "    #         'max_depth': 5,\n",
    "    #         'subsample': 0.9300933146213577,\n",
    "    #         'colsample_bytree': 0.1493961853415991,\n",
    "    #         'alpha': 0.12456513604853313,\n",
    "    #         'gamma': 0.9403251116679338,\n",
    "    #         'lambda': 8.136098473974746,\n",
    "    #         'min_child_weight': 114,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "    get_xgbclassifier_stacking_estimator(\n",
    "        index=202,\n",
    "        params_dict={ # Optuna study AUC: 0.7262290159966112\n",
    "            'n_estimators': 30000,\n",
    "            'learning_rate': 0.05550672575020678,\n",
    "            'max_depth': 3,\n",
    "            'subsample': 0.9477018401213056,\n",
    "            'colsample_bytree': 0.4493907534694529,\n",
    "            'alpha': 4.47848584018269,\n",
    "            'gamma': 0.9155407876651237,\n",
    "            'lambda': 9.972213918787583,\n",
    "            'min_child_weight': 56,\n",
    "        },\n",
    "        feature_names=FEATURE_SET_3\n",
    "    ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=203,\n",
    "    #     params_dict={ # Optuna study AUC: 0.7262949541805783\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.06597548869194442,\n",
    "    #         'max_depth': 3,\n",
    "    #         'subsample': 0.9292415774505621,\n",
    "    #         'colsample_bytree': 0.2419008659034062,\n",
    "    #         'alpha': 4.150553881297006,\n",
    "    #         'gamma': 0.49205261469458217,\n",
    "    #         'lambda': 2.043007240380063,\n",
    "    #         'min_child_weight': 6,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "    # get_xgbclassifier_stacking_estimator(\n",
    "    #     index=204,\n",
    "    #     params_dict={ # Optuna study AUC: 0.726241045292214\n",
    "    #         'n_estimators': 30000,\n",
    "    #         'learning_rate': 0.031040864135625165,\n",
    "    #         'max_depth': 4,\n",
    "    #         'subsample': 0.9380337531391458,\n",
    "    #         'colsample_bytree': 0.10194279727241388,\n",
    "    #         'alpha': 4.329119623946634,\n",
    "    #         'gamma': 0.9675602501164753,\n",
    "    #         'lambda': 1.0345146162650225,\n",
    "    #         'min_child_weight': 22,\n",
    "    #     },\n",
    "    #     feature_names=FEATURE_SET_3\n",
    "    # ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e1a9a",
   "metadata": {
    "papermill": {
     "duration": 0.014569,
     "end_time": "2025-12-31T04:24:01.521010",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.506441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8.4 Number of Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c26bd1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.552214Z",
     "iopub.status.busy": "2025-12-31T04:24:01.551820Z",
     "iopub.status.idle": "2025-12-31T04:24:01.556924Z",
     "shell.execute_reply": "2025-12-31T04:24:01.555850Z"
    },
    "papermill": {
     "duration": 0.02381,
     "end_time": "2025-12-31T04:24:01.559516",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.535706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of base models: 41\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of base models: {len(estimators)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78678fea",
   "metadata": {
    "papermill": {
     "duration": 0.018034,
     "end_time": "2025-12-31T04:24:01.593810",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.575776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. Base Model Predictions\n",
    "\n",
    "## 9.1 Get Base Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a6dced6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:24:01.628887Z",
     "iopub.status.busy": "2025-12-31T04:24:01.628552Z",
     "iopub.status.idle": "2025-12-31T04:25:57.009445Z",
     "shell.execute_reply": "2025-12-31T04:25:57.007880Z"
    },
    "papermill": {
     "duration": 115.401644,
     "end_time": "2025-12-31T04:25:57.011191",
     "exception": false,
     "start_time": "2025-12-31T04:24:01.609547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Finished clearing predictions\n",
      "[INFO] Importing predictions..\n",
      "[INFO] 41 train predictions were imported:\n",
      "CatBoostClassifier_1 (5b3133609cb7932f4c272f1494d1f6b0), CatBoostClassifier_3 (a2e94c97067190eb52e25c8f0d0b1b81), CatBoostClassifier_101 (939b20ef655c1c22f3cc5749a9dc0de7), CatBoostClassifier_104 (9db0b212db19e590b51a1af7fe65b7a0), CatBoostClassifier_105 (faa5d67c16c906b11264ade5016c0635), CatBoostClassifier_200 (193b4e2a59c2eac5f73a997fb968592b), CatBoostClassifier_202 (44630aa57085636ff4b42ef84843dad4), CatBoostClassifier_203 (2b17c55ab32780d9a9f1a913c64ad718), CatBoostClassifier_206 (3ae27bae1ac853a169480fdb81503537), LGBMClassifier_2 (756b644eceb4b410ad34d055d7a2a7ad), LGBMClassifier_3 (12e279a3f79f03854fcc391dd7dbd023), LGBMClassifier_6 (a0c02e5dec4bd4467961cd96901740a9), LGBMClassifier_7 (0d5c160d0c75a01607ee65e1309f0f3e), LGBMClassifier_8 (74451732f18860140bc6e208f17167ec), LGBMClassifier_9 (535b190c7fd27867f25b36c846af5749), LGBMClassifier_10 (d768bcfaea71d6315f8a3aec15264fd3), LGBMClassifier_11 (434b9911e9f067fa638a7372ae9de3b7), LGBMClassifier_13 (57b6180bb789e56517729d29e1113e9f), LGBMClassifier_14 (e9cd9321a6617423d09c86651868827b), LGBMClassifier_100 (e9308d5ef0fe3d2e21b23b76c24abf10), LGBMClassifier_101 (4184d68f723388204df6096a194619e3), LGBMClassifier_102 (15ce46227658fcf66d9fa61aa8770bd6), LGBMClassifier_103 (0f77b5c92200f4372a73a16c28e66a0c), LGBMClassifier_104 (03f3c6e632f5fffd70ec8a4c916a9b3a), LGBMClassifier_105 (b69a0d12e5e9a0dea6e97fd93d6e83ca), LGBMClassifier_107 (209378e46f2c00fc2bab71cb2a4b2806), LGBMClassifier_200 (595825024cf6728eede6526c34137bea), LGBMClassifier_201 (6fc3b3d774e94599d833c0f91c5a3bd9), LGBMClassifier_202 (be93bc9c94b117d579fef02264e6d81f), LGBMClassifier_203 (d42c5caf1073a9a9e7440490645eea6f), XGBClassifier_2 (f9455e9875a464c78cd90b60584d3f1c), XGBClassifier_3 (4a02ebc078c643d903a00ddcfb0f3301), XGBClassifier_4 (41fcdf694bf252b540f6c6d28d63eb45), XGBClassifier_6 (dd58a49196a10b1dfc83dd004b5cae1b), XGBClassifier_7 (159c6c407450077591a665dea6ecacfe), XGBClassifier_10 (3eba9b3facf87fe1c9ba57c1d875c799), XGBClassifier_11 (a13eb68990690e9fc4bef373e814ae80), XGBClassifier_101 (34a22ef42d0624dee9c89abc9971c23f), XGBClassifier_102 (3a16502492397945fe3feec5f3ce94f2), XGBClassifier_103 (ea8d1ee90caf97bacd865adb7e87423d), XGBClassifier_202 (29c6bbceec36b1810be94900531114e9)\n",
      "[INFO] 41 test predictions were imported:\n",
      "CatBoostClassifier_1 (5b3133609cb7932f4c272f1494d1f6b0), CatBoostClassifier_3 (a2e94c97067190eb52e25c8f0d0b1b81), CatBoostClassifier_101 (939b20ef655c1c22f3cc5749a9dc0de7), CatBoostClassifier_104 (9db0b212db19e590b51a1af7fe65b7a0), CatBoostClassifier_105 (faa5d67c16c906b11264ade5016c0635), CatBoostClassifier_200 (193b4e2a59c2eac5f73a997fb968592b), CatBoostClassifier_202 (44630aa57085636ff4b42ef84843dad4), CatBoostClassifier_203 (2b17c55ab32780d9a9f1a913c64ad718), CatBoostClassifier_206 (3ae27bae1ac853a169480fdb81503537), LGBMClassifier_2 (756b644eceb4b410ad34d055d7a2a7ad), LGBMClassifier_3 (12e279a3f79f03854fcc391dd7dbd023), LGBMClassifier_6 (a0c02e5dec4bd4467961cd96901740a9), LGBMClassifier_7 (0d5c160d0c75a01607ee65e1309f0f3e), LGBMClassifier_8 (74451732f18860140bc6e208f17167ec), LGBMClassifier_9 (535b190c7fd27867f25b36c846af5749), LGBMClassifier_10 (d768bcfaea71d6315f8a3aec15264fd3), LGBMClassifier_11 (434b9911e9f067fa638a7372ae9de3b7), LGBMClassifier_13 (57b6180bb789e56517729d29e1113e9f), LGBMClassifier_14 (e9cd9321a6617423d09c86651868827b), LGBMClassifier_100 (e9308d5ef0fe3d2e21b23b76c24abf10), LGBMClassifier_101 (4184d68f723388204df6096a194619e3), LGBMClassifier_102 (15ce46227658fcf66d9fa61aa8770bd6), LGBMClassifier_103 (0f77b5c92200f4372a73a16c28e66a0c), LGBMClassifier_104 (03f3c6e632f5fffd70ec8a4c916a9b3a), LGBMClassifier_105 (b69a0d12e5e9a0dea6e97fd93d6e83ca), LGBMClassifier_107 (209378e46f2c00fc2bab71cb2a4b2806), LGBMClassifier_200 (595825024cf6728eede6526c34137bea), LGBMClassifier_201 (6fc3b3d774e94599d833c0f91c5a3bd9), LGBMClassifier_202 (be93bc9c94b117d579fef02264e6d81f), LGBMClassifier_203 (d42c5caf1073a9a9e7440490645eea6f), XGBClassifier_2 (f9455e9875a464c78cd90b60584d3f1c), XGBClassifier_3 (4a02ebc078c643d903a00ddcfb0f3301), XGBClassifier_4 (41fcdf694bf252b540f6c6d28d63eb45), XGBClassifier_6 (dd58a49196a10b1dfc83dd004b5cae1b), XGBClassifier_7 (159c6c407450077591a665dea6ecacfe), XGBClassifier_10 (3eba9b3facf87fe1c9ba57c1d875c799), XGBClassifier_11 (a13eb68990690e9fc4bef373e814ae80), XGBClassifier_101 (34a22ef42d0624dee9c89abc9971c23f), XGBClassifier_102 (3a16502492397945fe3feec5f3ce94f2), XGBClassifier_103 (ea8d1ee90caf97bacd865adb7e87423d), XGBClassifier_202 (29c6bbceec36b1810be94900531114e9)\n",
      "[INFO] Finished importing predictions\n",
      "[INFO] Syncing predictions..\n",
      "[INFO] No columns for training predictions were dropped\n",
      "[INFO] No columns for test predictions were dropped\n",
      "[INFO] Finished syncing predictions\n",
      "[INFO] Getting predictions..\n",
      "[INFO] Skipped retrieving predictions for following estimators as their current ones are not stale:\n",
      "CatBoostClassifier_1 (5b3133609cb7932f4c272f1494d1f6b0), CatBoostClassifier_101 (939b20ef655c1c22f3cc5749a9dc0de7), CatBoostClassifier_104 (9db0b212db19e590b51a1af7fe65b7a0), CatBoostClassifier_105 (faa5d67c16c906b11264ade5016c0635), CatBoostClassifier_200 (193b4e2a59c2eac5f73a997fb968592b), CatBoostClassifier_202 (44630aa57085636ff4b42ef84843dad4), CatBoostClassifier_203 (2b17c55ab32780d9a9f1a913c64ad718), CatBoostClassifier_206 (3ae27bae1ac853a169480fdb81503537), CatBoostClassifier_3 (a2e94c97067190eb52e25c8f0d0b1b81), LGBMClassifier_10 (d768bcfaea71d6315f8a3aec15264fd3), LGBMClassifier_100 (e9308d5ef0fe3d2e21b23b76c24abf10), LGBMClassifier_101 (4184d68f723388204df6096a194619e3), LGBMClassifier_102 (15ce46227658fcf66d9fa61aa8770bd6), LGBMClassifier_103 (0f77b5c92200f4372a73a16c28e66a0c), LGBMClassifier_104 (03f3c6e632f5fffd70ec8a4c916a9b3a), LGBMClassifier_105 (b69a0d12e5e9a0dea6e97fd93d6e83ca), LGBMClassifier_107 (209378e46f2c00fc2bab71cb2a4b2806), LGBMClassifier_11 (434b9911e9f067fa638a7372ae9de3b7), LGBMClassifier_13 (57b6180bb789e56517729d29e1113e9f), LGBMClassifier_14 (e9cd9321a6617423d09c86651868827b), LGBMClassifier_2 (756b644eceb4b410ad34d055d7a2a7ad), LGBMClassifier_200 (595825024cf6728eede6526c34137bea), LGBMClassifier_201 (6fc3b3d774e94599d833c0f91c5a3bd9), LGBMClassifier_202 (be93bc9c94b117d579fef02264e6d81f), LGBMClassifier_203 (d42c5caf1073a9a9e7440490645eea6f), LGBMClassifier_3 (12e279a3f79f03854fcc391dd7dbd023), LGBMClassifier_6 (a0c02e5dec4bd4467961cd96901740a9), LGBMClassifier_7 (0d5c160d0c75a01607ee65e1309f0f3e), LGBMClassifier_8 (74451732f18860140bc6e208f17167ec), LGBMClassifier_9 (535b190c7fd27867f25b36c846af5749), XGBClassifier_10 (3eba9b3facf87fe1c9ba57c1d875c799), XGBClassifier_101 (34a22ef42d0624dee9c89abc9971c23f), XGBClassifier_102 (3a16502492397945fe3feec5f3ce94f2), XGBClassifier_103 (ea8d1ee90caf97bacd865adb7e87423d), XGBClassifier_11 (a13eb68990690e9fc4bef373e814ae80), XGBClassifier_2 (f9455e9875a464c78cd90b60584d3f1c), XGBClassifier_202 (29c6bbceec36b1810be94900531114e9), XGBClassifier_3 (4a02ebc078c643d903a00ddcfb0f3301), XGBClassifier_4 (41fcdf694bf252b540f6c6d28d63eb45), XGBClassifier_6 (dd58a49196a10b1dfc83dd004b5cae1b), XGBClassifier_7 (159c6c407450077591a665dea6ecacfe)\n",
      "[INFO] Finished getting all predictions\n"
     ]
    }
   ],
   "source": [
    "stacking_preds_retriever = StackingPredictionsRetriever(\n",
    "    estimators=estimators,\n",
    "    working_dir_path=\"/kaggle/working/\",\n",
    "    train_preds_filename=\"base_models_train_preds\",\n",
    "    test_preds_filename=\"base_models_test_preds\",\n",
    "    preds_save_interval=1\n",
    ")\n",
    "stacking_preds_retriever.clear_preds()\n",
    "stacking_preds_retriever.import_preds(\"/kaggle/input/diabetes-prediction-challenge-base-model-preds/\")\n",
    "stacking_preds_retriever.sync_preds()\n",
    "stacking_preds_retriever.get_preds()\n",
    "\n",
    "base_model_train_preds, base_model_test_preds = stacking_preds_retriever.get_current_train_and_test_preds()\n",
    "base_model_train_preds.sort_index(axis=1, inplace=True, key=lambda index: index.map(lambda col_name: (col_name.split(\"_\")[0], int(col_name.split()[0].split(\"_\")[-1]))))\n",
    "base_model_test_preds.sort_index(axis=1, inplace=True, key=lambda index: index.map(lambda col_name: (col_name.split(\"_\")[0], int(col_name.split()[0].split(\"_\")[-1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460ed5d",
   "metadata": {
    "papermill": {
     "duration": 0.017001,
     "end_time": "2025-12-31T04:25:57.045786",
     "exception": false,
     "start_time": "2025-12-31T04:25:57.028785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9.2 Base Models AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2da3e274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:25:57.078802Z",
     "iopub.status.busy": "2025-12-31T04:25:57.078478Z",
     "iopub.status.idle": "2025-12-31T04:26:11.827237Z",
     "shell.execute_reply": "2025-12-31T04:26:11.826252Z"
    },
    "papermill": {
     "duration": 14.767257,
     "end_time": "2025-12-31T04:26:11.828954",
     "exception": false,
     "start_time": "2025-12-31T04:25:57.061697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier_6 (a0c02e5dec4bd4467961cd96901740a9)          0.729329\n",
       "LGBMClassifier_11 (434b9911e9f067fa638a7372ae9de3b7)         0.729276\n",
       "LGBMClassifier_7 (0d5c160d0c75a01607ee65e1309f0f3e)          0.729191\n",
       "LGBMClassifier_9 (535b190c7fd27867f25b36c846af5749)          0.729190\n",
       "LGBMClassifier_13 (57b6180bb789e56517729d29e1113e9f)         0.729107\n",
       "LGBMClassifier_10 (d768bcfaea71d6315f8a3aec15264fd3)         0.729059\n",
       "LGBMClassifier_14 (e9cd9321a6617423d09c86651868827b)         0.728990\n",
       "LGBMClassifier_104 (03f3c6e632f5fffd70ec8a4c916a9b3a)        0.728980\n",
       "LGBMClassifier_105 (b69a0d12e5e9a0dea6e97fd93d6e83ca)        0.728904\n",
       "LGBMClassifier_103 (0f77b5c92200f4372a73a16c28e66a0c)        0.728801\n",
       "LGBMClassifier_102 (15ce46227658fcf66d9fa61aa8770bd6)        0.728792\n",
       "LGBMClassifier_3 (12e279a3f79f03854fcc391dd7dbd023)          0.728647\n",
       "LGBMClassifier_201 (6fc3b3d774e94599d833c0f91c5a3bd9)        0.728564\n",
       "LGBMClassifier_2 (756b644eceb4b410ad34d055d7a2a7ad)          0.728547\n",
       "LGBMClassifier_200 (595825024cf6728eede6526c34137bea)        0.728528\n",
       "XGBClassifier_6 (dd58a49196a10b1dfc83dd004b5cae1b)           0.728361\n",
       "XGBClassifier_7 (159c6c407450077591a665dea6ecacfe)           0.728263\n",
       "LGBMClassifier_107 (209378e46f2c00fc2bab71cb2a4b2806)        0.728086\n",
       "LGBMClassifier_203 (d42c5caf1073a9a9e7440490645eea6f)        0.727955\n",
       "XGBClassifier_2 (f9455e9875a464c78cd90b60584d3f1c)           0.727895\n",
       "XGBClassifier_3 (4a02ebc078c643d903a00ddcfb0f3301)           0.727831\n",
       "XGBClassifier_101 (34a22ef42d0624dee9c89abc9971c23f)         0.727822\n",
       "XGBClassifier_102 (3a16502492397945fe3feec5f3ce94f2)         0.727786\n",
       "XGBClassifier_103 (ea8d1ee90caf97bacd865adb7e87423d)         0.727724\n",
       "LGBMClassifier_202 (be93bc9c94b117d579fef02264e6d81f)        0.727705\n",
       "LGBMClassifier_101 (4184d68f723388204df6096a194619e3)        0.727692\n",
       "LGBMClassifier_100 (e9308d5ef0fe3d2e21b23b76c24abf10)        0.727588\n",
       "XGBClassifier_10 (3eba9b3facf87fe1c9ba57c1d875c799)          0.727534\n",
       "XGBClassifier_11 (a13eb68990690e9fc4bef373e814ae80)          0.727481\n",
       "CatBoostClassifier_203 (2b17c55ab32780d9a9f1a913c64ad718)    0.727320\n",
       "CatBoostClassifier_105 (faa5d67c16c906b11264ade5016c0635)    0.727305\n",
       "CatBoostClassifier_202 (44630aa57085636ff4b42ef84843dad4)    0.727295\n",
       "CatBoostClassifier_104 (9db0b212db19e590b51a1af7fe65b7a0)    0.727244\n",
       "CatBoostClassifier_101 (939b20ef655c1c22f3cc5749a9dc0de7)    0.727232\n",
       "XGBClassifier_4 (41fcdf694bf252b540f6c6d28d63eb45)           0.727212\n",
       "CatBoostClassifier_200 (193b4e2a59c2eac5f73a997fb968592b)    0.727082\n",
       "CatBoostClassifier_206 (3ae27bae1ac853a169480fdb81503537)    0.727029\n",
       "XGBClassifier_202 (29c6bbceec36b1810be94900531114e9)         0.726951\n",
       "CatBoostClassifier_3 (a2e94c97067190eb52e25c8f0d0b1b81)      0.726661\n",
       "CatBoostClassifier_1 (5b3133609cb7932f4c272f1494d1f6b0)      0.726533\n",
       "LGBMClassifier_8 (74451732f18860140bc6e208f17167ec)          0.725616\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_auc = pd.Series()\n",
    "for estimator in base_model_train_preds.columns:\n",
    "    base_model_auc[estimator] = roc_auc_score(train_data[target_col], base_model_train_preds[estimator])\n",
    "base_model_auc.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c2412",
   "metadata": {
    "papermill": {
     "duration": 0.015921,
     "end_time": "2025-12-31T04:26:11.861386",
     "exception": false,
     "start_time": "2025-12-31T04:26:11.845465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 10. Meta-Model\n",
    "\n",
    "## 10.1 Meta-Model Hyperparameters\n",
    "\n",
    "### 10.1.1 Meta-Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5add11f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:26:11.894575Z",
     "iopub.status.busy": "2025-12-31T04:26:11.894255Z",
     "iopub.status.idle": "2025-12-31T04:26:11.899152Z",
     "shell.execute_reply": "2025-12-31T04:26:11.898264Z"
    },
    "papermill": {
     "duration": 0.023122,
     "end_time": "2025-12-31T04:26:11.900673",
     "exception": false,
     "start_time": "2025-12-31T04:26:11.877551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to skip hyperparameter tuning when it's not needed; set to `False` to do the tuning\n",
    "SKIP_META_MODEL_HYPERPARAMETER_TUNING = False\n",
    "\n",
    "# maximum number of trials Optuna will conduct for the optimization\n",
    "META_MODEL_OPTUNA_STUDY_NUM_TRIALS = 1000\n",
    "\n",
    "# number of splits to use for K-Fold Cross-Validation\n",
    "META_MODEL_KFOLD_NUM_SPLITS = 5\n",
    "\n",
    "# value set for early stopping; this value will be used for actual model training as well\n",
    "META_MODEL_EARLY_STOPPING_ROUNDS = 100\n",
    "\n",
    "# optuna study best parameters for meta model\n",
    "meta_model_optuna_study_best_params = {}\n",
    "\n",
    "# parameters selected for meta model\n",
    "meta_model_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67e2e8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:26:11.935528Z",
     "iopub.status.busy": "2025-12-31T04:26:11.935206Z",
     "iopub.status.idle": "2025-12-31T04:26:11.946752Z",
     "shell.execute_reply": "2025-12-31T04:26:11.945792Z"
    },
    "papermill": {
     "duration": 0.032062,
     "end_time": "2025-12-31T04:26:11.948765",
     "exception": false,
     "start_time": "2025-12-31T04:26:11.916703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_meta_model_optuna_params(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.015, 0.035),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 40, 140),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 150, 250),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.001, 5.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1.0, 20.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 10.0, 300.0, log=True),\n",
    "    }\n",
    "\n",
    "def meta_model_optuna_study_objective(trial):\n",
    "    # get tuned hyperparameters for meta model\n",
    "    meta_model_params = get_meta_model_optuna_params(trial)\n",
    "\n",
    "    optuna_trial_step_num = 0 # for pruning trials\n",
    "\n",
    "    meta_skf = StratifiedKFold(n_splits=META_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=RANDOM_SEEDS[0])\n",
    "    meta_skf_splits = meta_skf.split(base_model_train_preds, train_data[target_col])\n",
    "    meta_skf_enumeration = enumerate(meta_skf_splits)\n",
    "\n",
    "    meta_oof_preds = np.zeros(len(train_data))\n",
    "\n",
    "    for fold, (train_indices, validation_indices) in meta_skf_enumeration:\n",
    "        X_train_fold = base_model_train_preds.iloc[train_indices]\n",
    "        y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "        X_validation_fold = base_model_train_preds.iloc[validation_indices]\n",
    "        y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "        model = lgb.LGBMClassifier(\n",
    "            **meta_model_params,\n",
    "            n_estimators=10000,\n",
    "            objective='binary',\n",
    "            metric='auc',\n",
    "            bagging_freq=1,\n",
    "            monotone_constraints=[1]*len(base_model_train_preds.columns),\n",
    "            monotone_constraints_method='advanced',\n",
    "            verbose=-1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_validation_fold, y_validation_fold),\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=META_MODEL_EARLY_STOPPING_ROUNDS, verbose=0)]\n",
    "        )\n",
    "\n",
    "        y_validation_pred_proba = model.predict_proba(X_validation_fold)[:, 1]\n",
    "        meta_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "\n",
    "        roc_auc_fold = roc_auc_score(y_validation_fold, y_validation_pred_proba)\n",
    "        trial.report(roc_auc_fold, step=optuna_trial_step_num)\n",
    "        optuna_trial_step_num += 1\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return roc_auc_score(train_data[target_col], meta_oof_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "104fe035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T04:26:11.986186Z",
     "iopub.status.busy": "2025-12-31T04:26:11.985360Z",
     "iopub.status.idle": "2025-12-31T12:34:11.752912Z",
     "shell.execute_reply": "2025-12-31T12:34:11.751377Z"
    },
    "papermill": {
     "duration": 29279.787827,
     "end_time": "2025-12-31T12:34:11.754637",
     "exception": false,
     "start_time": "2025-12-31T04:26:11.966810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-12-31 04:26:11,991] A new study created in memory with name: no-name-83f58028-3831-47f0-9b9c-1939a636ba7d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started hyperparameter tuning for meta-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-31 04:27:46,289] Trial 0 finished with value: 0.729462134779344 and parameters: {'learning_rate': 0.019865100445249074, 'max_depth': 3, 'num_leaves': 87, 'min_child_samples': 234, 'min_split_gain': 2.8398130570052182, 'subsample': 0.8677755156588648, 'colsample_bytree': 0.5722204063490992, 'reg_alpha': 1.2528329214270404, 'reg_lambda': 81.16196894726981}. Best is trial 0 with value: 0.729462134779344.\n",
      "[I 2025-12-31 04:29:14,239] Trial 1 finished with value: 0.724693590744126 and parameters: {'learning_rate': 0.025364240306424, 'max_depth': 4, 'num_leaves': 99, 'min_child_samples': 246, 'min_split_gain': 0.03179903336861134, 'subsample': 0.8838767577743454, 'colsample_bytree': 0.7640180183044576, 'reg_alpha': 10.212692283044829, 'reg_lambda': 10.84983001521298}. Best is trial 0 with value: 0.729462134779344.\n",
      "[I 2025-12-31 04:31:17,008] Trial 2 finished with value: 0.7295043095080183 and parameters: {'learning_rate': 0.021819211679904724, 'max_depth': 3, 'num_leaves': 137, 'min_child_samples': 227, 'min_split_gain': 0.07449273373616866, 'subsample': 0.9302528657111045, 'colsample_bytree': 0.6227244261470322, 'reg_alpha': 4.699705068774112, 'reg_lambda': 229.45751831852633}. Best is trial 2 with value: 0.7295043095080183.\n",
      "[I 2025-12-31 04:33:42,236] Trial 3 finished with value: 0.7290569694502813 and parameters: {'learning_rate': 0.018132663275695064, 'max_depth': 3, 'num_leaves': 72, 'min_child_samples': 199, 'min_split_gain': 0.005563256018509768, 'subsample': 0.8242680608412906, 'colsample_bytree': 0.8038030725324183, 'reg_alpha': 1.8550156794025312, 'reg_lambda': 110.81442221418247}. Best is trial 2 with value: 0.7295043095080183.\n",
      "[I 2025-12-31 04:36:02,091] Trial 4 finished with value: 0.7291600552210343 and parameters: {'learning_rate': 0.02093565886785196, 'max_depth': 4, 'num_leaves': 105, 'min_child_samples': 209, 'min_split_gain': 0.1117390464244268, 'subsample': 0.9526123828768887, 'colsample_bytree': 0.8011412917846867, 'reg_alpha': 4.9078211265714975, 'reg_lambda': 15.32365871614311}. Best is trial 2 with value: 0.7295043095080183.\n",
      "[I 2025-12-31 04:37:53,705] Trial 5 finished with value: 0.7295389621748708 and parameters: {'learning_rate': 0.033462297306463135, 'max_depth': 6, 'num_leaves': 135, 'min_child_samples': 218, 'min_split_gain': 0.6953613090638021, 'subsample': 0.9704172179696724, 'colsample_bytree': 0.8614167078308603, 'reg_alpha': 4.082330867201149, 'reg_lambda': 136.5150739356614}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:39:29,563] Trial 6 finished with value: 0.7276322377918678 and parameters: {'learning_rate': 0.021188818075195494, 'max_depth': 5, 'num_leaves': 79, 'min_child_samples': 194, 'min_split_gain': 0.14955546839994055, 'subsample': 0.9282341052582992, 'colsample_bytree': 0.8729424580099504, 'reg_alpha': 1.0069043450086175, 'reg_lambda': 15.514890872842054}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:41:18,130] Trial 7 finished with value: 0.7295353052433544 and parameters: {'learning_rate': 0.026297457745646926, 'max_depth': 5, 'num_leaves': 82, 'min_child_samples': 206, 'min_split_gain': 0.0015568667230661433, 'subsample': 0.8122140917843907, 'colsample_bytree': 0.79572444301293, 'reg_alpha': 9.753417324375407, 'reg_lambda': 42.06127455069096}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:41:45,544] Trial 8 pruned. \n",
      "[I 2025-12-31 04:43:02,944] Trial 9 pruned. \n",
      "[I 2025-12-31 04:44:43,908] Trial 10 finished with value: 0.7295060212343467 and parameters: {'learning_rate': 0.029885037575861504, 'max_depth': 6, 'num_leaves': 124, 'min_child_samples': 210, 'min_split_gain': 1.3864402911260376, 'subsample': 0.9911145274093085, 'colsample_bytree': 0.8730181557704613, 'reg_alpha': 6.340458566673922, 'reg_lambda': 58.50885839727272}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:46:44,539] Trial 11 finished with value: 0.7260411019642752 and parameters: {'learning_rate': 0.02557666690001509, 'max_depth': 6, 'num_leaves': 80, 'min_child_samples': 178, 'min_split_gain': 0.00687163845484627, 'subsample': 0.8620189455180952, 'colsample_bytree': 0.8932232892128349, 'reg_alpha': 7.429062594632404, 'reg_lambda': 43.06087239141959}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:48:09,288] Trial 12 pruned. \n",
      "[I 2025-12-31 04:49:10,263] Trial 13 pruned. \n",
      "[I 2025-12-31 04:49:33,438] Trial 14 pruned. \n",
      "[I 2025-12-31 04:50:39,077] Trial 15 pruned. \n",
      "[I 2025-12-31 04:52:34,707] Trial 16 finished with value: 0.7295362636957143 and parameters: {'learning_rate': 0.025802113919236383, 'max_depth': 5, 'num_leaves': 97, 'min_child_samples': 214, 'min_split_gain': 0.001084866224198568, 'subsample': 0.8734799258985306, 'colsample_bytree': 0.783413491251462, 'reg_alpha': 17.584758363708083, 'reg_lambda': 50.21913146842691}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:53:03,540] Trial 17 pruned. \n",
      "[I 2025-12-31 04:54:38,473] Trial 18 finished with value: 0.7285220961195313 and parameters: {'learning_rate': 0.03344968940824624, 'max_depth': 6, 'num_leaves': 126, 'min_child_samples': 214, 'min_split_gain': 0.19453758528969464, 'subsample': 0.8915515601191216, 'colsample_bytree': 0.8976144647029086, 'reg_alpha': 3.687233465969342, 'reg_lambda': 35.18282469139704}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:55:17,831] Trial 19 pruned. \n",
      "[I 2025-12-31 04:56:52,432] Trial 20 finished with value: 0.7258221350694208 and parameters: {'learning_rate': 0.028355608148756446, 'max_depth': 6, 'num_leaves': 111, 'min_child_samples': 217, 'min_split_gain': 0.0016330650940120939, 'subsample': 0.9130792003399342, 'colsample_bytree': 0.7639279586853744, 'reg_alpha': 11.209921828847866, 'reg_lambda': 32.404222809967266}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 04:57:16,310] Trial 21 pruned. \n",
      "[I 2025-12-31 04:57:35,656] Trial 22 pruned. \n",
      "[I 2025-12-31 04:57:54,873] Trial 23 pruned. \n",
      "[I 2025-12-31 04:58:12,696] Trial 24 pruned. \n",
      "[I 2025-12-31 04:58:34,742] Trial 25 pruned. \n",
      "[I 2025-12-31 04:58:56,171] Trial 26 pruned. \n",
      "[I 2025-12-31 04:59:42,273] Trial 27 pruned. \n",
      "[I 2025-12-31 05:00:11,757] Trial 28 pruned. \n",
      "[I 2025-12-31 05:00:30,281] Trial 29 pruned. \n",
      "[I 2025-12-31 05:02:27,756] Trial 30 finished with value: 0.7295347299946258 and parameters: {'learning_rate': 0.02695454874753494, 'max_depth': 5, 'num_leaves': 133, 'min_child_samples': 235, 'min_split_gain': 0.08161092416903501, 'subsample': 0.9967081522989595, 'colsample_bytree': 0.8298105208011085, 'reg_alpha': 7.501871182708871, 'reg_lambda': 96.17980735010845}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:03:00,029] Trial 31 pruned. \n",
      "[I 2025-12-31 05:03:34,484] Trial 32 pruned. \n",
      "[I 2025-12-31 05:04:07,865] Trial 33 pruned. \n",
      "[I 2025-12-31 05:04:29,656] Trial 34 pruned. \n",
      "[I 2025-12-31 05:04:52,425] Trial 35 pruned. \n",
      "[I 2025-12-31 05:05:54,135] Trial 36 pruned. \n",
      "[I 2025-12-31 05:06:24,091] Trial 37 pruned. \n",
      "[I 2025-12-31 05:06:49,530] Trial 38 pruned. \n",
      "[I 2025-12-31 05:07:16,078] Trial 39 pruned. \n",
      "[I 2025-12-31 05:07:35,215] Trial 40 pruned. \n",
      "[I 2025-12-31 05:07:49,819] Trial 41 pruned. \n",
      "[I 2025-12-31 05:08:25,587] Trial 42 pruned. \n",
      "[I 2025-12-31 05:08:47,740] Trial 43 pruned. \n",
      "[I 2025-12-31 05:09:44,448] Trial 44 pruned. \n",
      "[I 2025-12-31 05:10:06,801] Trial 45 pruned. \n",
      "[I 2025-12-31 05:10:25,450] Trial 46 pruned. \n",
      "[I 2025-12-31 05:10:50,780] Trial 47 pruned. \n",
      "[I 2025-12-31 05:11:13,526] Trial 48 pruned. \n",
      "[I 2025-12-31 05:11:36,231] Trial 49 pruned. \n",
      "[I 2025-12-31 05:11:57,517] Trial 50 pruned. \n",
      "[I 2025-12-31 05:12:24,385] Trial 51 pruned. \n",
      "[I 2025-12-31 05:13:15,068] Trial 52 pruned. \n",
      "[I 2025-12-31 05:13:34,958] Trial 53 pruned. \n",
      "[I 2025-12-31 05:14:06,755] Trial 54 pruned. \n",
      "[I 2025-12-31 05:14:37,467] Trial 55 pruned. \n",
      "[I 2025-12-31 05:15:01,015] Trial 56 pruned. \n",
      "[I 2025-12-31 05:15:29,331] Trial 57 pruned. \n",
      "[I 2025-12-31 05:15:54,574] Trial 58 pruned. \n",
      "[I 2025-12-31 05:16:23,620] Trial 59 pruned. \n",
      "[I 2025-12-31 05:18:13,875] Trial 60 finished with value: 0.7279947475015988 and parameters: {'learning_rate': 0.017407044301853712, 'max_depth': 5, 'num_leaves': 90, 'min_child_samples': 195, 'min_split_gain': 0.008135541094588502, 'subsample': 0.8199985854949343, 'colsample_bytree': 0.7843476475715762, 'reg_alpha': 6.374503918733009, 'reg_lambda': 38.00610138306471}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:18:33,502] Trial 61 pruned. \n",
      "[I 2025-12-31 05:18:57,276] Trial 62 pruned. \n",
      "[I 2025-12-31 05:19:19,687] Trial 63 pruned. \n",
      "[I 2025-12-31 05:19:42,682] Trial 64 pruned. \n",
      "[I 2025-12-31 05:20:03,284] Trial 65 pruned. \n",
      "[I 2025-12-31 05:20:21,687] Trial 66 pruned. \n",
      "[I 2025-12-31 05:20:54,707] Trial 67 pruned. \n",
      "[I 2025-12-31 05:21:23,209] Trial 68 pruned. \n",
      "[I 2025-12-31 05:21:47,787] Trial 69 pruned. \n",
      "[I 2025-12-31 05:23:21,287] Trial 70 finished with value: 0.7262687640735586 and parameters: {'learning_rate': 0.023551472470432974, 'max_depth': 6, 'num_leaves': 71, 'min_child_samples': 210, 'min_split_gain': 0.0014495844306404116, 'subsample': 0.8105227349463755, 'colsample_bytree': 0.7314592725354478, 'reg_alpha': 7.842717163091137, 'reg_lambda': 16.21610644561049}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:23:37,737] Trial 71 pruned. \n",
      "[I 2025-12-31 05:23:57,046] Trial 72 pruned. \n",
      "[I 2025-12-31 05:24:38,690] Trial 73 pruned. \n",
      "[I 2025-12-31 05:25:01,623] Trial 74 pruned. \n",
      "[I 2025-12-31 05:25:17,284] Trial 75 pruned. \n",
      "[I 2025-12-31 05:25:38,990] Trial 76 pruned. \n",
      "[I 2025-12-31 05:25:56,630] Trial 77 pruned. \n",
      "[I 2025-12-31 05:26:09,137] Trial 78 pruned. \n",
      "[I 2025-12-31 05:26:38,210] Trial 79 pruned. \n",
      "[I 2025-12-31 05:27:11,050] Trial 80 pruned. \n",
      "[I 2025-12-31 05:27:38,100] Trial 81 pruned. \n",
      "[I 2025-12-31 05:28:09,447] Trial 82 pruned. \n",
      "[I 2025-12-31 05:28:43,985] Trial 83 pruned. \n",
      "[I 2025-12-31 05:29:28,414] Trial 84 pruned. \n",
      "[I 2025-12-31 05:29:55,341] Trial 85 pruned. \n",
      "[I 2025-12-31 05:30:14,115] Trial 86 pruned. \n",
      "[I 2025-12-31 05:30:53,556] Trial 87 pruned. \n",
      "[I 2025-12-31 05:31:24,059] Trial 88 pruned. \n",
      "[I 2025-12-31 05:31:50,572] Trial 89 pruned. \n",
      "[I 2025-12-31 05:32:46,470] Trial 90 pruned. \n",
      "[I 2025-12-31 05:34:13,298] Trial 91 finished with value: 0.7289282502092256 and parameters: {'learning_rate': 0.03183713279725201, 'max_depth': 6, 'num_leaves': 135, 'min_child_samples': 209, 'min_split_gain': 0.2656659007474192, 'subsample': 0.9012831107525263, 'colsample_bytree': 0.7580095016175534, 'reg_alpha': 3.4038841149863632, 'reg_lambda': 33.088678965905}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:35:28,982] Trial 92 finished with value: 0.7281289961290776 and parameters: {'learning_rate': 0.03350480286531151, 'max_depth': 6, 'num_leaves': 124, 'min_child_samples': 212, 'min_split_gain': 0.06337234965119946, 'subsample': 0.8950225888604307, 'colsample_bytree': 0.6946222751664581, 'reg_alpha': 1.599612384059841, 'reg_lambda': 14.91845181268933}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:35:46,367] Trial 93 pruned. \n",
      "[I 2025-12-31 05:36:07,447] Trial 94 pruned. \n",
      "[I 2025-12-31 05:37:09,478] Trial 95 pruned. \n",
      "[I 2025-12-31 05:37:41,893] Trial 96 pruned. \n",
      "[I 2025-12-31 05:38:04,670] Trial 97 pruned. \n",
      "[I 2025-12-31 05:38:32,574] Trial 98 pruned. \n",
      "[I 2025-12-31 05:38:56,698] Trial 99 pruned. \n",
      "[I 2025-12-31 05:39:29,193] Trial 100 pruned. \n",
      "[I 2025-12-31 05:41:03,654] Trial 101 finished with value: 0.7286779491337754 and parameters: {'learning_rate': 0.03265753128383071, 'max_depth': 6, 'num_leaves': 118, 'min_child_samples': 245, 'min_split_gain': 0.4796183437107249, 'subsample': 0.8938044813003296, 'colsample_bytree': 0.8643474864193559, 'reg_alpha': 2.3605156283076663, 'reg_lambda': 20.61046502255758}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:41:17,998] Trial 102 pruned. \n",
      "[I 2025-12-31 05:42:55,996] Trial 103 finished with value: 0.7292490603400132 and parameters: {'learning_rate': 0.03206585244266557, 'max_depth': 6, 'num_leaves': 114, 'min_child_samples': 232, 'min_split_gain': 0.04830209672964402, 'subsample': 0.9081800504758121, 'colsample_bytree': 0.8104900971969001, 'reg_alpha': 2.261875326633541, 'reg_lambda': 51.04788217749869}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:43:25,673] Trial 104 pruned. \n",
      "[I 2025-12-31 05:44:19,208] Trial 105 pruned. \n",
      "[I 2025-12-31 05:44:42,359] Trial 106 pruned. \n",
      "[I 2025-12-31 05:46:11,057] Trial 107 finished with value: 0.7265429913996756 and parameters: {'learning_rate': 0.02927799548952265, 'max_depth': 6, 'num_leaves': 133, 'min_child_samples': 244, 'min_split_gain': 0.14507612987878457, 'subsample': 0.8976912834338535, 'colsample_bytree': 0.6467487540197109, 'reg_alpha': 2.7025222666428523, 'reg_lambda': 43.92309885293913}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:46:27,963] Trial 108 pruned. \n",
      "[I 2025-12-31 05:46:48,594] Trial 109 pruned. \n",
      "[I 2025-12-31 05:47:17,976] Trial 110 pruned. \n",
      "[I 2025-12-31 05:48:21,663] Trial 111 pruned. \n",
      "[I 2025-12-31 05:48:42,875] Trial 112 pruned. \n",
      "[I 2025-12-31 05:49:57,065] Trial 113 finished with value: 0.7281914615500135 and parameters: {'learning_rate': 0.03444151601686363, 'max_depth': 5, 'num_leaves': 130, 'min_child_samples': 226, 'min_split_gain': 0.3270273936186103, 'subsample': 0.8541965373265403, 'colsample_bytree': 0.8705918789814395, 'reg_alpha': 2.418636535428601, 'reg_lambda': 11.370237302464801}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:50:55,121] Trial 114 pruned. \n",
      "[I 2025-12-31 05:51:30,746] Trial 115 pruned. \n",
      "[I 2025-12-31 05:52:06,183] Trial 116 pruned. \n",
      "[I 2025-12-31 05:53:01,105] Trial 117 pruned. \n",
      "[I 2025-12-31 05:53:27,965] Trial 118 pruned. \n",
      "[I 2025-12-31 05:53:56,525] Trial 119 pruned. \n",
      "[I 2025-12-31 05:55:00,760] Trial 120 pruned. \n",
      "[I 2025-12-31 05:55:20,086] Trial 121 pruned. \n",
      "[I 2025-12-31 05:55:44,802] Trial 122 pruned. \n",
      "[I 2025-12-31 05:56:28,869] Trial 123 pruned. \n",
      "[I 2025-12-31 05:56:58,576] Trial 124 pruned. \n",
      "[I 2025-12-31 05:57:17,674] Trial 125 pruned. \n",
      "[I 2025-12-31 05:58:48,742] Trial 126 finished with value: 0.7293865179502343 and parameters: {'learning_rate': 0.03318017988831692, 'max_depth': 6, 'num_leaves': 112, 'min_child_samples': 204, 'min_split_gain': 0.9989464505603058, 'subsample': 0.8997314791137516, 'colsample_bytree': 0.8499916201011521, 'reg_alpha': 4.937362142935624, 'reg_lambda': 57.52942991447027}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 05:59:12,379] Trial 127 pruned. \n",
      "[I 2025-12-31 05:59:34,936] Trial 128 pruned. \n",
      "[I 2025-12-31 05:59:50,076] Trial 129 pruned. \n",
      "[I 2025-12-31 06:00:42,698] Trial 130 pruned. \n",
      "[I 2025-12-31 06:00:59,693] Trial 131 pruned. \n",
      "[I 2025-12-31 06:01:31,884] Trial 132 pruned. \n",
      "[I 2025-12-31 06:01:57,940] Trial 133 pruned. \n",
      "[I 2025-12-31 06:02:13,995] Trial 134 pruned. \n",
      "[I 2025-12-31 06:02:27,989] Trial 135 pruned. \n",
      "[I 2025-12-31 06:02:47,139] Trial 136 pruned. \n",
      "[I 2025-12-31 06:03:06,595] Trial 137 pruned. \n",
      "[I 2025-12-31 06:03:41,025] Trial 138 pruned. \n",
      "[I 2025-12-31 06:04:40,173] Trial 139 pruned. \n",
      "[I 2025-12-31 06:04:56,012] Trial 140 pruned. \n",
      "[I 2025-12-31 06:05:24,395] Trial 141 pruned. \n",
      "[I 2025-12-31 06:06:58,485] Trial 142 finished with value: 0.7281093848392625 and parameters: {'learning_rate': 0.026846876406550278, 'max_depth': 5, 'num_leaves': 136, 'min_child_samples': 220, 'min_split_gain': 1.342532436895467, 'subsample': 0.8295741129760784, 'colsample_bytree': 0.8756662431480188, 'reg_alpha': 2.2892606861007048, 'reg_lambda': 11.11980532780002}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:07:24,022] Trial 143 pruned. \n",
      "[I 2025-12-31 06:07:47,736] Trial 144 pruned. \n",
      "[I 2025-12-31 06:09:21,187] Trial 145 finished with value: 0.7290749179485447 and parameters: {'learning_rate': 0.03216134966790249, 'max_depth': 5, 'num_leaves': 113, 'min_child_samples': 212, 'min_split_gain': 0.5207848198626779, 'subsample': 0.823006678897893, 'colsample_bytree': 0.8521606753334778, 'reg_alpha': 3.4660794553173337, 'reg_lambda': 15.140836888152814}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:09:39,949] Trial 146 pruned. \n",
      "[I 2025-12-31 06:11:24,855] Trial 147 finished with value: 0.7286402610374947 and parameters: {'learning_rate': 0.03032698930300214, 'max_depth': 6, 'num_leaves': 103, 'min_child_samples': 210, 'min_split_gain': 0.17700337436785604, 'subsample': 0.8237036622660424, 'colsample_bytree': 0.8818025200687494, 'reg_alpha': 2.91225484834681, 'reg_lambda': 11.52300118623236}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:13:03,624] Trial 148 finished with value: 0.7227503746114908 and parameters: {'learning_rate': 0.02586959803212824, 'max_depth': 6, 'num_leaves': 108, 'min_child_samples': 212, 'min_split_gain': 0.03734372561426473, 'subsample': 0.8598005441384134, 'colsample_bytree': 0.8477390432769119, 'reg_alpha': 4.308237994768501, 'reg_lambda': 14.796617519385997}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:13:48,187] Trial 149 pruned. \n",
      "[I 2025-12-31 06:15:15,641] Trial 150 finished with value: 0.7264913244629012 and parameters: {'learning_rate': 0.031045334307985797, 'max_depth': 6, 'num_leaves': 132, 'min_child_samples': 235, 'min_split_gain': 0.10896035085231454, 'subsample': 0.953899387392907, 'colsample_bytree': 0.8499992740777398, 'reg_alpha': 1.3396290793154804, 'reg_lambda': 10.700779726360878}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:15:32,250] Trial 151 pruned. \n",
      "[I 2025-12-31 06:15:49,819] Trial 152 pruned. \n",
      "[I 2025-12-31 06:16:05,943] Trial 153 pruned. \n",
      "[I 2025-12-31 06:16:32,588] Trial 154 pruned. \n",
      "[I 2025-12-31 06:17:34,690] Trial 155 pruned. \n",
      "[I 2025-12-31 06:17:51,724] Trial 156 pruned. \n",
      "[I 2025-12-31 06:18:22,893] Trial 157 pruned. \n",
      "[I 2025-12-31 06:19:46,088] Trial 158 finished with value: 0.7287892099544472 and parameters: {'learning_rate': 0.028009496303550346, 'max_depth': 5, 'num_leaves': 95, 'min_child_samples': 217, 'min_split_gain': 0.11708124745691602, 'subsample': 0.8021773267024701, 'colsample_bytree': 0.8499370140403786, 'reg_alpha': 5.248086250313676, 'reg_lambda': 13.639498167450906}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:20:04,413] Trial 159 pruned. \n",
      "[I 2025-12-31 06:21:05,811] Trial 160 pruned. \n",
      "[I 2025-12-31 06:21:23,216] Trial 161 pruned. \n",
      "[I 2025-12-31 06:21:49,404] Trial 162 pruned. \n",
      "[I 2025-12-31 06:22:04,817] Trial 163 pruned. \n",
      "[I 2025-12-31 06:22:27,327] Trial 164 pruned. \n",
      "[I 2025-12-31 06:22:55,682] Trial 165 pruned. \n",
      "[I 2025-12-31 06:23:19,056] Trial 166 pruned. \n",
      "[I 2025-12-31 06:23:58,499] Trial 167 pruned. \n",
      "[I 2025-12-31 06:24:25,334] Trial 168 pruned. \n",
      "[I 2025-12-31 06:25:18,075] Trial 169 pruned. \n",
      "[I 2025-12-31 06:26:09,429] Trial 170 pruned. \n",
      "[I 2025-12-31 06:27:14,229] Trial 171 pruned. \n",
      "[I 2025-12-31 06:27:29,575] Trial 172 pruned. \n",
      "[I 2025-12-31 06:28:28,584] Trial 173 pruned. \n",
      "[I 2025-12-31 06:28:49,144] Trial 174 pruned. \n",
      "[I 2025-12-31 06:29:12,644] Trial 175 pruned. \n",
      "[I 2025-12-31 06:29:45,201] Trial 176 pruned. \n",
      "[I 2025-12-31 06:31:06,357] Trial 177 finished with value: 0.728862793195904 and parameters: {'learning_rate': 0.0335175059640701, 'max_depth': 5, 'num_leaves': 123, 'min_child_samples': 218, 'min_split_gain': 0.7288206121422186, 'subsample': 0.8138391141924779, 'colsample_bytree': 0.8551005845268522, 'reg_alpha': 2.806866902161602, 'reg_lambda': 12.974396393263328}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:32:04,059] Trial 178 pruned. \n",
      "[I 2025-12-31 06:32:26,161] Trial 179 pruned. \n",
      "[I 2025-12-31 06:33:22,595] Trial 180 pruned. \n",
      "[I 2025-12-31 06:34:11,530] Trial 181 pruned. \n",
      "[I 2025-12-31 06:34:27,283] Trial 182 pruned. \n",
      "[I 2025-12-31 06:36:06,112] Trial 183 finished with value: 0.7292796846708227 and parameters: {'learning_rate': 0.030932167815173727, 'max_depth': 5, 'num_leaves': 108, 'min_child_samples': 205, 'min_split_gain': 0.31327742159592076, 'subsample': 0.8670024897538309, 'colsample_bytree': 0.8935457665639372, 'reg_alpha': 3.887032420296321, 'reg_lambda': 17.396688763424557}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:36:31,928] Trial 184 pruned. \n",
      "[I 2025-12-31 06:37:01,672] Trial 185 pruned. \n",
      "[I 2025-12-31 06:37:47,749] Trial 186 pruned. \n",
      "[I 2025-12-31 06:38:51,152] Trial 187 pruned. \n",
      "[I 2025-12-31 06:39:10,070] Trial 188 pruned. \n",
      "[I 2025-12-31 06:39:38,185] Trial 189 pruned. \n",
      "[I 2025-12-31 06:40:09,982] Trial 190 pruned. \n",
      "[I 2025-12-31 06:40:42,723] Trial 191 pruned. \n",
      "[I 2025-12-31 06:41:00,323] Trial 192 pruned. \n",
      "[I 2025-12-31 06:41:18,457] Trial 193 pruned. \n",
      "[I 2025-12-31 06:42:54,868] Trial 194 finished with value: 0.7269650720556706 and parameters: {'learning_rate': 0.03162260411212226, 'max_depth': 5, 'num_leaves': 127, 'min_child_samples': 213, 'min_split_gain': 0.16633735344342493, 'subsample': 0.872357326994891, 'colsample_bytree': 0.8676059017542589, 'reg_alpha': 4.444783520308375, 'reg_lambda': 19.74357563732191}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:43:19,119] Trial 195 pruned. \n",
      "[I 2025-12-31 06:43:39,773] Trial 196 pruned. \n",
      "[I 2025-12-31 06:44:10,218] Trial 197 pruned. \n",
      "[I 2025-12-31 06:44:28,350] Trial 198 pruned. \n",
      "[I 2025-12-31 06:44:44,549] Trial 199 pruned. \n",
      "[I 2025-12-31 06:46:15,362] Trial 200 finished with value: 0.7293304777263524 and parameters: {'learning_rate': 0.033815070460450486, 'max_depth': 5, 'num_leaves': 112, 'min_child_samples': 248, 'min_split_gain': 0.1004036645257747, 'subsample': 0.9023396741057054, 'colsample_bytree': 0.8660400870808888, 'reg_alpha': 2.3549753105793325, 'reg_lambda': 20.110339333928714}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:46:30,073] Trial 201 pruned. \n",
      "[I 2025-12-31 06:47:03,065] Trial 202 pruned. \n",
      "[I 2025-12-31 06:47:59,464] Trial 203 pruned. \n",
      "[I 2025-12-31 06:48:13,974] Trial 204 pruned. \n",
      "[I 2025-12-31 06:48:28,408] Trial 205 pruned. \n",
      "[I 2025-12-31 06:48:42,906] Trial 206 pruned. \n",
      "[I 2025-12-31 06:49:10,261] Trial 207 pruned. \n",
      "[I 2025-12-31 06:49:36,355] Trial 208 pruned. \n",
      "[I 2025-12-31 06:51:18,889] Trial 209 finished with value: 0.728016431479084 and parameters: {'learning_rate': 0.03222905881924594, 'max_depth': 5, 'num_leaves': 109, 'min_child_samples': 248, 'min_split_gain': 0.05029535693041412, 'subsample': 0.9150072625474057, 'colsample_bytree': 0.8715020198536746, 'reg_alpha': 2.960774579474168, 'reg_lambda': 24.46839913626578}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:51:35,542] Trial 210 pruned. \n",
      "[I 2025-12-31 06:53:06,376] Trial 211 finished with value: 0.728216881254436 and parameters: {'learning_rate': 0.03054188090233037, 'max_depth': 6, 'num_leaves': 91, 'min_child_samples': 194, 'min_split_gain': 0.07116958960938395, 'subsample': 0.8907872144311602, 'colsample_bytree': 0.8901951698996543, 'reg_alpha': 2.6264970069159155, 'reg_lambda': 10.367109610643176}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:54:31,460] Trial 212 finished with value: 0.7274832688837986 and parameters: {'learning_rate': 0.03434848362330355, 'max_depth': 5, 'num_leaves': 128, 'min_child_samples': 222, 'min_split_gain': 0.25868675716392037, 'subsample': 0.8727525698601413, 'colsample_bytree': 0.8940286834563661, 'reg_alpha': 3.0078310013916068, 'reg_lambda': 17.09773799749069}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:54:54,803] Trial 213 pruned. \n",
      "[I 2025-12-31 06:55:30,744] Trial 214 pruned. \n",
      "[I 2025-12-31 06:56:36,410] Trial 215 pruned. \n",
      "[I 2025-12-31 06:56:54,390] Trial 216 pruned. \n",
      "[I 2025-12-31 06:58:17,391] Trial 217 finished with value: 0.7293382689772518 and parameters: {'learning_rate': 0.03137733711029645, 'max_depth': 5, 'num_leaves': 135, 'min_child_samples': 213, 'min_split_gain': 0.06630886393774058, 'subsample': 0.8066969385336287, 'colsample_bytree': 0.8606408685699477, 'reg_alpha': 2.0650132348457775, 'reg_lambda': 11.780939181167804}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 06:58:59,616] Trial 218 pruned. \n",
      "[I 2025-12-31 06:59:29,558] Trial 219 pruned. \n",
      "[I 2025-12-31 06:59:46,341] Trial 220 pruned. \n",
      "[I 2025-12-31 07:00:18,386] Trial 221 pruned. \n",
      "[I 2025-12-31 07:00:37,370] Trial 222 pruned. \n",
      "[I 2025-12-31 07:01:07,724] Trial 223 pruned. \n",
      "[I 2025-12-31 07:01:38,639] Trial 224 pruned. \n",
      "[I 2025-12-31 07:01:59,579] Trial 225 pruned. \n",
      "[I 2025-12-31 07:02:20,623] Trial 226 pruned. \n",
      "[I 2025-12-31 07:02:44,366] Trial 227 pruned. \n",
      "[I 2025-12-31 07:02:59,981] Trial 228 pruned. \n",
      "[I 2025-12-31 07:03:23,837] Trial 229 pruned. \n",
      "[I 2025-12-31 07:03:59,593] Trial 230 pruned. \n",
      "[I 2025-12-31 07:04:15,629] Trial 231 pruned. \n",
      "[I 2025-12-31 07:05:09,858] Trial 232 pruned. \n",
      "[I 2025-12-31 07:05:32,059] Trial 233 pruned. \n",
      "[I 2025-12-31 07:06:55,048] Trial 234 finished with value: 0.7217605542902003 and parameters: {'learning_rate': 0.028839859153536127, 'max_depth': 5, 'num_leaves': 98, 'min_child_samples': 188, 'min_split_gain': 0.029268090782022742, 'subsample': 0.8777252772993681, 'colsample_bytree': 0.8832595756380035, 'reg_alpha': 3.7471947663355842, 'reg_lambda': 13.2273412786486}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:07:17,175] Trial 235 pruned. \n",
      "[I 2025-12-31 07:07:35,652] Trial 236 pruned. \n",
      "[I 2025-12-31 07:08:06,552] Trial 237 pruned. \n",
      "[I 2025-12-31 07:08:38,908] Trial 238 pruned. \n",
      "[I 2025-12-31 07:08:55,760] Trial 239 pruned. \n",
      "[I 2025-12-31 07:09:23,151] Trial 240 pruned. \n",
      "[I 2025-12-31 07:09:37,221] Trial 241 pruned. \n",
      "[I 2025-12-31 07:09:53,603] Trial 242 pruned. \n",
      "[I 2025-12-31 07:10:15,375] Trial 243 pruned. \n",
      "[I 2025-12-31 07:11:00,641] Trial 244 pruned. \n",
      "[I 2025-12-31 07:11:15,897] Trial 245 pruned. \n",
      "[I 2025-12-31 07:12:40,235] Trial 246 finished with value: 0.729507755229041 and parameters: {'learning_rate': 0.0318452997832287, 'max_depth': 5, 'num_leaves': 139, 'min_child_samples': 216, 'min_split_gain': 0.14157209319737826, 'subsample': 0.8033518861621227, 'colsample_bytree': 0.87644178862838, 'reg_alpha': 1.6540193375205712, 'reg_lambda': 11.615444688141373}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:12:55,115] Trial 247 pruned. \n",
      "[I 2025-12-31 07:13:12,421] Trial 248 pruned. \n",
      "[I 2025-12-31 07:13:29,782] Trial 249 pruned. \n",
      "[I 2025-12-31 07:13:48,085] Trial 250 pruned. \n",
      "[I 2025-12-31 07:14:44,608] Trial 251 pruned. \n",
      "[I 2025-12-31 07:16:07,007] Trial 252 finished with value: 0.7291415532469758 and parameters: {'learning_rate': 0.03011732813759218, 'max_depth': 6, 'num_leaves': 121, 'min_child_samples': 197, 'min_split_gain': 0.36022988712514215, 'subsample': 0.8998502156381329, 'colsample_bytree': 0.7075005155157761, 'reg_alpha': 1.6110392838602057, 'reg_lambda': 10.908974456940623}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:16:34,468] Trial 253 pruned. \n",
      "[I 2025-12-31 07:17:11,307] Trial 254 pruned. \n",
      "[I 2025-12-31 07:17:34,086] Trial 255 pruned. \n",
      "[I 2025-12-31 07:18:54,782] Trial 256 finished with value: 0.7291638388049669 and parameters: {'learning_rate': 0.03119416762068042, 'max_depth': 5, 'num_leaves': 133, 'min_child_samples': 206, 'min_split_gain': 0.0783330340642776, 'subsample': 0.820746239719758, 'colsample_bytree': 0.8792200079149887, 'reg_alpha': 1.4976971921408313, 'reg_lambda': 21.79227118108814}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:20:14,149] Trial 257 finished with value: 0.7282492083764138 and parameters: {'learning_rate': 0.030349507719178083, 'max_depth': 5, 'num_leaves': 126, 'min_child_samples': 210, 'min_split_gain': 0.17451279524117153, 'subsample': 0.8071890106041619, 'colsample_bytree': 0.7738587007873075, 'reg_alpha': 2.179564004423766, 'reg_lambda': 11.095144893346653}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:20:33,001] Trial 258 pruned. \n",
      "[I 2025-12-31 07:21:56,433] Trial 259 finished with value: 0.7285641870593511 and parameters: {'learning_rate': 0.026228719682529877, 'max_depth': 5, 'num_leaves': 129, 'min_child_samples': 218, 'min_split_gain': 0.015492069963685046, 'subsample': 0.8028251649286767, 'colsample_bytree': 0.8687376411188967, 'reg_alpha': 2.4640914537133027, 'reg_lambda': 16.91512535095984}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:22:25,438] Trial 260 pruned. \n",
      "[I 2025-12-31 07:22:56,316] Trial 261 pruned. \n",
      "[I 2025-12-31 07:23:24,615] Trial 262 pruned. \n",
      "[I 2025-12-31 07:23:40,866] Trial 263 pruned. \n",
      "[I 2025-12-31 07:24:00,073] Trial 264 pruned. \n",
      "[I 2025-12-31 07:24:15,559] Trial 265 pruned. \n",
      "[I 2025-12-31 07:24:31,921] Trial 266 pruned. \n",
      "[I 2025-12-31 07:24:47,103] Trial 267 pruned. \n",
      "[I 2025-12-31 07:25:03,605] Trial 268 pruned. \n",
      "[I 2025-12-31 07:25:21,285] Trial 269 pruned. \n",
      "[I 2025-12-31 07:25:38,750] Trial 270 pruned. \n",
      "[I 2025-12-31 07:25:59,775] Trial 271 pruned. \n",
      "[I 2025-12-31 07:26:24,934] Trial 272 pruned. \n",
      "[I 2025-12-31 07:26:51,958] Trial 273 pruned. \n",
      "[I 2025-12-31 07:27:22,629] Trial 274 pruned. \n",
      "[I 2025-12-31 07:27:48,588] Trial 275 pruned. \n",
      "[I 2025-12-31 07:28:41,244] Trial 276 pruned. \n",
      "[I 2025-12-31 07:28:59,887] Trial 277 pruned. \n",
      "[I 2025-12-31 07:29:25,251] Trial 278 pruned. \n",
      "[I 2025-12-31 07:29:52,941] Trial 279 pruned. \n",
      "[I 2025-12-31 07:30:16,234] Trial 280 pruned. \n",
      "[I 2025-12-31 07:31:37,552] Trial 281 finished with value: 0.7225272132457217 and parameters: {'learning_rate': 0.02915282841406771, 'max_depth': 6, 'num_leaves': 116, 'min_child_samples': 188, 'min_split_gain': 0.07739932503871798, 'subsample': 0.9435374565034889, 'colsample_bytree': 0.7578048131674506, 'reg_alpha': 1.373127215349251, 'reg_lambda': 10.445328719896953}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:31:52,767] Trial 282 pruned. \n",
      "[I 2025-12-31 07:32:27,948] Trial 283 pruned. \n",
      "[I 2025-12-31 07:32:57,973] Trial 284 pruned. \n",
      "[I 2025-12-31 07:33:13,294] Trial 285 pruned. \n",
      "[I 2025-12-31 07:33:36,622] Trial 286 pruned. \n",
      "[I 2025-12-31 07:33:57,516] Trial 287 pruned. \n",
      "[I 2025-12-31 07:34:12,620] Trial 288 pruned. \n",
      "[I 2025-12-31 07:34:45,477] Trial 289 pruned. \n",
      "[I 2025-12-31 07:35:00,320] Trial 290 pruned. \n",
      "[I 2025-12-31 07:35:53,786] Trial 291 pruned. \n",
      "[I 2025-12-31 07:36:27,358] Trial 292 pruned. \n",
      "[I 2025-12-31 07:36:53,134] Trial 293 pruned. \n",
      "[I 2025-12-31 07:37:15,991] Trial 294 pruned. \n",
      "[I 2025-12-31 07:37:44,506] Trial 295 pruned. \n",
      "[I 2025-12-31 07:38:03,168] Trial 296 pruned. \n",
      "[I 2025-12-31 07:38:18,997] Trial 297 pruned. \n",
      "[I 2025-12-31 07:38:33,519] Trial 298 pruned. \n",
      "[I 2025-12-31 07:39:28,434] Trial 299 pruned. \n",
      "[I 2025-12-31 07:39:49,170] Trial 300 pruned. \n",
      "[I 2025-12-31 07:40:12,265] Trial 301 pruned. \n",
      "[I 2025-12-31 07:40:40,447] Trial 302 pruned. \n",
      "[I 2025-12-31 07:40:56,063] Trial 303 pruned. \n",
      "[I 2025-12-31 07:41:52,518] Trial 304 pruned. \n",
      "[I 2025-12-31 07:42:14,191] Trial 305 pruned. \n",
      "[I 2025-12-31 07:42:32,599] Trial 306 pruned. \n",
      "[I 2025-12-31 07:42:46,727] Trial 307 pruned. \n",
      "[I 2025-12-31 07:43:02,709] Trial 308 pruned. \n",
      "[I 2025-12-31 07:43:26,918] Trial 309 pruned. \n",
      "[I 2025-12-31 07:43:51,473] Trial 310 pruned. \n",
      "[I 2025-12-31 07:44:07,258] Trial 311 pruned. \n",
      "[I 2025-12-31 07:45:39,506] Trial 312 finished with value: 0.7282288373807057 and parameters: {'learning_rate': 0.03362440016416883, 'max_depth': 6, 'num_leaves': 118, 'min_child_samples': 197, 'min_split_gain': 0.39655997904192364, 'subsample': 0.9134084962180021, 'colsample_bytree': 0.8829347990801198, 'reg_alpha': 6.77649086360468, 'reg_lambda': 19.606832622117036}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:46:29,804] Trial 313 pruned. \n",
      "[I 2025-12-31 07:47:00,174] Trial 314 pruned. \n",
      "[I 2025-12-31 07:47:32,722] Trial 315 pruned. \n",
      "[I 2025-12-31 07:47:50,959] Trial 316 pruned. \n",
      "[I 2025-12-31 07:48:15,146] Trial 317 pruned. \n",
      "[I 2025-12-31 07:48:29,586] Trial 318 pruned. \n",
      "[I 2025-12-31 07:49:02,886] Trial 319 pruned. \n",
      "[I 2025-12-31 07:49:24,459] Trial 320 pruned. \n",
      "[I 2025-12-31 07:50:47,038] Trial 321 finished with value: 0.7224874479681158 and parameters: {'learning_rate': 0.034109041296737246, 'max_depth': 5, 'num_leaves': 91, 'min_child_samples': 238, 'min_split_gain': 0.09158365228111912, 'subsample': 0.9509294956422363, 'colsample_bytree': 0.8717681728388865, 'reg_alpha': 3.476355171958339, 'reg_lambda': 11.485695709855051}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:51:10,360] Trial 322 pruned. \n",
      "[I 2025-12-31 07:51:31,268] Trial 323 pruned. \n",
      "[I 2025-12-31 07:53:09,315] Trial 324 finished with value: 0.727764015195728 and parameters: {'learning_rate': 0.03415372752072161, 'max_depth': 5, 'num_leaves': 121, 'min_child_samples': 248, 'min_split_gain': 0.7087654509702893, 'subsample': 0.8915190193652592, 'colsample_bytree': 0.8678277045901774, 'reg_alpha': 2.1646527501500628, 'reg_lambda': 17.07077766825022}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 07:53:33,714] Trial 325 pruned. \n",
      "[I 2025-12-31 07:54:03,366] Trial 326 pruned. \n",
      "[I 2025-12-31 07:54:19,136] Trial 327 pruned. \n",
      "[I 2025-12-31 07:54:38,295] Trial 328 pruned. \n",
      "[I 2025-12-31 07:55:10,619] Trial 329 pruned. \n",
      "[I 2025-12-31 07:55:27,080] Trial 330 pruned. \n",
      "[I 2025-12-31 07:55:51,898] Trial 331 pruned. \n",
      "[I 2025-12-31 07:56:18,129] Trial 332 pruned. \n",
      "[I 2025-12-31 07:56:39,656] Trial 333 pruned. \n",
      "[I 2025-12-31 07:57:03,678] Trial 334 pruned. \n",
      "[I 2025-12-31 07:57:27,054] Trial 335 pruned. \n",
      "[I 2025-12-31 07:57:52,018] Trial 336 pruned. \n",
      "[I 2025-12-31 07:58:15,021] Trial 337 pruned. \n",
      "[I 2025-12-31 07:58:46,928] Trial 338 pruned. \n",
      "[I 2025-12-31 07:59:16,054] Trial 339 pruned. \n",
      "[I 2025-12-31 07:59:42,814] Trial 340 pruned. \n",
      "[I 2025-12-31 08:00:23,516] Trial 341 pruned. \n",
      "[I 2025-12-31 08:00:47,920] Trial 342 pruned. \n",
      "[I 2025-12-31 08:01:06,927] Trial 343 pruned. \n",
      "[I 2025-12-31 08:01:28,815] Trial 344 pruned. \n",
      "[I 2025-12-31 08:01:50,747] Trial 345 pruned. \n",
      "[I 2025-12-31 08:02:23,250] Trial 346 pruned. \n",
      "[I 2025-12-31 08:02:44,537] Trial 347 pruned. \n",
      "[I 2025-12-31 08:03:07,918] Trial 348 pruned. \n",
      "[I 2025-12-31 08:03:21,426] Trial 349 pruned. \n",
      "[I 2025-12-31 08:04:52,653] Trial 350 finished with value: 0.7254121728284502 and parameters: {'learning_rate': 0.027160844885483884, 'max_depth': 6, 'num_leaves': 109, 'min_child_samples': 212, 'min_split_gain': 1.3559597583563565, 'subsample': 0.9067190776349942, 'colsample_bytree': 0.7290732397725299, 'reg_alpha': 2.597153393650173, 'reg_lambda': 13.578245331766682}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 08:05:12,230] Trial 351 pruned. \n",
      "[I 2025-12-31 08:05:31,421] Trial 352 pruned. \n",
      "[I 2025-12-31 08:05:47,178] Trial 353 pruned. \n",
      "[I 2025-12-31 08:06:15,966] Trial 354 pruned. \n",
      "[I 2025-12-31 08:06:53,820] Trial 355 pruned. \n",
      "[I 2025-12-31 08:08:20,817] Trial 356 finished with value: 0.7283166167834779 and parameters: {'learning_rate': 0.029803752924478517, 'max_depth': 5, 'num_leaves': 104, 'min_child_samples': 214, 'min_split_gain': 0.12159941464104783, 'subsample': 0.8006682842586805, 'colsample_bytree': 0.8670077689070957, 'reg_alpha': 5.213255019274946, 'reg_lambda': 18.549514965184606}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 08:09:07,883] Trial 357 pruned. \n",
      "[I 2025-12-31 08:09:23,066] Trial 358 pruned. \n",
      "[I 2025-12-31 08:09:56,022] Trial 359 pruned. \n",
      "[I 2025-12-31 08:10:12,799] Trial 360 pruned. \n",
      "[I 2025-12-31 08:11:47,207] Trial 361 finished with value: 0.7285352377885548 and parameters: {'learning_rate': 0.03211626331126334, 'max_depth': 6, 'num_leaves': 140, 'min_child_samples': 219, 'min_split_gain': 0.06362939515486774, 'subsample': 0.8268586691813734, 'colsample_bytree': 0.8666974249345523, 'reg_alpha': 3.1574717911684527, 'reg_lambda': 11.350329293664199}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 08:12:12,357] Trial 362 pruned. \n",
      "[I 2025-12-31 08:12:36,357] Trial 363 pruned. \n",
      "[I 2025-12-31 08:12:54,132] Trial 364 pruned. \n",
      "[I 2025-12-31 08:13:39,804] Trial 365 pruned. \n",
      "[I 2025-12-31 08:13:56,194] Trial 366 pruned. \n",
      "[I 2025-12-31 08:14:27,199] Trial 367 pruned. \n",
      "[I 2025-12-31 08:14:42,953] Trial 368 pruned. \n",
      "[I 2025-12-31 08:14:57,421] Trial 369 pruned. \n",
      "[I 2025-12-31 08:15:12,843] Trial 370 pruned. \n",
      "[I 2025-12-31 08:15:28,111] Trial 371 pruned. \n",
      "[I 2025-12-31 08:15:54,681] Trial 372 pruned. \n",
      "[I 2025-12-31 08:16:26,929] Trial 373 pruned. \n",
      "[I 2025-12-31 08:16:42,334] Trial 374 pruned. \n",
      "[I 2025-12-31 08:17:35,985] Trial 375 pruned. \n",
      "[I 2025-12-31 08:18:09,841] Trial 376 pruned. \n",
      "[I 2025-12-31 08:18:41,148] Trial 377 pruned. \n",
      "[I 2025-12-31 08:19:47,657] Trial 378 pruned. \n",
      "[I 2025-12-31 08:20:05,904] Trial 379 pruned. \n",
      "[I 2025-12-31 08:20:38,509] Trial 380 pruned. \n",
      "[I 2025-12-31 08:21:05,271] Trial 381 pruned. \n",
      "[I 2025-12-31 08:21:26,436] Trial 382 pruned. \n",
      "[I 2025-12-31 08:21:43,382] Trial 383 pruned. \n",
      "[I 2025-12-31 08:22:02,429] Trial 384 pruned. \n",
      "[I 2025-12-31 08:22:36,285] Trial 385 pruned. \n",
      "[I 2025-12-31 08:22:54,220] Trial 386 pruned. \n",
      "[I 2025-12-31 08:23:11,332] Trial 387 pruned. \n",
      "[I 2025-12-31 08:23:43,418] Trial 388 pruned. \n",
      "[I 2025-12-31 08:24:22,474] Trial 389 pruned. \n",
      "[I 2025-12-31 08:24:42,388] Trial 390 pruned. \n",
      "[I 2025-12-31 08:26:20,201] Trial 391 finished with value: 0.7279760741037147 and parameters: {'learning_rate': 0.029812670152906073, 'max_depth': 6, 'num_leaves': 120, 'min_child_samples': 235, 'min_split_gain': 1.352427652318269, 'subsample': 0.8828440878081786, 'colsample_bytree': 0.8136575961098403, 'reg_alpha': 1.9286086301868588, 'reg_lambda': 19.760811255136304}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 08:26:34,644] Trial 392 pruned. \n",
      "[I 2025-12-31 08:27:03,691] Trial 393 pruned. \n",
      "[I 2025-12-31 08:27:30,668] Trial 394 pruned. \n",
      "[I 2025-12-31 08:27:51,497] Trial 395 pruned. \n",
      "[I 2025-12-31 08:28:16,372] Trial 396 pruned. \n",
      "[I 2025-12-31 08:28:45,810] Trial 397 pruned. \n",
      "[I 2025-12-31 08:29:13,748] Trial 398 pruned. \n",
      "[I 2025-12-31 08:29:44,587] Trial 399 pruned. \n",
      "[I 2025-12-31 08:30:07,118] Trial 400 pruned. \n",
      "[I 2025-12-31 08:30:27,461] Trial 401 pruned. \n",
      "[I 2025-12-31 08:30:56,773] Trial 402 pruned. \n",
      "[I 2025-12-31 08:31:17,546] Trial 403 pruned. \n",
      "[I 2025-12-31 08:31:50,406] Trial 404 pruned. \n",
      "[I 2025-12-31 08:32:21,919] Trial 405 pruned. \n",
      "[I 2025-12-31 08:32:49,627] Trial 406 pruned. \n",
      "[I 2025-12-31 08:33:23,997] Trial 407 pruned. \n",
      "[I 2025-12-31 08:33:47,785] Trial 408 pruned. \n",
      "[I 2025-12-31 08:34:04,712] Trial 409 pruned. \n",
      "[I 2025-12-31 08:34:31,271] Trial 410 pruned. \n",
      "[I 2025-12-31 08:34:50,894] Trial 411 pruned. \n",
      "[I 2025-12-31 08:35:09,823] Trial 412 pruned. \n",
      "[I 2025-12-31 08:35:24,640] Trial 413 pruned. \n",
      "[I 2025-12-31 08:35:42,178] Trial 414 pruned. \n",
      "[I 2025-12-31 08:35:54,010] Trial 415 pruned. \n",
      "[I 2025-12-31 08:36:19,876] Trial 416 pruned. \n",
      "[I 2025-12-31 08:36:51,186] Trial 417 pruned. \n",
      "[I 2025-12-31 08:37:23,772] Trial 418 pruned. \n",
      "[I 2025-12-31 08:37:38,436] Trial 419 pruned. \n",
      "[I 2025-12-31 08:38:08,806] Trial 420 pruned. \n",
      "[I 2025-12-31 08:38:38,563] Trial 421 pruned. \n",
      "[I 2025-12-31 08:39:07,591] Trial 422 pruned. \n",
      "[I 2025-12-31 08:39:39,523] Trial 423 pruned. \n",
      "[I 2025-12-31 08:39:58,015] Trial 424 pruned. \n",
      "[I 2025-12-31 08:40:12,469] Trial 425 pruned. \n",
      "[I 2025-12-31 08:40:41,616] Trial 426 pruned. \n",
      "[I 2025-12-31 08:42:12,770] Trial 427 finished with value: 0.7279469713924062 and parameters: {'learning_rate': 0.02794791174194299, 'max_depth': 6, 'num_leaves': 99, 'min_child_samples': 223, 'min_split_gain': 0.5076389899095118, 'subsample': 0.8286908531245383, 'colsample_bytree': 0.8733638775758683, 'reg_alpha': 2.163667239537706, 'reg_lambda': 11.061615770927157}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 08:42:28,603] Trial 428 pruned. \n",
      "[I 2025-12-31 08:42:43,261] Trial 429 pruned. \n",
      "[I 2025-12-31 08:43:00,064] Trial 430 pruned. \n",
      "[I 2025-12-31 08:43:21,244] Trial 431 pruned. \n",
      "[I 2025-12-31 08:43:56,044] Trial 432 pruned. \n",
      "[I 2025-12-31 08:44:22,461] Trial 433 pruned. \n",
      "[I 2025-12-31 08:45:02,032] Trial 434 pruned. \n",
      "[I 2025-12-31 08:45:15,407] Trial 435 pruned. \n",
      "[I 2025-12-31 08:45:36,116] Trial 436 pruned. \n",
      "[I 2025-12-31 08:45:55,316] Trial 437 pruned. \n",
      "[I 2025-12-31 08:46:27,106] Trial 438 pruned. \n",
      "[I 2025-12-31 08:46:57,346] Trial 439 pruned. \n",
      "[I 2025-12-31 08:47:28,419] Trial 440 pruned. \n",
      "[I 2025-12-31 08:47:52,749] Trial 441 pruned. \n",
      "[I 2025-12-31 08:48:13,466] Trial 442 pruned. \n",
      "[I 2025-12-31 08:48:27,329] Trial 443 pruned. \n",
      "[I 2025-12-31 08:48:43,537] Trial 444 pruned. \n",
      "[I 2025-12-31 08:49:11,028] Trial 445 pruned. \n",
      "[I 2025-12-31 08:49:42,437] Trial 446 pruned. \n",
      "[I 2025-12-31 08:49:57,815] Trial 447 pruned. \n",
      "[I 2025-12-31 08:50:28,217] Trial 448 pruned. \n",
      "[I 2025-12-31 08:51:07,718] Trial 449 pruned. \n",
      "[I 2025-12-31 08:52:40,403] Trial 450 finished with value: 0.7267982672514756 and parameters: {'learning_rate': 0.028463169160011202, 'max_depth': 6, 'num_leaves': 137, 'min_child_samples': 192, 'min_split_gain': 0.31979382023746095, 'subsample': 0.9066706787439567, 'colsample_bytree': 0.666841100570297, 'reg_alpha': 1.0399733776715494, 'reg_lambda': 10.89925740064851}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 08:53:14,095] Trial 451 pruned. \n",
      "[I 2025-12-31 08:53:46,897] Trial 452 pruned. \n",
      "[I 2025-12-31 08:54:07,194] Trial 453 pruned. \n",
      "[I 2025-12-31 08:54:29,991] Trial 454 pruned. \n",
      "[I 2025-12-31 08:54:53,023] Trial 455 pruned. \n",
      "[I 2025-12-31 08:55:10,454] Trial 456 pruned. \n",
      "[I 2025-12-31 08:55:38,807] Trial 457 pruned. \n",
      "[I 2025-12-31 08:56:00,044] Trial 458 pruned. \n",
      "[I 2025-12-31 08:56:32,410] Trial 459 pruned. \n",
      "[I 2025-12-31 08:57:04,656] Trial 460 pruned. \n",
      "[I 2025-12-31 08:57:18,794] Trial 461 pruned. \n",
      "[I 2025-12-31 08:57:43,456] Trial 462 pruned. \n",
      "[I 2025-12-31 08:57:55,683] Trial 463 pruned. \n",
      "[I 2025-12-31 08:58:17,278] Trial 464 pruned. \n",
      "[I 2025-12-31 08:58:31,366] Trial 465 pruned. \n",
      "[I 2025-12-31 08:58:57,891] Trial 466 pruned. \n",
      "[I 2025-12-31 08:59:32,872] Trial 467 pruned. \n",
      "[I 2025-12-31 08:59:51,724] Trial 468 pruned. \n",
      "[I 2025-12-31 09:00:20,879] Trial 469 pruned. \n",
      "[I 2025-12-31 09:00:37,418] Trial 470 pruned. \n",
      "[I 2025-12-31 09:00:58,646] Trial 471 pruned. \n",
      "[I 2025-12-31 09:01:37,785] Trial 472 pruned. \n",
      "[I 2025-12-31 09:02:00,144] Trial 473 pruned. \n",
      "[I 2025-12-31 09:02:16,860] Trial 474 pruned. \n",
      "[I 2025-12-31 09:02:40,150] Trial 475 pruned. \n",
      "[I 2025-12-31 09:03:03,862] Trial 476 pruned. \n",
      "[I 2025-12-31 09:03:25,625] Trial 477 pruned. \n",
      "[I 2025-12-31 09:04:21,868] Trial 478 pruned. \n",
      "[I 2025-12-31 09:04:38,290] Trial 479 pruned. \n",
      "[I 2025-12-31 09:04:55,472] Trial 480 pruned. \n",
      "[I 2025-12-31 09:05:10,557] Trial 481 pruned. \n",
      "[I 2025-12-31 09:05:28,027] Trial 482 pruned. \n",
      "[I 2025-12-31 09:05:43,148] Trial 483 pruned. \n",
      "[I 2025-12-31 09:05:58,746] Trial 484 pruned. \n",
      "[I 2025-12-31 09:06:13,895] Trial 485 pruned. \n",
      "[I 2025-12-31 09:06:33,310] Trial 486 pruned. \n",
      "[I 2025-12-31 09:06:56,097] Trial 487 pruned. \n",
      "[I 2025-12-31 09:07:25,960] Trial 488 pruned. \n",
      "[I 2025-12-31 09:07:48,905] Trial 489 pruned. \n",
      "[I 2025-12-31 09:08:08,140] Trial 490 pruned. \n",
      "[I 2025-12-31 09:08:34,983] Trial 491 pruned. \n",
      "[I 2025-12-31 09:08:52,960] Trial 492 pruned. \n",
      "[I 2025-12-31 09:09:25,490] Trial 493 pruned. \n",
      "[I 2025-12-31 09:09:39,851] Trial 494 pruned. \n",
      "[I 2025-12-31 09:09:55,171] Trial 495 pruned. \n",
      "[I 2025-12-31 09:10:12,417] Trial 496 pruned. \n",
      "[I 2025-12-31 09:11:08,127] Trial 497 pruned. \n",
      "[I 2025-12-31 09:11:44,632] Trial 498 pruned. \n",
      "[I 2025-12-31 09:12:03,333] Trial 499 pruned. \n",
      "[I 2025-12-31 09:12:23,669] Trial 500 pruned. \n",
      "[I 2025-12-31 09:12:46,022] Trial 501 pruned. \n",
      "[I 2025-12-31 09:13:04,259] Trial 502 pruned. \n",
      "[I 2025-12-31 09:13:19,199] Trial 503 pruned. \n",
      "[I 2025-12-31 09:13:35,083] Trial 504 pruned. \n",
      "[I 2025-12-31 09:14:19,253] Trial 505 pruned. \n",
      "[I 2025-12-31 09:14:47,850] Trial 506 pruned. \n",
      "[I 2025-12-31 09:15:08,864] Trial 507 pruned. \n",
      "[I 2025-12-31 09:15:23,249] Trial 508 pruned. \n",
      "[I 2025-12-31 09:15:41,763] Trial 509 pruned. \n",
      "[I 2025-12-31 09:16:01,461] Trial 510 pruned. \n",
      "[I 2025-12-31 09:16:16,100] Trial 511 pruned. \n",
      "[I 2025-12-31 09:16:55,221] Trial 512 pruned. \n",
      "[I 2025-12-31 09:17:10,527] Trial 513 pruned. \n",
      "[I 2025-12-31 09:17:43,217] Trial 514 pruned. \n",
      "[I 2025-12-31 09:18:16,454] Trial 515 pruned. \n",
      "[I 2025-12-31 09:18:49,523] Trial 516 pruned. \n",
      "[I 2025-12-31 09:19:40,231] Trial 517 pruned. \n",
      "[I 2025-12-31 09:19:56,620] Trial 518 pruned. \n",
      "[I 2025-12-31 09:20:19,562] Trial 519 pruned. \n",
      "[I 2025-12-31 09:20:51,116] Trial 520 pruned. \n",
      "[I 2025-12-31 09:21:07,290] Trial 521 pruned. \n",
      "[I 2025-12-31 09:21:46,793] Trial 522 pruned. \n",
      "[I 2025-12-31 09:22:04,738] Trial 523 pruned. \n",
      "[I 2025-12-31 09:22:21,514] Trial 524 pruned. \n",
      "[I 2025-12-31 09:22:54,382] Trial 525 pruned. \n",
      "[I 2025-12-31 09:23:08,473] Trial 526 pruned. \n",
      "[I 2025-12-31 09:23:41,624] Trial 527 pruned. \n",
      "[I 2025-12-31 09:23:58,409] Trial 528 pruned. \n",
      "[I 2025-12-31 09:24:17,702] Trial 529 pruned. \n",
      "[I 2025-12-31 09:24:36,323] Trial 530 pruned. \n",
      "[I 2025-12-31 09:24:58,041] Trial 531 pruned. \n",
      "[I 2025-12-31 09:25:14,848] Trial 532 pruned. \n",
      "[I 2025-12-31 09:25:31,485] Trial 533 pruned. \n",
      "[I 2025-12-31 09:26:30,741] Trial 534 pruned. \n",
      "[I 2025-12-31 09:26:55,446] Trial 535 pruned. \n",
      "[I 2025-12-31 09:27:11,783] Trial 536 pruned. \n",
      "[I 2025-12-31 09:27:27,831] Trial 537 pruned. \n",
      "[I 2025-12-31 09:28:07,194] Trial 538 pruned. \n",
      "[I 2025-12-31 09:28:22,476] Trial 539 pruned. \n",
      "[I 2025-12-31 09:28:36,508] Trial 540 pruned. \n",
      "[I 2025-12-31 09:29:24,672] Trial 541 pruned. \n",
      "[I 2025-12-31 09:29:49,452] Trial 542 pruned. \n",
      "[I 2025-12-31 09:30:09,803] Trial 543 pruned. \n",
      "[I 2025-12-31 09:30:32,364] Trial 544 pruned. \n",
      "[I 2025-12-31 09:31:05,842] Trial 545 pruned. \n",
      "[I 2025-12-31 09:31:40,944] Trial 546 pruned. \n",
      "[I 2025-12-31 09:32:11,897] Trial 547 pruned. \n",
      "[I 2025-12-31 09:32:26,914] Trial 548 pruned. \n",
      "[I 2025-12-31 09:32:56,462] Trial 549 pruned. \n",
      "[I 2025-12-31 09:33:29,566] Trial 550 pruned. \n",
      "[I 2025-12-31 09:34:01,641] Trial 551 pruned. \n",
      "[I 2025-12-31 09:34:31,746] Trial 552 pruned. \n",
      "[I 2025-12-31 09:35:02,352] Trial 553 pruned. \n",
      "[I 2025-12-31 09:35:33,080] Trial 554 pruned. \n",
      "[I 2025-12-31 09:36:01,411] Trial 555 pruned. \n",
      "[I 2025-12-31 09:36:45,111] Trial 556 pruned. \n",
      "[I 2025-12-31 09:37:01,713] Trial 557 pruned. \n",
      "[I 2025-12-31 09:37:22,812] Trial 558 pruned. \n",
      "[I 2025-12-31 09:37:51,588] Trial 559 pruned. \n",
      "[I 2025-12-31 09:38:08,096] Trial 560 pruned. \n",
      "[I 2025-12-31 09:38:22,189] Trial 561 pruned. \n",
      "[I 2025-12-31 09:38:35,327] Trial 562 pruned. \n",
      "[I 2025-12-31 09:38:51,281] Trial 563 pruned. \n",
      "[I 2025-12-31 09:39:12,302] Trial 564 pruned. \n",
      "[I 2025-12-31 09:39:28,276] Trial 565 pruned. \n",
      "[I 2025-12-31 09:39:50,845] Trial 566 pruned. \n",
      "[I 2025-12-31 09:40:13,808] Trial 567 pruned. \n",
      "[I 2025-12-31 09:40:39,621] Trial 568 pruned. \n",
      "[I 2025-12-31 09:41:08,240] Trial 569 pruned. \n",
      "[I 2025-12-31 09:41:22,659] Trial 570 pruned. \n",
      "[I 2025-12-31 09:41:51,857] Trial 571 pruned. \n",
      "[I 2025-12-31 09:42:06,545] Trial 572 pruned. \n",
      "[I 2025-12-31 09:42:30,090] Trial 573 pruned. \n",
      "[I 2025-12-31 09:42:52,648] Trial 574 pruned. \n",
      "[I 2025-12-31 09:43:19,782] Trial 575 pruned. \n",
      "[I 2025-12-31 09:43:41,068] Trial 576 pruned. \n",
      "[I 2025-12-31 09:44:11,005] Trial 577 pruned. \n",
      "[I 2025-12-31 09:44:27,230] Trial 578 pruned. \n",
      "[I 2025-12-31 09:45:10,099] Trial 579 pruned. \n",
      "[I 2025-12-31 09:45:38,935] Trial 580 pruned. \n",
      "[I 2025-12-31 09:46:06,461] Trial 581 pruned. \n",
      "[I 2025-12-31 09:46:31,470] Trial 582 pruned. \n",
      "[I 2025-12-31 09:46:48,528] Trial 583 pruned. \n",
      "[I 2025-12-31 09:47:15,644] Trial 584 pruned. \n",
      "[I 2025-12-31 09:47:37,452] Trial 585 pruned. \n",
      "[I 2025-12-31 09:47:58,246] Trial 586 pruned. \n",
      "[I 2025-12-31 09:48:17,600] Trial 587 pruned. \n",
      "[I 2025-12-31 09:48:33,860] Trial 588 pruned. \n",
      "[I 2025-12-31 09:49:07,627] Trial 589 pruned. \n",
      "[I 2025-12-31 09:49:23,201] Trial 590 pruned. \n",
      "[I 2025-12-31 09:49:39,371] Trial 591 pruned. \n",
      "[I 2025-12-31 09:50:04,941] Trial 592 pruned. \n",
      "[I 2025-12-31 09:50:25,090] Trial 593 pruned. \n",
      "[I 2025-12-31 09:50:41,399] Trial 594 pruned. \n",
      "[I 2025-12-31 09:50:57,760] Trial 595 pruned. \n",
      "[I 2025-12-31 09:51:15,497] Trial 596 pruned. \n",
      "[I 2025-12-31 09:51:41,539] Trial 597 pruned. \n",
      "[I 2025-12-31 09:52:16,192] Trial 598 pruned. \n",
      "[I 2025-12-31 09:52:32,360] Trial 599 pruned. \n",
      "[I 2025-12-31 09:52:49,707] Trial 600 pruned. \n",
      "[I 2025-12-31 09:53:28,071] Trial 601 pruned. \n",
      "[I 2025-12-31 09:53:48,595] Trial 602 pruned. \n",
      "[I 2025-12-31 09:54:18,980] Trial 603 pruned. \n",
      "[I 2025-12-31 09:54:40,544] Trial 604 pruned. \n",
      "[I 2025-12-31 09:54:58,004] Trial 605 pruned. \n",
      "[I 2025-12-31 09:55:16,832] Trial 606 pruned. \n",
      "[I 2025-12-31 09:55:38,770] Trial 607 pruned. \n",
      "[I 2025-12-31 09:55:52,540] Trial 608 pruned. \n",
      "[I 2025-12-31 09:56:18,173] Trial 609 pruned. \n",
      "[I 2025-12-31 09:56:32,887] Trial 610 pruned. \n",
      "[I 2025-12-31 09:56:57,122] Trial 611 pruned. \n",
      "[I 2025-12-31 09:57:17,400] Trial 612 pruned. \n",
      "[I 2025-12-31 09:57:30,320] Trial 613 pruned. \n",
      "[I 2025-12-31 09:57:46,148] Trial 614 pruned. \n",
      "[I 2025-12-31 09:58:20,960] Trial 615 pruned. \n",
      "[I 2025-12-31 09:58:36,327] Trial 616 pruned. \n",
      "[I 2025-12-31 10:00:09,142] Trial 617 finished with value: 0.7284352227358968 and parameters: {'learning_rate': 0.029330618232994078, 'max_depth': 5, 'num_leaves': 125, 'min_child_samples': 205, 'min_split_gain': 2.721584630573123, 'subsample': 0.8043697890777477, 'colsample_bytree': 0.862495272943861, 'reg_alpha': 1.8762853720101058, 'reg_lambda': 18.49676858338775}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 10:00:29,695] Trial 618 pruned. \n",
      "[I 2025-12-31 10:00:44,654] Trial 619 pruned. \n",
      "[I 2025-12-31 10:00:59,140] Trial 620 pruned. \n",
      "[I 2025-12-31 10:01:31,543] Trial 621 pruned. \n",
      "[I 2025-12-31 10:01:48,886] Trial 622 pruned. \n",
      "[I 2025-12-31 10:02:12,884] Trial 623 pruned. \n",
      "[I 2025-12-31 10:02:52,470] Trial 624 pruned. \n",
      "[I 2025-12-31 10:03:09,403] Trial 625 pruned. \n",
      "[I 2025-12-31 10:03:24,092] Trial 626 pruned. \n",
      "[I 2025-12-31 10:03:38,494] Trial 627 pruned. \n",
      "[I 2025-12-31 10:03:55,041] Trial 628 pruned. \n",
      "[I 2025-12-31 10:04:18,947] Trial 629 pruned. \n",
      "[I 2025-12-31 10:04:39,777] Trial 630 pruned. \n",
      "[I 2025-12-31 10:05:07,170] Trial 631 pruned. \n",
      "[I 2025-12-31 10:05:27,080] Trial 632 pruned. \n",
      "[I 2025-12-31 10:05:41,507] Trial 633 pruned. \n",
      "[I 2025-12-31 10:06:00,284] Trial 634 pruned. \n",
      "[I 2025-12-31 10:06:20,409] Trial 635 pruned. \n",
      "[I 2025-12-31 10:06:45,037] Trial 636 pruned. \n",
      "[I 2025-12-31 10:07:01,320] Trial 637 pruned. \n",
      "[I 2025-12-31 10:07:27,397] Trial 638 pruned. \n",
      "[I 2025-12-31 10:07:45,581] Trial 639 pruned. \n",
      "[I 2025-12-31 10:08:09,414] Trial 640 pruned. \n",
      "[I 2025-12-31 10:08:36,598] Trial 641 pruned. \n",
      "[I 2025-12-31 10:09:08,282] Trial 642 pruned. \n",
      "[I 2025-12-31 10:09:29,387] Trial 643 pruned. \n",
      "[I 2025-12-31 10:09:49,926] Trial 644 pruned. \n",
      "[I 2025-12-31 10:10:08,518] Trial 645 pruned. \n",
      "[I 2025-12-31 10:10:21,687] Trial 646 pruned. \n",
      "[I 2025-12-31 10:10:51,286] Trial 647 pruned. \n",
      "[I 2025-12-31 10:11:18,046] Trial 648 pruned. \n",
      "[I 2025-12-31 10:11:42,093] Trial 649 pruned. \n",
      "[I 2025-12-31 10:11:58,709] Trial 650 pruned. \n",
      "[I 2025-12-31 10:12:24,390] Trial 651 pruned. \n",
      "[I 2025-12-31 10:12:39,920] Trial 652 pruned. \n",
      "[I 2025-12-31 10:13:09,327] Trial 653 pruned. \n",
      "[I 2025-12-31 10:13:26,177] Trial 654 pruned. \n",
      "[I 2025-12-31 10:14:07,015] Trial 655 pruned. \n",
      "[I 2025-12-31 10:14:38,137] Trial 656 pruned. \n",
      "[I 2025-12-31 10:15:00,886] Trial 657 pruned. \n",
      "[I 2025-12-31 10:15:21,936] Trial 658 pruned. \n",
      "[I 2025-12-31 10:15:39,778] Trial 659 pruned. \n",
      "[I 2025-12-31 10:16:02,186] Trial 660 pruned. \n",
      "[I 2025-12-31 10:16:18,607] Trial 661 pruned. \n",
      "[I 2025-12-31 10:16:37,854] Trial 662 pruned. \n",
      "[I 2025-12-31 10:16:56,301] Trial 663 pruned. \n",
      "[I 2025-12-31 10:17:19,431] Trial 664 pruned. \n",
      "[I 2025-12-31 10:17:39,409] Trial 665 pruned. \n",
      "[I 2025-12-31 10:18:02,449] Trial 666 pruned. \n",
      "[I 2025-12-31 10:18:15,479] Trial 667 pruned. \n",
      "[I 2025-12-31 10:18:28,816] Trial 668 pruned. \n",
      "[I 2025-12-31 10:18:50,961] Trial 669 pruned. \n",
      "[I 2025-12-31 10:19:19,835] Trial 670 pruned. \n",
      "[I 2025-12-31 10:20:06,542] Trial 671 pruned. \n",
      "[I 2025-12-31 10:20:36,297] Trial 672 pruned. \n",
      "[I 2025-12-31 10:21:00,376] Trial 673 pruned. \n",
      "[I 2025-12-31 10:21:17,586] Trial 674 pruned. \n",
      "[I 2025-12-31 10:21:40,854] Trial 675 pruned. \n",
      "[I 2025-12-31 10:21:57,313] Trial 676 pruned. \n",
      "[I 2025-12-31 10:22:20,121] Trial 677 pruned. \n",
      "[I 2025-12-31 10:22:34,649] Trial 678 pruned. \n",
      "[I 2025-12-31 10:23:07,192] Trial 679 pruned. \n",
      "[I 2025-12-31 10:23:24,061] Trial 680 pruned. \n",
      "[I 2025-12-31 10:23:38,505] Trial 681 pruned. \n",
      "[I 2025-12-31 10:23:55,957] Trial 682 pruned. \n",
      "[I 2025-12-31 10:24:13,687] Trial 683 pruned. \n",
      "[I 2025-12-31 10:24:29,416] Trial 684 pruned. \n",
      "[I 2025-12-31 10:24:49,762] Trial 685 pruned. \n",
      "[I 2025-12-31 10:25:30,435] Trial 686 pruned. \n",
      "[I 2025-12-31 10:26:01,081] Trial 687 pruned. \n",
      "[I 2025-12-31 10:26:22,426] Trial 688 pruned. \n",
      "[I 2025-12-31 10:26:38,076] Trial 689 pruned. \n",
      "[I 2025-12-31 10:26:59,260] Trial 690 pruned. \n",
      "[I 2025-12-31 10:27:18,917] Trial 691 pruned. \n",
      "[I 2025-12-31 10:27:45,113] Trial 692 pruned. \n",
      "[I 2025-12-31 10:28:01,214] Trial 693 pruned. \n",
      "[I 2025-12-31 10:28:18,607] Trial 694 pruned. \n",
      "[I 2025-12-31 10:28:48,669] Trial 695 pruned. \n",
      "[I 2025-12-31 10:29:17,845] Trial 696 pruned. \n",
      "[I 2025-12-31 10:30:00,342] Trial 697 pruned. \n",
      "[I 2025-12-31 10:30:14,901] Trial 698 pruned. \n",
      "[I 2025-12-31 10:30:40,587] Trial 699 pruned. \n",
      "[I 2025-12-31 10:31:05,039] Trial 700 pruned. \n",
      "[I 2025-12-31 10:31:41,703] Trial 701 pruned. \n",
      "[I 2025-12-31 10:32:03,100] Trial 702 pruned. \n",
      "[I 2025-12-31 10:32:24,616] Trial 703 pruned. \n",
      "[I 2025-12-31 10:32:39,351] Trial 704 pruned. \n",
      "[I 2025-12-31 10:33:26,009] Trial 705 pruned. \n",
      "[I 2025-12-31 10:33:50,351] Trial 706 pruned. \n",
      "[I 2025-12-31 10:34:05,999] Trial 707 pruned. \n",
      "[I 2025-12-31 10:34:23,559] Trial 708 pruned. \n",
      "[I 2025-12-31 10:34:50,144] Trial 709 pruned. \n",
      "[I 2025-12-31 10:35:17,657] Trial 710 pruned. \n",
      "[I 2025-12-31 10:35:46,203] Trial 711 pruned. \n",
      "[I 2025-12-31 10:36:11,900] Trial 712 pruned. \n",
      "[I 2025-12-31 10:36:35,581] Trial 713 pruned. \n",
      "[I 2025-12-31 10:37:00,006] Trial 714 pruned. \n",
      "[I 2025-12-31 10:37:16,680] Trial 715 pruned. \n",
      "[I 2025-12-31 10:37:47,533] Trial 716 pruned. \n",
      "[I 2025-12-31 10:38:04,415] Trial 717 pruned. \n",
      "[I 2025-12-31 10:38:35,428] Trial 718 pruned. \n",
      "[I 2025-12-31 10:38:49,388] Trial 719 pruned. \n",
      "[I 2025-12-31 10:39:50,273] Trial 720 pruned. \n",
      "[I 2025-12-31 10:40:22,901] Trial 721 pruned. \n",
      "[I 2025-12-31 10:41:22,015] Trial 722 pruned. \n",
      "[I 2025-12-31 10:41:47,760] Trial 723 pruned. \n",
      "[I 2025-12-31 10:42:02,879] Trial 724 pruned. \n",
      "[I 2025-12-31 10:42:24,424] Trial 725 pruned. \n",
      "[I 2025-12-31 10:42:53,175] Trial 726 pruned. \n",
      "[I 2025-12-31 10:43:24,428] Trial 727 pruned. \n",
      "[I 2025-12-31 10:43:48,471] Trial 728 pruned. \n",
      "[I 2025-12-31 10:44:12,862] Trial 729 pruned. \n",
      "[I 2025-12-31 10:44:36,154] Trial 730 pruned. \n",
      "[I 2025-12-31 10:44:51,648] Trial 731 pruned. \n",
      "[I 2025-12-31 10:45:27,703] Trial 732 pruned. \n",
      "[I 2025-12-31 10:45:55,983] Trial 733 pruned. \n",
      "[I 2025-12-31 10:46:11,917] Trial 734 pruned. \n",
      "[I 2025-12-31 10:46:33,763] Trial 735 pruned. \n",
      "[I 2025-12-31 10:46:56,796] Trial 736 pruned. \n",
      "[I 2025-12-31 10:47:17,670] Trial 737 pruned. \n",
      "[I 2025-12-31 10:47:47,937] Trial 738 pruned. \n",
      "[I 2025-12-31 10:48:06,381] Trial 739 pruned. \n",
      "[I 2025-12-31 10:48:20,488] Trial 740 pruned. \n",
      "[I 2025-12-31 10:48:49,159] Trial 741 pruned. \n",
      "[I 2025-12-31 10:49:19,251] Trial 742 pruned. \n",
      "[I 2025-12-31 10:49:33,451] Trial 743 pruned. \n",
      "[I 2025-12-31 10:50:07,779] Trial 744 pruned. \n",
      "[I 2025-12-31 10:50:43,307] Trial 745 pruned. \n",
      "[I 2025-12-31 10:50:59,602] Trial 746 pruned. \n",
      "[I 2025-12-31 10:51:21,823] Trial 747 pruned. \n",
      "[I 2025-12-31 10:51:43,922] Trial 748 pruned. \n",
      "[I 2025-12-31 10:51:59,230] Trial 749 pruned. \n",
      "[I 2025-12-31 10:52:14,426] Trial 750 pruned. \n",
      "[I 2025-12-31 10:53:37,152] Trial 751 finished with value: 0.7289536756893424 and parameters: {'learning_rate': 0.032366843652491685, 'max_depth': 5, 'num_leaves': 135, 'min_child_samples': 215, 'min_split_gain': 0.07868982758092172, 'subsample': 0.8225122578008894, 'colsample_bytree': 0.8838633144914629, 'reg_alpha': 1.3688482887401912, 'reg_lambda': 20.493646878841844}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 10:53:58,838] Trial 752 pruned. \n",
      "[I 2025-12-31 10:54:29,628] Trial 753 pruned. \n",
      "[I 2025-12-31 10:54:45,963] Trial 754 pruned. \n",
      "[I 2025-12-31 10:55:02,137] Trial 755 pruned. \n",
      "[I 2025-12-31 10:55:16,701] Trial 756 pruned. \n",
      "[I 2025-12-31 10:55:31,949] Trial 757 pruned. \n",
      "[I 2025-12-31 10:55:53,887] Trial 758 pruned. \n",
      "[I 2025-12-31 10:56:09,813] Trial 759 pruned. \n",
      "[I 2025-12-31 10:56:24,934] Trial 760 pruned. \n",
      "[I 2025-12-31 10:56:58,336] Trial 761 pruned. \n",
      "[I 2025-12-31 10:57:27,592] Trial 762 pruned. \n",
      "[I 2025-12-31 10:57:51,487] Trial 763 pruned. \n",
      "[I 2025-12-31 10:58:14,127] Trial 764 pruned. \n",
      "[I 2025-12-31 10:58:35,759] Trial 765 pruned. \n",
      "[I 2025-12-31 10:58:51,673] Trial 766 pruned. \n",
      "[I 2025-12-31 10:59:19,970] Trial 767 pruned. \n",
      "[I 2025-12-31 10:59:50,077] Trial 768 pruned. \n",
      "[I 2025-12-31 11:00:29,503] Trial 769 pruned. \n",
      "[I 2025-12-31 11:00:59,882] Trial 770 pruned. \n",
      "[I 2025-12-31 11:01:28,903] Trial 771 pruned. \n",
      "[I 2025-12-31 11:02:34,230] Trial 772 pruned. \n",
      "[I 2025-12-31 11:02:50,393] Trial 773 pruned. \n",
      "[I 2025-12-31 11:03:06,913] Trial 774 pruned. \n",
      "[I 2025-12-31 11:03:25,358] Trial 775 pruned. \n",
      "[I 2025-12-31 11:03:46,131] Trial 776 pruned. \n",
      "[I 2025-12-31 11:04:01,689] Trial 777 pruned. \n",
      "[I 2025-12-31 11:04:29,502] Trial 778 pruned. \n",
      "[I 2025-12-31 11:05:01,917] Trial 779 pruned. \n",
      "[I 2025-12-31 11:05:27,610] Trial 780 pruned. \n",
      "[I 2025-12-31 11:05:51,391] Trial 781 pruned. \n",
      "[I 2025-12-31 11:06:05,784] Trial 782 pruned. \n",
      "[I 2025-12-31 11:06:30,234] Trial 783 pruned. \n",
      "[I 2025-12-31 11:07:49,112] Trial 784 finished with value: 0.7280261844713015 and parameters: {'learning_rate': 0.029084897505057543, 'max_depth': 5, 'num_leaves': 111, 'min_child_samples': 200, 'min_split_gain': 0.20238826474758828, 'subsample': 0.897295862545006, 'colsample_bytree': 0.738517588125595, 'reg_alpha': 1.8947191634667486, 'reg_lambda': 11.021373772814723}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 11:08:04,324] Trial 785 pruned. \n",
      "[I 2025-12-31 11:08:23,433] Trial 786 pruned. \n",
      "[I 2025-12-31 11:09:23,771] Trial 787 pruned. \n",
      "[I 2025-12-31 11:09:41,205] Trial 788 pruned. \n",
      "[I 2025-12-31 11:10:05,067] Trial 789 pruned. \n",
      "[I 2025-12-31 11:10:21,446] Trial 790 pruned. \n",
      "[I 2025-12-31 11:11:28,206] Trial 791 pruned. \n",
      "[I 2025-12-31 11:11:57,526] Trial 792 pruned. \n",
      "[I 2025-12-31 11:12:16,220] Trial 793 pruned. \n",
      "[I 2025-12-31 11:12:37,453] Trial 794 pruned. \n",
      "[I 2025-12-31 11:13:03,909] Trial 795 pruned. \n",
      "[I 2025-12-31 11:13:18,642] Trial 796 pruned. \n",
      "[I 2025-12-31 11:13:39,733] Trial 797 pruned. \n",
      "[I 2025-12-31 11:14:08,530] Trial 798 pruned. \n",
      "[I 2025-12-31 11:14:22,955] Trial 799 pruned. \n",
      "[I 2025-12-31 11:14:38,462] Trial 800 pruned. \n",
      "[I 2025-12-31 11:14:54,070] Trial 801 pruned. \n",
      "[I 2025-12-31 11:15:08,537] Trial 802 pruned. \n",
      "[I 2025-12-31 11:15:30,918] Trial 803 pruned. \n",
      "[I 2025-12-31 11:16:03,108] Trial 804 pruned. \n",
      "[I 2025-12-31 11:16:19,997] Trial 805 pruned. \n",
      "[I 2025-12-31 11:16:34,925] Trial 806 pruned. \n",
      "[I 2025-12-31 11:16:55,653] Trial 807 pruned. \n",
      "[I 2025-12-31 11:17:10,558] Trial 808 pruned. \n",
      "[I 2025-12-31 11:17:53,545] Trial 809 pruned. \n",
      "[I 2025-12-31 11:18:13,277] Trial 810 pruned. \n",
      "[I 2025-12-31 11:18:32,790] Trial 811 pruned. \n",
      "[I 2025-12-31 11:18:46,863] Trial 812 pruned. \n",
      "[I 2025-12-31 11:19:01,365] Trial 813 pruned. \n",
      "[I 2025-12-31 11:19:21,338] Trial 814 pruned. \n",
      "[I 2025-12-31 11:19:37,576] Trial 815 pruned. \n",
      "[I 2025-12-31 11:20:01,654] Trial 816 pruned. \n",
      "[I 2025-12-31 11:20:31,369] Trial 817 pruned. \n",
      "[I 2025-12-31 11:21:05,521] Trial 818 pruned. \n",
      "[I 2025-12-31 11:21:23,815] Trial 819 pruned. \n",
      "[I 2025-12-31 11:21:51,796] Trial 820 pruned. \n",
      "[I 2025-12-31 11:22:15,370] Trial 821 pruned. \n",
      "[I 2025-12-31 11:22:32,283] Trial 822 pruned. \n",
      "[I 2025-12-31 11:22:47,309] Trial 823 pruned. \n",
      "[I 2025-12-31 11:23:24,100] Trial 824 pruned. \n",
      "[I 2025-12-31 11:23:45,146] Trial 825 pruned. \n",
      "[I 2025-12-31 11:24:08,304] Trial 826 pruned. \n",
      "[I 2025-12-31 11:24:28,412] Trial 827 pruned. \n",
      "[I 2025-12-31 11:25:00,352] Trial 828 pruned. \n",
      "[I 2025-12-31 11:25:14,494] Trial 829 pruned. \n",
      "[I 2025-12-31 11:25:36,985] Trial 830 pruned. \n",
      "[I 2025-12-31 11:25:54,175] Trial 831 pruned. \n",
      "[I 2025-12-31 11:26:19,750] Trial 832 pruned. \n",
      "[I 2025-12-31 11:26:41,141] Trial 833 pruned. \n",
      "[I 2025-12-31 11:27:07,642] Trial 834 pruned. \n",
      "[I 2025-12-31 11:28:00,659] Trial 835 pruned. \n",
      "[I 2025-12-31 11:28:31,408] Trial 836 pruned. \n",
      "[I 2025-12-31 11:28:57,149] Trial 837 pruned. \n",
      "[I 2025-12-31 11:29:14,953] Trial 838 pruned. \n",
      "[I 2025-12-31 11:29:33,278] Trial 839 pruned. \n",
      "[I 2025-12-31 11:30:23,567] Trial 840 pruned. \n",
      "[I 2025-12-31 11:30:36,660] Trial 841 pruned. \n",
      "[I 2025-12-31 11:30:52,075] Trial 842 pruned. \n",
      "[I 2025-12-31 11:31:06,912] Trial 843 pruned. \n",
      "[I 2025-12-31 11:31:34,495] Trial 844 pruned. \n",
      "[I 2025-12-31 11:32:06,061] Trial 845 pruned. \n",
      "[I 2025-12-31 11:32:21,422] Trial 846 pruned. \n",
      "[I 2025-12-31 11:32:54,340] Trial 847 pruned. \n",
      "[I 2025-12-31 11:33:24,859] Trial 848 pruned. \n",
      "[I 2025-12-31 11:33:50,652] Trial 849 pruned. \n",
      "[I 2025-12-31 11:34:04,354] Trial 850 pruned. \n",
      "[I 2025-12-31 11:34:21,196] Trial 851 pruned. \n",
      "[I 2025-12-31 11:34:35,599] Trial 852 pruned. \n",
      "[I 2025-12-31 11:34:57,020] Trial 853 pruned. \n",
      "[I 2025-12-31 11:35:19,564] Trial 854 pruned. \n",
      "[I 2025-12-31 11:35:45,289] Trial 855 pruned. \n",
      "[I 2025-12-31 11:36:01,699] Trial 856 pruned. \n",
      "[I 2025-12-31 11:36:33,482] Trial 857 pruned. \n",
      "[I 2025-12-31 11:37:03,145] Trial 858 pruned. \n",
      "[I 2025-12-31 11:37:32,410] Trial 859 pruned. \n",
      "[I 2025-12-31 11:38:37,985] Trial 860 pruned. \n",
      "[I 2025-12-31 11:38:51,947] Trial 861 pruned. \n",
      "[I 2025-12-31 11:39:10,985] Trial 862 pruned. \n",
      "[I 2025-12-31 11:40:04,502] Trial 863 pruned. \n",
      "[I 2025-12-31 11:40:18,694] Trial 864 pruned. \n",
      "[I 2025-12-31 11:40:37,025] Trial 865 pruned. \n",
      "[I 2025-12-31 11:41:07,832] Trial 866 pruned. \n",
      "[I 2025-12-31 11:41:28,806] Trial 867 pruned. \n",
      "[I 2025-12-31 11:41:44,861] Trial 868 pruned. \n",
      "[I 2025-12-31 11:41:58,580] Trial 869 pruned. \n",
      "[I 2025-12-31 11:42:14,058] Trial 870 pruned. \n",
      "[I 2025-12-31 11:42:39,294] Trial 871 pruned. \n",
      "[I 2025-12-31 11:42:56,898] Trial 872 pruned. \n",
      "[I 2025-12-31 11:43:38,947] Trial 873 pruned. \n",
      "[I 2025-12-31 11:44:02,426] Trial 874 pruned. \n",
      "[I 2025-12-31 11:44:19,953] Trial 875 pruned. \n",
      "[I 2025-12-31 11:44:34,196] Trial 876 pruned. \n",
      "[I 2025-12-31 11:44:59,360] Trial 877 pruned. \n",
      "[I 2025-12-31 11:45:19,537] Trial 878 pruned. \n",
      "[I 2025-12-31 11:45:42,344] Trial 879 pruned. \n",
      "[I 2025-12-31 11:45:57,604] Trial 880 pruned. \n",
      "[I 2025-12-31 11:46:09,227] Trial 881 pruned. \n",
      "[I 2025-12-31 11:46:57,618] Trial 882 pruned. \n",
      "[I 2025-12-31 11:47:12,258] Trial 883 pruned. \n",
      "[I 2025-12-31 11:47:27,409] Trial 884 pruned. \n",
      "[I 2025-12-31 11:47:44,573] Trial 885 pruned. \n",
      "[I 2025-12-31 11:48:12,770] Trial 886 pruned. \n",
      "[I 2025-12-31 11:48:29,517] Trial 887 pruned. \n",
      "[I 2025-12-31 11:48:49,520] Trial 888 pruned. \n",
      "[I 2025-12-31 11:49:07,781] Trial 889 pruned. \n",
      "[I 2025-12-31 11:49:21,825] Trial 890 pruned. \n",
      "[I 2025-12-31 11:49:49,237] Trial 891 pruned. \n",
      "[I 2025-12-31 11:50:11,232] Trial 892 pruned. \n",
      "[I 2025-12-31 11:50:25,196] Trial 893 pruned. \n",
      "[I 2025-12-31 11:50:38,704] Trial 894 pruned. \n",
      "[I 2025-12-31 11:51:10,916] Trial 895 pruned. \n",
      "[I 2025-12-31 11:51:26,398] Trial 896 pruned. \n",
      "[I 2025-12-31 11:51:44,747] Trial 897 pruned. \n",
      "[I 2025-12-31 11:52:13,307] Trial 898 pruned. \n",
      "[I 2025-12-31 11:52:35,221] Trial 899 pruned. \n",
      "[I 2025-12-31 11:53:00,218] Trial 900 pruned. \n",
      "[I 2025-12-31 11:53:16,862] Trial 901 pruned. \n",
      "[I 2025-12-31 11:53:34,931] Trial 902 pruned. \n",
      "[I 2025-12-31 11:54:05,438] Trial 903 pruned. \n",
      "[I 2025-12-31 11:54:26,887] Trial 904 pruned. \n",
      "[I 2025-12-31 11:54:45,857] Trial 905 pruned. \n",
      "[I 2025-12-31 11:55:04,774] Trial 906 pruned. \n",
      "[I 2025-12-31 11:55:30,637] Trial 907 pruned. \n",
      "[I 2025-12-31 11:55:59,092] Trial 908 pruned. \n",
      "[I 2025-12-31 11:56:20,156] Trial 909 pruned. \n",
      "[I 2025-12-31 11:56:35,708] Trial 910 pruned. \n",
      "[I 2025-12-31 11:56:51,124] Trial 911 pruned. \n",
      "[I 2025-12-31 11:57:14,963] Trial 912 pruned. \n",
      "[I 2025-12-31 11:57:28,182] Trial 913 pruned. \n",
      "[I 2025-12-31 11:57:42,305] Trial 914 pruned. \n",
      "[I 2025-12-31 11:58:20,741] Trial 915 pruned. \n",
      "[I 2025-12-31 11:58:41,659] Trial 916 pruned. \n",
      "[I 2025-12-31 11:58:58,301] Trial 917 pruned. \n",
      "[I 2025-12-31 11:59:18,557] Trial 918 pruned. \n",
      "[I 2025-12-31 11:59:45,560] Trial 919 pruned. \n",
      "[I 2025-12-31 12:00:06,063] Trial 920 pruned. \n",
      "[I 2025-12-31 12:00:35,881] Trial 921 pruned. \n",
      "[I 2025-12-31 12:00:54,131] Trial 922 pruned. \n",
      "[I 2025-12-31 12:01:29,274] Trial 923 pruned. \n",
      "[I 2025-12-31 12:02:00,551] Trial 924 pruned. \n",
      "[I 2025-12-31 12:02:22,878] Trial 925 pruned. \n",
      "[I 2025-12-31 12:02:41,473] Trial 926 pruned. \n",
      "[I 2025-12-31 12:02:59,642] Trial 927 pruned. \n",
      "[I 2025-12-31 12:03:23,551] Trial 928 pruned. \n",
      "[I 2025-12-31 12:03:38,104] Trial 929 pruned. \n",
      "[I 2025-12-31 12:04:13,441] Trial 930 pruned. \n",
      "[I 2025-12-31 12:04:29,208] Trial 931 pruned. \n",
      "[I 2025-12-31 12:05:32,938] Trial 932 pruned. \n",
      "[I 2025-12-31 12:05:47,532] Trial 933 pruned. \n",
      "[I 2025-12-31 12:06:17,259] Trial 934 pruned. \n",
      "[I 2025-12-31 12:07:37,421] Trial 935 finished with value: 0.7285457725377362 and parameters: {'learning_rate': 0.031816238191718804, 'max_depth': 5, 'num_leaves': 109, 'min_child_samples': 237, 'min_split_gain': 0.04805352745047304, 'subsample': 0.8952474089977794, 'colsample_bytree': 0.7834659056225511, 'reg_alpha': 3.122560849887179, 'reg_lambda': 10.28296858647297}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 12:07:58,448] Trial 936 pruned. \n",
      "[I 2025-12-31 12:08:13,813] Trial 937 pruned. \n",
      "[I 2025-12-31 12:08:28,091] Trial 938 pruned. \n",
      "[I 2025-12-31 12:08:43,203] Trial 939 pruned. \n",
      "[I 2025-12-31 12:08:59,808] Trial 940 pruned. \n",
      "[I 2025-12-31 12:09:15,941] Trial 941 pruned. \n",
      "[I 2025-12-31 12:09:46,144] Trial 942 pruned. \n",
      "[I 2025-12-31 12:10:06,648] Trial 943 pruned. \n",
      "[I 2025-12-31 12:11:35,956] Trial 944 finished with value: 0.7281133849096051 and parameters: {'learning_rate': 0.029213108653314866, 'max_depth': 5, 'num_leaves': 94, 'min_child_samples': 212, 'min_split_gain': 0.24966610888582366, 'subsample': 0.8220017143502524, 'colsample_bytree': 0.8951709363110787, 'reg_alpha': 3.166690431366556, 'reg_lambda': 13.50470641627131}. Best is trial 5 with value: 0.7295389621748708.\n",
      "[I 2025-12-31 12:12:21,048] Trial 945 pruned. \n",
      "[I 2025-12-31 12:12:50,586] Trial 946 pruned. \n",
      "[I 2025-12-31 12:14:00,257] Trial 947 pruned. \n",
      "[I 2025-12-31 12:14:22,462] Trial 948 pruned. \n",
      "[I 2025-12-31 12:14:34,743] Trial 949 pruned. \n",
      "[I 2025-12-31 12:14:50,975] Trial 950 pruned. \n",
      "[I 2025-12-31 12:15:10,813] Trial 951 pruned. \n",
      "[I 2025-12-31 12:15:38,648] Trial 952 pruned. \n",
      "[I 2025-12-31 12:16:01,180] Trial 953 pruned. \n",
      "[I 2025-12-31 12:16:24,758] Trial 954 pruned. \n",
      "[I 2025-12-31 12:16:37,647] Trial 955 pruned. \n",
      "[I 2025-12-31 12:16:49,912] Trial 956 pruned. \n",
      "[I 2025-12-31 12:17:05,855] Trial 957 pruned. \n",
      "[I 2025-12-31 12:17:40,569] Trial 958 pruned. \n",
      "[I 2025-12-31 12:17:55,932] Trial 959 pruned. \n",
      "[I 2025-12-31 12:18:16,217] Trial 960 pruned. \n",
      "[I 2025-12-31 12:18:39,197] Trial 961 pruned. \n",
      "[I 2025-12-31 12:19:08,318] Trial 962 pruned. \n",
      "[I 2025-12-31 12:19:27,882] Trial 963 pruned. \n",
      "[I 2025-12-31 12:19:53,776] Trial 964 pruned. \n",
      "[I 2025-12-31 12:20:11,022] Trial 965 pruned. \n",
      "[I 2025-12-31 12:20:27,986] Trial 966 pruned. \n",
      "[I 2025-12-31 12:20:58,147] Trial 967 pruned. \n",
      "[I 2025-12-31 12:21:16,037] Trial 968 pruned. \n",
      "[I 2025-12-31 12:21:33,398] Trial 969 pruned. \n",
      "[I 2025-12-31 12:21:49,790] Trial 970 pruned. \n",
      "[I 2025-12-31 12:22:04,190] Trial 971 pruned. \n",
      "[I 2025-12-31 12:22:19,691] Trial 972 pruned. \n",
      "[I 2025-12-31 12:22:35,238] Trial 973 pruned. \n",
      "[I 2025-12-31 12:23:00,873] Trial 974 pruned. \n",
      "[I 2025-12-31 12:23:23,564] Trial 975 pruned. \n",
      "[I 2025-12-31 12:23:40,455] Trial 976 pruned. \n",
      "[I 2025-12-31 12:23:56,331] Trial 977 pruned. \n",
      "[I 2025-12-31 12:24:13,976] Trial 978 pruned. \n",
      "[I 2025-12-31 12:24:47,814] Trial 979 pruned. \n",
      "[I 2025-12-31 12:25:06,263] Trial 980 pruned. \n",
      "[I 2025-12-31 12:25:42,452] Trial 981 pruned. \n",
      "[I 2025-12-31 12:26:03,862] Trial 982 pruned. \n",
      "[I 2025-12-31 12:26:18,199] Trial 983 pruned. \n",
      "[I 2025-12-31 12:26:53,652] Trial 984 pruned. \n",
      "[I 2025-12-31 12:27:14,601] Trial 985 pruned. \n",
      "[I 2025-12-31 12:27:49,941] Trial 986 pruned. \n",
      "[I 2025-12-31 12:28:22,950] Trial 987 pruned. \n",
      "[I 2025-12-31 12:29:20,920] Trial 988 pruned. \n",
      "[I 2025-12-31 12:29:44,157] Trial 989 pruned. \n",
      "[I 2025-12-31 12:29:58,724] Trial 990 pruned. \n",
      "[I 2025-12-31 12:30:57,723] Trial 991 pruned. \n",
      "[I 2025-12-31 12:31:25,959] Trial 992 pruned. \n",
      "[I 2025-12-31 12:31:55,381] Trial 993 pruned. \n",
      "[I 2025-12-31 12:32:08,136] Trial 994 pruned. \n",
      "[I 2025-12-31 12:32:28,837] Trial 995 pruned. \n",
      "[I 2025-12-31 12:32:45,359] Trial 996 pruned. \n",
      "[I 2025-12-31 12:33:08,202] Trial 997 pruned. \n",
      "[I 2025-12-31 12:33:38,588] Trial 998 pruned. \n",
      "[I 2025-12-31 12:34:11,610] Trial 999 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trials finished: 1000\n",
      "Best trial AUC: 0.7295389621748708\n",
      "Best trial params:\n",
      "- learning_rate: 0.033462297306463135\n",
      "- max_depth: 6\n",
      "- num_leaves: 135\n",
      "- min_child_samples: 218\n",
      "- min_split_gain: 0.6953613090638021\n",
      "- subsample: 0.9704172179696724\n",
      "- colsample_bytree: 0.8614167078308603\n",
      "- reg_alpha: 4.082330867201149\n",
      "- reg_lambda: 136.5150739356614\n"
     ]
    }
   ],
   "source": [
    "if SKIP_META_MODEL_HYPERPARAMETER_TUNING:\n",
    "    print(\"Skipped hyperparameter tuning for meta-model\")\n",
    "else:\n",
    "    print(\"Started hyperparameter tuning for meta-model\")\n",
    "    sampler = optuna.samplers.TPESampler(n_ei_candidates=24, multivariate=True)\n",
    "    study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "    study.optimize(meta_model_optuna_study_objective, n_trials=META_MODEL_OPTUNA_STUDY_NUM_TRIALS)\n",
    "    \n",
    "    print(f\"# trials finished: {len(study.trials)}\")\n",
    "    trial = study.best_trial\n",
    "    meta_model_optuna_study_best_params = study.best_params\n",
    "    print(f\"Best trial AUC: {trial.value}\")\n",
    "    print(f\"Best trial params:\")\n",
    "    for param_key, param_value in meta_model_optuna_study_best_params.items():\n",
    "        print(f\"- {param_key}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f02c5c",
   "metadata": {
    "papermill": {
     "duration": 0.068063,
     "end_time": "2025-12-31T12:34:11.892633",
     "exception": false,
     "start_time": "2025-12-31T12:34:11.824570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 10.1.2 Meta-Model Default Values\n",
    "\n",
    "The default values to use if hyperparameter tuning & feature set selection was skipped for the meta model.\n",
    "These values are typically found from previous tuning/selection attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bedc020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:34:12.033660Z",
     "iopub.status.busy": "2025-12-31T12:34:12.033214Z",
     "iopub.status.idle": "2025-12-31T12:34:12.043703Z",
     "shell.execute_reply": "2025-12-31T12:34:12.042879Z"
    },
    "papermill": {
     "duration": 0.083911,
     "end_time": "2025-12-31T12:34:12.045179",
     "exception": false,
     "start_time": "2025-12-31T12:34:11.961268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "META_MODEL_DEFAULT_LEARNING_RATE = 0.03245958197888048\n",
    "META_MODEL_DEFAULT_MAX_DEPTH = 5\n",
    "META_MODEL_DEFAULT_NUM_LEAVES = 43\n",
    "META_MODEL_DEFAULT_MIN_CHILD_SAMPLES = 213\n",
    "META_MODEL_DEFAULT_MIN_SPLIT_GAIN = 0.05347530243444319\n",
    "META_MODEL_DEFAULT_SUBSAMPLE = 0.8656161171287692\n",
    "META_MODEL_DEFAULT_COLSAMPLE_BY_TREE = 0.7124759010931409\n",
    "META_MODEL_DEFAULT_REG_ALPHA = 12.049714533965576\n",
    "META_MODEL_DEFAULT_REG_LAMBDA = 172.91214403640194"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824f0eff",
   "metadata": {
    "papermill": {
     "duration": 0.069034,
     "end_time": "2025-12-31T12:34:12.185042",
     "exception": false,
     "start_time": "2025-12-31T12:34:12.116008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 10.1.3 Meta-Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fc9de26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:34:12.322462Z",
     "iopub.status.busy": "2025-12-31T12:34:12.322131Z",
     "iopub.status.idle": "2025-12-31T12:34:12.331997Z",
     "shell.execute_reply": "2025-12-31T12:34:12.330968Z"
    },
    "papermill": {
     "duration": 0.080524,
     "end_time": "2025-12-31T12:34:12.333508",
     "exception": false,
     "start_time": "2025-12-31T12:34:12.252984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following tuned parameters will be used for the meta-model:\n",
      "- learning_rate: 0.033462297306463135\n",
      "- max_depth: 6\n",
      "- num_leaves: 135\n",
      "- min_child_samples: 218\n",
      "- min_split_gain: 0.6953613090638021\n",
      "- subsample: 0.9704172179696724\n",
      "- colsample_bytree: 0.8614167078308603\n",
      "- reg_alpha: 4.082330867201149\n",
      "- reg_lambda: 136.5150739356614\n"
     ]
    }
   ],
   "source": [
    "meta_model_params['learning_rate'] = meta_model_optuna_study_best_params.get('learning_rate', META_MODEL_DEFAULT_LEARNING_RATE)\n",
    "meta_model_params['max_depth'] = meta_model_optuna_study_best_params.get('max_depth', META_MODEL_DEFAULT_MAX_DEPTH)\n",
    "meta_model_params['num_leaves'] = meta_model_optuna_study_best_params.get('num_leaves', META_MODEL_DEFAULT_NUM_LEAVES)\n",
    "meta_model_params['min_child_samples'] = meta_model_optuna_study_best_params.get('min_child_samples', META_MODEL_DEFAULT_MIN_CHILD_SAMPLES)\n",
    "meta_model_params['min_split_gain'] = meta_model_optuna_study_best_params.get('min_split_gain', META_MODEL_DEFAULT_MIN_SPLIT_GAIN)\n",
    "meta_model_params['subsample'] = meta_model_optuna_study_best_params.get('subsample', META_MODEL_DEFAULT_SUBSAMPLE)\n",
    "meta_model_params['colsample_bytree'] = meta_model_optuna_study_best_params.get('colsample_bytree', META_MODEL_DEFAULT_COLSAMPLE_BY_TREE)\n",
    "meta_model_params['reg_alpha'] = meta_model_optuna_study_best_params.get('reg_alpha', META_MODEL_DEFAULT_REG_ALPHA)\n",
    "meta_model_params['reg_lambda'] = meta_model_optuna_study_best_params.get('reg_lambda', META_MODEL_DEFAULT_REG_LAMBDA)\n",
    "print(f\"The following tuned parameters will be used for the meta-model:\")\n",
    "for param_key, param_value in meta_model_params.items():\n",
    "        print(f\"- {param_key}: {param_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf2366",
   "metadata": {
    "papermill": {
     "duration": 0.25059,
     "end_time": "2025-12-31T12:34:12.651541",
     "exception": false,
     "start_time": "2025-12-31T12:34:12.400951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.2 Meta-Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e421c770",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:34:12.789814Z",
     "iopub.status.busy": "2025-12-31T12:34:12.789500Z",
     "iopub.status.idle": "2025-12-31T12:37:55.484295Z",
     "shell.execute_reply": "2025-12-31T12:37:55.483222Z"
    },
    "papermill": {
     "duration": 222.76722,
     "end_time": "2025-12-31T12:37:55.486649",
     "exception": false,
     "start_time": "2025-12-31T12:34:12.719429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "meta_oof_preds_accumulator = np.zeros(len(train_data))\n",
    "meta_test_preds_accumulator = np.zeros(len(test_data))\n",
    "meta_train_feature_importances_accumulator = np.zeros(len(base_model_train_preds.columns))\n",
    "\n",
    "for random_seed in RANDOM_SEEDS:\n",
    "    meta_skf = StratifiedKFold(n_splits=META_MODEL_KFOLD_NUM_SPLITS, shuffle=True, random_state=random_seed)\n",
    "    meta_skf_splits = meta_skf.split(base_model_train_preds, train_data[target_col])\n",
    "    meta_skf_enumeration = enumerate(meta_skf_splits)\n",
    "\n",
    "    seed_oof_preds = np.zeros(len(train_data))\n",
    "\n",
    "    for fold, (train_indices, validation_indices) in meta_skf_enumeration:\n",
    "        X_train_fold = base_model_train_preds.iloc[train_indices]\n",
    "        y_train_fold = train_data[target_col].iloc[train_indices]\n",
    "        X_validation_fold = base_model_train_preds.iloc[validation_indices]\n",
    "        y_validation_fold = train_data[target_col].iloc[validation_indices]\n",
    "\n",
    "        meta_model = lgb.LGBMClassifier(\n",
    "            **meta_model_params,\n",
    "            n_estimators=10000,\n",
    "            objective='binary',\n",
    "            metric='auc',\n",
    "            bagging_freq=1,\n",
    "            monotone_constraints=[1]*len(base_model_train_preds.columns),\n",
    "            monotone_constraints_method='advanced',\n",
    "            verbose=-1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        meta_model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            eval_set=(X_validation_fold, y_validation_fold),\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=META_MODEL_EARLY_STOPPING_ROUNDS, verbose=0)]\n",
    "        )\n",
    "\n",
    "        y_validation_pred_proba = meta_model.predict_proba(X_validation_fold)[:, 1]\n",
    "        y_test_pred_proba = meta_model.predict_proba(base_model_test_preds)[:, 1]\n",
    "        seed_oof_preds[validation_indices] = np.array(y_validation_pred_proba)\n",
    "        meta_test_preds_accumulator += np.array(y_test_pred_proba)\n",
    "        meta_train_feature_importances_accumulator += np.array(meta_model.feature_importances_)\n",
    "\n",
    "    meta_oof_preds_accumulator += seed_oof_preds\n",
    "\n",
    "final_meta_oof_preds = meta_oof_preds_accumulator / len(RANDOM_SEEDS)\n",
    "final_meta_test_preds = meta_test_preds_accumulator / (META_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))\n",
    "meta_train_feature_importances = meta_train_feature_importances_accumulator / (META_MODEL_KFOLD_NUM_SPLITS * len(RANDOM_SEEDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8e53c",
   "metadata": {
    "papermill": {
     "duration": 0.067173,
     "end_time": "2025-12-31T12:37:55.622531",
     "exception": false,
     "start_time": "2025-12-31T12:37:55.555358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.3 Meta-Model Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa698b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:37:55.759464Z",
     "iopub.status.busy": "2025-12-31T12:37:55.759111Z",
     "iopub.status.idle": "2025-12-31T12:37:55.776823Z",
     "shell.execute_reply": "2025-12-31T12:37:55.775893Z"
    },
    "papermill": {
     "duration": 0.088069,
     "end_time": "2025-12-31T12:37:55.778384",
     "exception": false,
     "start_time": "2025-12-31T12:37:55.690315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier_7 (159c6c407450077591a665dea6ecacfe)           281.7\n",
       "LGBMClassifier_11 (434b9911e9f067fa638a7372ae9de3b7)         249.7\n",
       "LGBMClassifier_10 (d768bcfaea71d6315f8a3aec15264fd3)         235.4\n",
       "LGBMClassifier_6 (a0c02e5dec4bd4467961cd96901740a9)          225.3\n",
       "LGBMClassifier_8 (74451732f18860140bc6e208f17167ec)          215.6\n",
       "LGBMClassifier_104 (03f3c6e632f5fffd70ec8a4c916a9b3a)        141.8\n",
       "LGBMClassifier_9 (535b190c7fd27867f25b36c846af5749)          134.5\n",
       "LGBMClassifier_7 (0d5c160d0c75a01607ee65e1309f0f3e)          119.4\n",
       "XGBClassifier_102 (3a16502492397945fe3feec5f3ce94f2)         106.1\n",
       "XGBClassifier_6 (dd58a49196a10b1dfc83dd004b5cae1b)           102.9\n",
       "LGBMClassifier_13 (57b6180bb789e56517729d29e1113e9f)          83.9\n",
       "LGBMClassifier_2 (756b644eceb4b410ad34d055d7a2a7ad)           75.5\n",
       "LGBMClassifier_105 (b69a0d12e5e9a0dea6e97fd93d6e83ca)         68.5\n",
       "XGBClassifier_101 (34a22ef42d0624dee9c89abc9971c23f)          63.0\n",
       "LGBMClassifier_14 (e9cd9321a6617423d09c86651868827b)          51.7\n",
       "LGBMClassifier_3 (12e279a3f79f03854fcc391dd7dbd023)           50.3\n",
       "XGBClassifier_3 (4a02ebc078c643d903a00ddcfb0f3301)            47.6\n",
       "LGBMClassifier_103 (0f77b5c92200f4372a73a16c28e66a0c)         43.8\n",
       "CatBoostClassifier_203 (2b17c55ab32780d9a9f1a913c64ad718)     32.8\n",
       "CatBoostClassifier_202 (44630aa57085636ff4b42ef84843dad4)     29.7\n",
       "LGBMClassifier_202 (be93bc9c94b117d579fef02264e6d81f)         26.6\n",
       "XGBClassifier_2 (f9455e9875a464c78cd90b60584d3f1c)            24.4\n",
       "XGBClassifier_103 (ea8d1ee90caf97bacd865adb7e87423d)          23.3\n",
       "LGBMClassifier_101 (4184d68f723388204df6096a194619e3)         20.9\n",
       "LGBMClassifier_201 (6fc3b3d774e94599d833c0f91c5a3bd9)         17.8\n",
       "LGBMClassifier_107 (209378e46f2c00fc2bab71cb2a4b2806)         15.3\n",
       "LGBMClassifier_102 (15ce46227658fcf66d9fa61aa8770bd6)         14.4\n",
       "CatBoostClassifier_3 (a2e94c97067190eb52e25c8f0d0b1b81)       14.3\n",
       "CatBoostClassifier_101 (939b20ef655c1c22f3cc5749a9dc0de7)     13.5\n",
       "CatBoostClassifier_105 (faa5d67c16c906b11264ade5016c0635)     10.8\n",
       "CatBoostClassifier_1 (5b3133609cb7932f4c272f1494d1f6b0)        8.6\n",
       "XGBClassifier_11 (a13eb68990690e9fc4bef373e814ae80)            8.4\n",
       "CatBoostClassifier_206 (3ae27bae1ac853a169480fdb81503537)      8.3\n",
       "CatBoostClassifier_200 (193b4e2a59c2eac5f73a997fb968592b)      8.0\n",
       "LGBMClassifier_200 (595825024cf6728eede6526c34137bea)          7.3\n",
       "LGBMClassifier_203 (d42c5caf1073a9a9e7440490645eea6f)          7.2\n",
       "XGBClassifier_10 (3eba9b3facf87fe1c9ba57c1d875c799)            5.8\n",
       "CatBoostClassifier_104 (9db0b212db19e590b51a1af7fe65b7a0)      5.3\n",
       "LGBMClassifier_100 (e9308d5ef0fe3d2e21b23b76c24abf10)          5.1\n",
       "XGBClassifier_4 (41fcdf694bf252b540f6c6d28d63eb45)             5.0\n",
       "XGBClassifier_202 (29c6bbceec36b1810be94900531114e9)           3.7\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model_feature_importances = pd.Series(meta_train_feature_importances)\n",
    "meta_model_feature_importances.index = base_model_train_preds.columns\n",
    "meta_model_feature_importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914274fd",
   "metadata": {
    "papermill": {
     "duration": 0.067391,
     "end_time": "2025-12-31T12:37:55.913023",
     "exception": false,
     "start_time": "2025-12-31T12:37:55.845632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.4 Final Adjustments to Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7b39ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:37:56.052121Z",
     "iopub.status.busy": "2025-12-31T12:37:56.051772Z",
     "iopub.status.idle": "2025-12-31T12:37:56.066671Z",
     "shell.execute_reply": "2025-12-31T12:37:56.065840Z"
    },
    "papermill": {
     "duration": 0.08675,
     "end_time": "2025-12-31T12:37:56.068287",
     "exception": false,
     "start_time": "2025-12-31T12:37:55.981537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def min_max_scale(preds):\n",
    "    min_val = preds.min()\n",
    "    max_val = preds.max()\n",
    "    if max_val > min_val:\n",
    "        return (preds - min_val) / (max_val - min_val)\n",
    "    return preds\n",
    "\n",
    "# scale final meta oof/test preds\n",
    "scaled_final_meta_oof_preds = min_max_scale(final_meta_oof_preds)\n",
    "scaled_final_meta_test_preds = min_max_scale(final_meta_test_preds)\n",
    "\n",
    "# just in case floating point math leaves values very slightly below 0 or above 1\n",
    "scaled_final_meta_oof_preds = np.clip(scaled_final_meta_oof_preds, 0, 1)\n",
    "scaled_final_meta_test_preds = np.clip(scaled_final_meta_test_preds, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b6cd7",
   "metadata": {
    "papermill": {
     "duration": 0.068535,
     "end_time": "2025-12-31T12:37:56.205582",
     "exception": false,
     "start_time": "2025-12-31T12:37:56.137047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10.5 Meta-Model AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86a8ac5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:37:56.343514Z",
     "iopub.status.busy": "2025-12-31T12:37:56.342548Z",
     "iopub.status.idle": "2025-12-31T12:37:56.699665Z",
     "shell.execute_reply": "2025-12-31T12:37:56.698741Z"
    },
    "papermill": {
     "duration": 0.428106,
     "end_time": "2025-12-31T12:37:56.701281",
     "exception": false,
     "start_time": "2025-12-31T12:37:56.273175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7295001137941777\n"
     ]
    }
   ],
   "source": [
    "meta_model_auc = roc_auc_score(train_data[target_col], scaled_final_meta_oof_preds)\n",
    "print(meta_model_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedc581",
   "metadata": {
    "papermill": {
     "duration": 0.068081,
     "end_time": "2025-12-31T12:37:56.837623",
     "exception": false,
     "start_time": "2025-12-31T12:37:56.769542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 11. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0604f554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:37:56.977235Z",
     "iopub.status.busy": "2025-12-31T12:37:56.976323Z",
     "iopub.status.idle": "2025-12-31T12:37:57.636970Z",
     "shell.execute_reply": "2025-12-31T12:37:57.635169Z"
    },
    "papermill": {
     "duration": 0.732387,
     "end_time": "2025-12-31T12:37:57.638719",
     "exception": false,
     "start_time": "2025-12-31T12:37:56.906332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file prepared.\n"
     ]
    }
   ],
   "source": [
    "# prepare submission\n",
    "submission = pd.DataFrame({'id': test_data.index, target_col: scaled_final_meta_test_preds})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file prepared.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b04bd049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:37:57.778960Z",
     "iopub.status.busy": "2025-12-31T12:37:57.778041Z",
     "iopub.status.idle": "2025-12-31T12:38:02.702830Z",
     "shell.execute_reply": "2025-12-31T12:38:02.701777Z"
    },
    "papermill": {
     "duration": 4.995956,
     "end_time": "2025-12-31T12:38:02.704449",
     "exception": false,
     "start_time": "2025-12-31T12:37:57.708493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of predictions\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(scaled_final_meta_oof_preds, label='OOF Predictions (Train)', fill=True, color='blue', alpha=0.35)\n",
    "sns.kdeplot(scaled_final_meta_test_preds, label='Test Predictions', fill=True, color='orange', alpha=0.35)\n",
    "plt.title('Distribution of Predictions: OOF vs Test')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14272474,
     "sourceId": 91723,
     "sourceType": "competition"
    },
    {
     "datasetId": 8925440,
     "sourceId": 14307177,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29696.504395,
   "end_time": "2025-12-31T12:38:06.309323",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-31T04:23:09.804928",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
